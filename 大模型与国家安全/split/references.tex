% ==================== 参考文献 ====================
\begin{thebibliography}{99}

% ===== 基础技术文献 =====
\bibitem{vaswani2017attention} Vaswani A, Shazeer N, Parmar N, et al. Attention is all you need[C]. Advances in Neural Information Processing Systems 30, 2017: 5998--6008.

\bibitem{brown2020language} Brown T, Mann B, Ryder N, et al. Language models are few-shot learners[J]. Advances in Neural Information Processing Systems, 2020, 33: 1877--1901.

\bibitem{achiam2023gpt4} Achiam J, Adler S, Agarwal S, et al. GPT-4 technical report[J]. arXiv preprint arXiv:2303.08774, 2023.

\bibitem{touvron2023llama2} Touvron H, Martin L, Stone K, et al. Llama 2: Open foundation and fine-tuned chat models[J]. arXiv preprint arXiv:2307.09288, 2023.

\bibitem{anthropic2024claude3} Anthropic. The Claude 3 Model Family: A New Standard for Intelligence[R]. Anthropic Technical Report, 2024.

\bibitem{geminiteam2024} Gemini Team. Gemini: A family of highly capable multimodal models[J]. arXiv preprint arXiv:2312.11805, 2024.

\bibitem{deepseekv3} DeepSeek-AI. DeepSeek-V3 Technical Report[R]. 2024.

% ===== 缩放定律与涌现 =====
\bibitem{kaplan2020scaling} Kaplan J, McCandlish S, Henighan T, et al. Scaling laws for neural language models[J]. arXiv preprint arXiv:2001.08361, 2020.

\bibitem{hoffmann2022training} Hoffmann J, Borgeaud S, Mensch A, et al. Training compute-optimal large language models[J]. arXiv preprint arXiv:2203.15556, 2022.

\bibitem{wei2022emergent} Wei J, Tay Y, Bommasani R, et al. Emergent abilities of large language models[J]. Transactions on Machine Learning Research, 2022.

\bibitem{schaeffer2023emergent} Schaeffer R, Miranda B, Koyejo S. Are emergent abilities of large language models a mirage?[C]. Advances in Neural Information Processing Systems 36, 2023.

% ===== 对齐与安全 =====
\bibitem{ouyang2022training} Ouyang L, Wu J, Jiang X, et al. Training language models to follow instructions with human feedback[J]. Advances in Neural Information Processing Systems, 2022, 35: 27730--27744.

\bibitem{bai2022constitutional} Bai Y, Kadavath S, Kundu S, et al. Constitutional AI: Harmlessness from AI feedback[J]. arXiv preprint arXiv:2212.08073, 2022.

\bibitem{ji2023ai} Ji Z, Lee N, Frieske R, et al. Survey of hallucination in natural language generation[J]. ACM Computing Surveys, 2023, 55(12): 1--38.

\bibitem{hendrycks2023overview} Hendrycks D, Mazeika M, Woodside T. An overview of catastrophic AI risks[J]. arXiv preprint arXiv:2306.12001, 2023.

\bibitem{ngo2022alignment} Ngo R, Chan L, Mindermann S. The alignment problem from a deep learning perspective[J]. arXiv preprint arXiv:2209.00626, 2022.

% ===== AI代理与工具使用 =====
\bibitem{schick2023toolformer} Schick T, Dwivedi-Yu J, Dessì R, et al. Toolformer: Language models can teach themselves to use tools[J]. Advances in Neural Information Processing Systems 36, 2023.

\bibitem{significant2023autogpt} Significant Gravitas. Auto-GPT: An autonomous GPT-4 experiment[EB/OL]. https://github.com/Significant-Gravitas/Auto-GPT, 2023.

\bibitem{yao2022react} Yao S, Zhao J, Yu D, et al. ReAct: Synergizing reasoning and acting in language models[J]. arXiv preprint arXiv:2210.03629, 2022.

% ===== 国际政策与战略 =====
\bibitem{whitehouse2023ai} The White House. Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence[R]. 2023.

\bibitem{euaiact} European Parliament. Regulation (EU) 2024/1689 laying down harmonised rules on artificial intelligence (AI Act)[R]. 2024.

\bibitem{ukai2023} UK Government. AI Safety Summit 2023: The Bletchley Declaration[R]. 2023.

\bibitem{china2023} 国家互联网信息办公室. 生成式人工智能服务管理暂行办法[R]. 2023.

\bibitem{chips2022} U.S. Congress. CHIPS and Science Act of 2022[R]. Public Law 117--167, 2022.

% ===== 中国AI发展 =====
\bibitem{chinaai2017} 国务院. 新一代人工智能发展规划[R]. 国发〔2017〕35号, 2017.

\bibitem{roberts2021china} Roberts H, Cowls J, Morley J, et al. The Chinese approach to artificial intelligence: An analysis of policy, ethics, and regulation[J]. AI \& Society, 2021, 36(1): 59--77.

\bibitem{lee2018ai} Lee K F. AI superpowers: China, Silicon Valley, and the new world order[M]. Houghton Mifflin Harcourt, 2018.

% ===== 经济影响 =====
\bibitem{acemoglu2022artificial} Acemoglu D, Restrepo P. Tasks, automation, and the rise in U.S. wage inequality[J]. Econometrica, 2022, 90(5): 1973--2016.

\bibitem{eloundou2023gpts} Eloundou T, Manning S, Mishkin P, et al. GPTs are GPTs: An early look at the labor market impact potential of large language models[J]. arXiv preprint arXiv:2303.10130, 2023.

\bibitem{mckinsey2023generative} McKinsey Global Institute. The economic potential of generative AI: The next productivity frontier[R]. 2023.

\bibitem{goldman2023ai} Goldman Sachs. Generative AI could raise global GDP by 7\%[R]. Goldman Sachs Economics Research, 2023.

% ===== 军事与安全应用 =====
\bibitem{horowitz2018artificial} Horowitz M C. Artificial intelligence, international competition, and the balance of power[J]. Texas National Security Review, 2018, 1(3): 36--57.

\bibitem{scharre2018army} Scharre P. Army of none: Autonomous weapons and the future of war[M]. WW Norton \& Company, 2018.

\bibitem{allen2022defense} Allen G C, Chan T. Artificial intelligence and national security[R]. Belfer Center for Science and International Affairs, Harvard Kennedy School, 2022.

% ===== 开源与治理 =====
\bibitem{solaiman2023gradient} Solaiman I. The gradient of generative AI release: Methods and considerations[J]. arXiv preprint arXiv:2302.04844, 2023.

\bibitem{bommasani2021opportunities} Bommasani R, Hudson D A, Adeli E, et al. On the opportunities and risks of foundation models[J]. arXiv preprint arXiv:2108.07258, 2021.

\bibitem{anthropic2023rsp} Anthropic. Anthropic's Responsible Scaling Policy[R]. Anthropic Policy Document, 2023.

% ===== 计算与基础设施 =====
\bibitem{patterson2022carbon} Patterson D, Gonzalez J, Le Q, et al. Carbon emissions and large neural network training[J]. arXiv preprint arXiv:2104.10350, 2022.

\bibitem{sevilla2022compute} Sevilla J, Heim L, Ho A, et al. Compute trends across three eras of machine learning[C]. 2022 International Joint Conference on Neural Networks, 2022: 1--8.

% ===== 哲学与未来 =====
\bibitem{bostrom2014superintelligence} Bostrom N. Superintelligence: Paths, dangers, strategies[M]. Oxford University Press, 2014.

\bibitem{russell2019human} Russell S. Human compatible: Artificial intelligence and the problem of control[M]. Penguin, 2019.

\bibitem{kissinger2021age} Kissinger H, Schmidt E, Huttenlocher D. The age of AI: And our human future[M]. Little, Brown and Company, 2021.

% ===== 评测与基准 =====
\bibitem{hendrycks2020mmlu} Hendrycks D, Burns C, Basart S, et al. Measuring massive multitask language understanding[J]. arXiv preprint arXiv:2009.03300, 2020.

\bibitem{srivastava2022beyond} Srivastava A, Rastogi A, Rao A, et al. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models[J]. Transactions on Machine Learning Research, 2022.

\bibitem{chen2021evaluating} Chen M, Tworek J, Jun H, et al. Evaluating large language models trained on code[J]. arXiv preprint arXiv:2107.03374, 2021.

% ===== 中文文献 =====
\bibitem{huangtianyuan2023} 黄铁军. 大模型时代[M]. 中信出版社, 2023.

\bibitem{liuzhiyuan2024} 刘知远. 大语言模型[M]. 电子工业出版社, 2024.

\bibitem{tencent2024ai} 腾讯研究院. 2024年大模型产业发展报告[R]. 2024.

\bibitem{caict2024ai} 中国信息通信研究院. 人工智能发展白皮书（2024年）[R]. 2024.

\bibitem{aliresearch2024} 阿里研究院. 生成式AI的经济影响研究[R]. 2024.

\end{thebibliography}
