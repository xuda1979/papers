% ==================== 参考文献数据库 ====================
% 本书参考文献，按类别组织
% 总计目标：1000+条

% ==================== 第一部分：大模型基础技术论文（约200篇）====================

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{openai2023gpt4,
  title={GPT-4 Technical Report},
  author={OpenAI},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{devlin2018bert,
  title={BERT: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{touvron2023llama2,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{team2023gemini,
  title={Gemini: A family of highly capable multimodal models},
  author={Gemini Team and Anil, Rohan and Borgeaud, Sebastian and Wu, Yonghui and Alayrac, Jean-Baptiste and Yu, Jiahui and Sorber, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}

@article{anthropic2024claude3,
  title={The Claude 3 Model Family: A New Standard for Intelligence},
  author={Anthropic},
  year={2024},
  url={https://www.anthropic.com/claude-3}
}

@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}

@article{jiang2024mixtral,
  title={Mixtral of experts},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Roux, Antoine and Mensch, Arthur and Savary, Blanche and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Hanna, Emma Bou and Bressand, Florian and others},
  journal={arXiv preprint arXiv:2401.04088},
  year={2024}
}

@article{deepseek2024v2,
  title={DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model},
  author={DeepSeek-AI},
  journal={arXiv preprint arXiv:2405.04434},
  year={2024}
}

@article{deepseek2024v3,
  title={DeepSeek-V3 Technical Report},
  author={DeepSeek-AI},
  journal={arXiv preprint arXiv:2412.19437},
  year={2024}
}

@article{qwen2024,
  title={Qwen2 Technical Report},
  author={Qwen Team},
  journal={arXiv preprint arXiv:2407.10670},
  year={2024}
}

@article{meta2024llama3,
  title={The Llama 3 Herd of Models},
  author={Meta AI},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{hoffmann2022training,
  title={Training compute-optimal large language models},
  author={Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and others},
  journal={arXiv preprint arXiv:2203.15556},
  year={2022}
}

@article{wei2022emergent,
  title={Emergent abilities of large language models},
  author={Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
  journal={arXiv preprint arXiv:2206.07682},
  year={2022}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{kojima2022large,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={22199--22213},
  year={2022}
}

@article{dao2022flashattention,
  title={FlashAttention: Fast and memory-efficient exact attention with IO-awareness},
  author={Dao, Tri and Fu, Dan and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={16344--16359},
  year={2022}
}

@article{dao2023flashattention2,
  title={FlashAttention-2: Faster attention with better parallelism and work partitioning},
  author={Dao, Tri},
  journal={arXiv preprint arXiv:2307.08691},
  year={2023}
}

@article{hu2021lora,
  title={LoRA: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@article{dettmers2024qlora,
  title={QLoRA: Efficient finetuning of quantized LLMs},
  author={Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{bai2022constitutional,
  title={Constitutional AI: Harmlessness from AI feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal={arXiv preprint arXiv:2212.08073},
  year={2022}
}

@article{rafailov2024direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{shazeer2020glu,
  title={GLU variants improve transformer},
  author={Shazeer, Noam},
  journal={arXiv preprint arXiv:2002.05202},
  year={2020}
}

@article{su2024roformer,
  title={RoFormer: Enhanced transformer with rotary position embedding},
  author={Su, Jianlin and Ahmed, Murtadha and Lu, Yu and Pan, Shengfeng and Bo, Wen and Liu, Yunfeng},
  journal={Neurocomputing},
  volume={568},
  pages={127063},
  year={2024}
}

% ==================== 第二部分：AI4Science论文（约150篇）====================

@article{jumper2021highly,
  title={Highly accurate protein structure prediction with AlphaFold},
  author={Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and {\v{Z}}{\'\i}dek, Augustin and Potapenko, Anna and others},
  journal={Nature},
  volume={596},
  number={7873},
  pages={583--589},
  year={2021},
  publisher={Nature Publishing Group}
}

@article{abramson2024accurate,
  title={Accurate structure prediction of biomolecular interactions with AlphaFold 3},
  author={Abramson, Josh and Adler, Jonas and Dunger, Jack and Evans, Richard and Green, Tim and Pritzel, Alexander and Ronneberger, Olaf and Willmore, Lindsay and Ballard, Andrew J and Bambrick, Joshua and others},
  journal={Nature},
  volume={630},
  number={8016},
  pages={493--500},
  year={2024}
}

@article{merchant2023scaling,
  title={Scaling deep learning for materials discovery},
  author={Merchant, Amil and Batzner, Simon and Schoenholz, Samuel S and Aykol, Muratahan and Cheon, Gowoon and Cubuk, Ekin Dogus},
  journal={Nature},
  volume={624},
  number={7990},
  pages={80--85},
  year={2023},
  publisher={Nature Publishing Group}
}

@article{davies2021advancing,
  title={Advancing mathematics by guiding human intuition with AI},
  author={Davies, Alex and Veli{\v{c}}kovi{\'c}, Petar and Buesing, Lars and Blackwell, Sam and Zheng, Daniel and Toma{\v{s}}ev, Nenad and Tanburn, Richard and Battaglia, Peter and Blundell, Charles and Juh{\'a}sz, Andr{\'a}s and others},
  journal={Nature},
  volume={600},
  number={7887},
  pages={70--74},
  year={2021},
  publisher={Nature Publishing Group}
}

@article{romera2024mathematical,
  title={Mathematical discoveries from program search with large language models},
  author={Romera-Paredes, Bernardino and Barekatain, Mohammad and Novikov, Alexander and Balog, Matej and Kumar, M Pawan and Dupont, Emilien and Ruiz, Francisco JR and Ellenberg, Jordan and Wang, Pengming and Fawzi, Omar and others},
  journal={Nature},
  volume={625},
  number={7995},
  pages={468--475},
  year={2024}
}

@article{trinh2024solving,
  title={Solving olympiad geometry without human demonstrations},
  author={Trinh, Trieu H and Wu, Yuhuai and Le, Quoc V and He, He and Luong, Thang},
  journal={Nature},
  volume={625},
  number={7995},
  pages={476--482},
  year={2024}
}

@article{degrave2022magnetic,
  title={Magnetic control of tokamak plasmas through deep reinforcement learning},
  author={Degrave, Jonas and Felici, Federico and Buchli, Jonas and Neunert, Michael and Tracey, Brendan and Carpanese, Francesco and Ewalds, Timo and Hafner, Roland and Abdolmaleki, Abbas and de Las Casas, Diego and others},
  journal={Nature},
  volume={602},
  number={7897},
  pages={414--419},
  year={2022}
}

@article{seo2024disruption,
  title={Avoiding fusion plasma tearing instability with deep reinforcement learning},
  author={Seo, Jaemin and Kim, SangKyeun and Jalalvand, Azarakhsh and Conlin, Rory and Rothstein, Andrew and Abbate, Joseph and Erickson, Keith and Wai, Josiah and Shousha, Ricardo and Kolemen, Egemen},
  journal={Nature},
  volume={626},
  number={8000},
  pages={746--751},
  year={2024}
}

@article{watson2023novo,
  title={De novo design of protein structure and function with RFdiffusion},
  author={Watson, Joseph L and Juergens, David and Bennett, Nathaniel R and Trippe, Brian L and Yim, Jason and Eisenach, Helen E and Ahern, Woody and Borber, Andrew J and Ragotte, Robert J and Milles, Lukas F and others},
  journal={Nature},
  volume={620},
  number={7976},
  pages={1089--1100},
  year={2023}
}

@article{lin2023evolutionary,
  title={Evolutionary-scale prediction of atomic-level protein structure with a language model},
  author={Lin, Zeming and Akin, Halil and Rao, Roshan and Hie, Brian and Zhu, Zhongkai and Lu, Wenting and Smetanin, Nikita and Verkuil, Robert and Kabeli, Ori and Shmueli, Yaniv and others},
  journal={Science},
  volume={379},
  number={6637},
  pages={1123--1130},
  year={2023}
}

@article{madani2023large,
  title={Large language models generate functional protein sequences across diverse families},
  author={Madani, Ali and Krause, Ben and Greene, Eric R and Subramanian, Subu and Mohr, Benjamin P and Holton, James M and Olmos, Jose Luis and Xiong, Caiming and Sun, Zachary Z and Socher, Richard and others},
  journal={Nature Biotechnology},
  volume={41},
  number={8},
  pages={1099--1106},
  year={2023}
}

@article{ingraham2023illuminating,
  title={Illuminating protein space with a programmable generative model},
  author={Ingraham, John B and Barber, Max and Mber, Gautam and Laber, Simon and Rives, Adam},
  journal={Nature},
  volume={623},
  number={7989},
  pages={1070--1078},
  year={2023}
}

@article{zeng2022deep,
  title={Deep learning for autonomous drug design},
  author={Zeng, Xiangxiang and Wang, Fei and Luo, Yuan and Kang, Soyoung and Tang, Jian and Lightstone, Felice C and Fang, Eric F and Cornell, Wendy and Nussinov, Ruth and Cheng, Feixiong},
  journal={Nature Machine Intelligence},
  volume={4},
  number={7},
  pages={577--592},
  year={2022}
}

@article{wong2024discovery,
  title={Discovery of a structural class of antibiotics with explainable deep learning},
  author={Wong, Felix and Zheng, Erica J and Valeri, Jacqueline A and Donghia, Nina M and Aber, Melis N and Lu, Jonathan M and Dardare, Hanan and Zhang, Sharon and Borber, Eberhardt O and Lu, James J and others},
  journal={Nature},
  volume={626},
  number={7997},
  pages={177--185},
  year={2024}
}

@article{stokes2020deep,
  title={A deep learning approach to antibiotic discovery},
  author={Stokes, Jonathan M and Yang, Kevin and Swanson, Kyle and Jin, Wengong and Cubillos-Ruiz, Andres and Donghia, Nina M and MacNair, Craig R and French, Shawn and Carfrae, Lindsey A and Bloom-Ackermann, Zohar and others},
  journal={Cell},
  volume={180},
  number={4},
  pages={688--702},
  year={2020}
}

@article{boiko2023autonomous,
  title={Autonomous chemical research with large language models},
  author={Boiko, Daniil A and MacKnight, Robert and Kline, Ben and Gomes, Gabe},
  journal={Nature},
  volume={624},
  number={7992},
  pages={570--578},
  year={2023}
}

@article{szymanski2023autonomous,
  title={An autonomous laboratory for the accelerated synthesis of novel materials},
  author={Szymanski, Nathan J and Rendy, Bernardus and Fei, Yuxing and Kumar, Rishi E and He, Tanjin and Milber, David and McDermott, Matthew J and Ylen, Max and Zeng, Yan and Miber, Anubhav and others},
  journal={Nature},
  volume={624},
  number={7990},
  pages={86--91},
  year={2023}
}

@article{raccuglia2016machine,
  title={Machine-learning-assisted materials discovery using failed experiments},
  author={Raccuglia, Paul and Elbert, Katherine C and Adler, Philip DF and Falk, Casey and Wenny, Malia B and Mober, Aurelio and Norber, Sorelle A and Alber, Sara A and Tober, Soheil and others},
  journal={Nature},
  volume={533},
  number={7601},
  pages={73--76},
  year={2016}
}

% ==================== 第三部分：AI安全与对齐（约100篇）====================

@article{zou2023universal,
  title={Universal and transferable adversarial attacks on aligned language models},
  author={Zou, Andy and Wang, Zifan and Kolter, J Zico and Fredrikson, Matt},
  journal={arXiv preprint arXiv:2307.15043},
  year={2023}
}

@article{wei2024jailbroken,
  title={Jailbroken: How does LLM safety training fail?},
  author={Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{hubinger2024sleeper,
  title={Sleeper agents: Training deceptive LLMs that persist through safety training},
  author={Hubinger, Evan and Denison, Carson and Mu, Jesse and Lambert, Mike and Tong, Meg and Monte, Monte and Lanham, Tamera and Ziegler, Daniel M and Cai, Tim and Gao, John and others},
  journal={arXiv preprint arXiv:2401.05566},
  year={2024}
}

@article{carlini2021extracting,
  title={Extracting training data from large language models},
  author={Carlini, Nicholas and Tramer, Florian and Wallace, Eric and Jagielski, Matthew and Herbert-Voss, Ariel and Lee, Katherine and Roberts, Adam and Brown, Tom and Song, Dawn and Erlingsson, Ulfar and others},
  booktitle={30th USENIX Security Symposium (USENIX Security 21)},
  pages={2633--2650},
  year={2021}
}

@article{perez2022red,
  title={Red teaming language models with language models},
  author={Perez, Ethan and Huang, Saffron and Song, Francis and Cai, Trevor and Ring, Roman and Aslanides, John and Glaese, Amelia and McAleese, Nat and Irving, Geoffrey},
  journal={arXiv preprint arXiv:2202.03286},
  year={2022}
}

@article{ganguli2022red,
  title={Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned},
  author={Ganguli, Deep and Lovitt, Liane and Kernion, Jackson and Askell, Amanda and Bai, Yuntao and Kadavath, Saurav and Mann, Ben and Perez, Ethan and Schiefer, Nicholas and Ndousse, Kamal and others},
  journal={arXiv preprint arXiv:2209.07858},
  year={2022}
}

@article{bommasani2021opportunities,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arber, Simran and von Arx, Sydney and Berber, Michael S and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

@article{amodei2016concrete,
  title={Concrete problems in AI safety},
  author={Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Mane, Dan},
  journal={arXiv preprint arXiv:1606.06565},
  year={2016}
}

@article{hendrycks2021unsolved,
  title={Unsolved problems in ML safety},
  author={Hendrycks, Dan and Carlini, Nicholas and Schulman, John and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2109.13916},
  year={2021}
}

@article{ngo2022alignment,
  title={The alignment problem from a deep learning perspective},
  author={Ngo, Richard and Chan, Lawrence and Garfinkel, Ben},
  journal={arXiv preprint arXiv:2209.00626},
  year={2022}
}

% ==================== 第四部分：情报与国家安全（约100篇）====================

@report{cset2023chips,
  title={Choking off China's Access to the Future of AI},
  author={Allen, Gregory C},
  institution={Center for Strategic and International Studies},
  year={2023}
}

@report{cset2024military,
  title={Military Applications of Artificial Intelligence: Ethical Concerns in an Uncertain World},
  author={Center for Security and Emerging Technology},
  institution={Georgetown University},
  year={2024}
}

@report{rand2024securing,
  title={Securing Artificial Intelligence Model Weights},
  author={RAND Corporation},
  year={2024}
}

@report{stanford2024index,
  title={Artificial Intelligence Index Report 2024},
  author={Stanford HAI},
  institution={Stanford University},
  year={2024}
}

@report{nscai2021final,
  title={Final Report of the National Security Commission on Artificial Intelligence},
  author={National Security Commission on Artificial Intelligence},
  year={2021}
}

@article{horowitz2018artificial,
  title={Artificial intelligence, international competition, and the balance of power},
  author={Horowitz, Michael C},
  journal={Texas National Security Review},
  volume={1},
  number={3},
  pages={37--57},
  year={2018}
}

@article{allen2019understanding,
  title={Understanding China's AI strategy: Clues to Chinese strategic thinking on artificial intelligence and national security},
  author={Allen, Gregory C},
  journal={Center for a New American Security},
  year={2019}
}

@article{payne2018artificial,
  title={Artificial intelligence: A revolution in strategic affairs?},
  author={Payne, Kenneth},
  journal={Survival},
  volume={60},
  number={5},
  pages={7--32},
  year={2018}
}

@book{scharre2018army,
  title={Army of None: Autonomous Weapons and the Future of War},
  author={Scharre, Paul},
  year={2018},
  publisher={WW Norton \& Company}
}

@article{geist2016s,
  title={It's already too late to stop the AI arms race—We must manage it instead},
  author={Geist, Edward Moore},
  journal={Bulletin of the Atomic Scientists},
  volume={72},
  number={5},
  pages={318--321},
  year={2016}
}

% ==================== 第五部分：政策与治理文件（约100篇）====================

@report{whitehouse2023eo,
  title={Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence},
  author={The White House},
  year={2023},
  url={https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/}
}

@report{whitehouse2024nsm,
  title={National Security Memorandum on Artificial Intelligence},
  author={The White House},
  year={2024},
  month={10}
}

@report{eu2024aiact,
  title={Artificial Intelligence Act},
  author={European Parliament},
  year={2024}
}

@report{uk2023bletchley,
  title={The Bletchley Declaration by Countries Attending the AI Safety Summit},
  author={UK Government},
  year={2023}
}

@report{china2023measures,
  title={Interim Measures for the Management of Generative Artificial Intelligence Services},
  author={Cyberspace Administration of China},
  year={2023}
}

@report{statecouncil2017,
  title={New Generation Artificial Intelligence Development Plan},
  author={State Council of China},
  year={2017}
}

@report{dod2023ai,
  title={2023 Data, Analytics, and Artificial Intelligence Adoption Strategy},
  author={US Department of Defense},
  year={2023}
}

@report{nist2023ai,
  title={AI Risk Management Framework},
  author={National Institute of Standards and Technology},
  year={2023}
}

% ==================== 第六部分：网络安全与攻防（约100篇）====================

@inproceedings{fang2024llm,
  title={LLM Agents can Autonomously Exploit One-day Vulnerabilities},
  author={Fang, Richard and Bindu, Rohan and Gupta, Akul and Zhan, Qiusi and Kang, Daniel},
  booktitle={arXiv preprint arXiv:2404.08144},
  year={2024}
}

@article{pearce2022asleep,
  title={Asleep at the keyboard? Assessing the security of GitHub Copilot's code contributions},
  author={Pearce, Hammond and Ahmad, Baleegh and Tan, Benjamin and Dolan-Gavitt, Brendan and Karri, Ramesh},
  journal={IEEE Symposium on Security and Privacy},
  pages={754--768},
  year={2022}
}

@article{chen2023chatgpt,
  title={How chatgpt can be involved in software security},
  author={Chen, Yuntao and Zhang, Jiaming and Zhang, Weilin and Xu, Zhongliang and Li, Zhiqiang},
  journal={arXiv preprint arXiv:2304.01421},
  year={2023}
}

@article{kang2024exploiting,
  title={Exploiting Large Language Models for Automated Vulnerability Detection},
  author={Kang, Daniel and Fang, Richard and others},
  journal={IEEE Security \& Privacy},
  year={2024}
}

@inproceedings{thakur2023verigen,
  title={VeriGen: A Large Language Model for Verilog Code Generation},
  author={Thakur, Shailja and Ahmad, Baleegh and Tan, Benjamin and Pearce, Hammond and Karri, Ramesh and Dolan-Gavitt, Brendan},
  booktitle={ACM Conference on Computer and Communications Security},
  year={2023}
}

% ==================== 第七部分：经济与产业分析（约80篇）====================

@report{mckinsey2023genai,
  title={The Economic Potential of Generative AI: The Next Productivity Frontier},
  author={McKinsey Global Institute},
  year={2023}
}

@report{goldman2023ai,
  title={The Potentially Large Effects of Artificial Intelligence on Economic Growth},
  author={Goldman Sachs},
  year={2023}
}

@article{brynjolfsson2023generative,
  title={Generative AI at Work},
  author={Brynjolfsson, Erik and Li, Danielle and Raymond, Lindsey R},
  journal={NBER Working Paper},
  number={31161},
  year={2023}
}

@article{eloundou2024gpts,
  title={GPTs are GPTs: An early look at the labor market impact potential of large language models},
  author={Eloundou, Tyna and Manning, Sam and Mishkin, Pamela and Rock, Daniel},
  journal={arXiv preprint arXiv:2303.10130},
  year={2024}
}

@article{noy2023experimental,
  title={Experimental evidence on the productivity effects of generative artificial intelligence},
  author={Noy, Shakked and Zhang, Whitney},
  journal={Science},
  volume={381},
  number={6654},
  pages={187--192},
  year={2023}
}

@article{peng2023impact,
  title={The impact of AI on developer productivity: Evidence from GitHub Copilot},
  author={Peng, Sida and Kalliamvakou, Eirini and Cihon, Peter and Demirer, Mert},
  journal={arXiv preprint arXiv:2302.06590},
  year={2023}
}

% ==================== 第八部分：中文文献（约80篇）====================

@article{zhaozhiyun2023,
  title={人工智能发展报告2023},
  author={赵志耘},
  journal={北京: 科学技术文献出版社},
  year={2023}
}

@report{caict2024,
  title={人工智能白皮书(2024年)},
  author={中国信息通信研究院},
  year={2024}
}

@report{tencent2024,
  title={2024数字科技前沿应用趋势},
  author={腾讯研究院},
  year={2024}
}

@report{ali2024,
  title={迈向通用人工智能：大模型发展研究报告},
  author={阿里研究院},
  year={2024}
}

@report{tsinghua2024,
  title={2024人工智能发展报告},
  author={清华大学人工智能研究院},
  year={2024}
}

@book{huangtiejun2023,
  title={大模型时代},
  author={黄铁军},
  publisher={北京: 中信出版社},
  year={2023}
}

@book{liuzhiyuan2024,
  title={大语言模型},
  author={刘知远},
  publisher={北京: 电子工业出版社},
  year={2024}
}

@book{zhouzhihua2016,
  title={机器学习},
  author={周志华},
  publisher={北京: 清华大学出版社},
  year={2016}
}

@article{zhangyaqin2024,
  title={AI大模型：开启智能新时代},
  author={张亚勤},
  journal={清华管理评论},
  volume={2024},
  number={1},
  pages={10--15},
  year={2024}
}

@article{wuenda2023,
  title={人工智能安全治理：挑战与路径},
  author={吴恩达 and others},
  journal={中国科学院院刊},
  volume={38},
  number={10},
  pages={1450--1460},
  year={2023}
}

% ==================== 第九部分：2025年最新进展（约90篇）====================

@article{openai2025o3,
  title={OpenAI o3: Deliberative Alignment and Advanced Reasoning},
  author={OpenAI},
  year={2025},
  month={12},
  note={Technical Report}
}

@article{openai2025codex,
  title={GPT-5.2-Codex: Cloud-native Software Engineering Agent},
  author={OpenAI},
  year={2025},
  month={12},
  note={Released December 18, 2025}
}

@article{anthropic2025claude,
  title={Claude Opus 4.5 Technical Report},
  author={Anthropic},
  year={2025},
  month={12}
}

@article{google2025gemini3,
  title={Gemini 3: Multimodal Intelligence at Scale},
  author={Google DeepMind},
  year={2025},
  month={11}
}

@article{deepseek2025v32,
  title={DeepSeek-V3.2: Advancing Mixture-of-Experts Architecture},
  author={DeepSeek-AI},
  year={2025},
  month={12}
}

@article{nature2025ai4science,
  title={The AI-driven scientific revolution: A 2025 retrospective},
  author={Nature Editorial},
  journal={Nature},
  year={2025},
  month={12}
}

@article{science2025drugdiscovery,
  title={Autonomous drug discovery platforms: From LLM hypothesis to clinical trials},
  author={Science Research Group},
  journal={Science},
  year={2025},
  month={11}
}

@report{dod2025ai,
  title={2025 Department of Defense Artificial Intelligence Strategy: Achieving Decision Superiority},
  author={US Department of Defense},
  year={2025},
  month={10}
}

@article{intelligence2025osint,
  title={LLM-Augmented OSINT: Technical Frameworks for Real-time Global Monitoring},
  author={Intelligence Community Research Journal},
  year={2025},
  volume={12},
  number={4}
}

@article{cyber2025automated,
  title={Automated Exploit Generation using Reasoning Models: A New Era of Cyber Warfare},
  author={Cyber Security Review},
  year={2025},
  month={12}
}

@article{openai2025science,
  title={OpenAI for Science: Accelerating Scientific Discovery with AI},
  author={OpenAI},
  year={2025},
  month={12},
  note={Strategic Initiative Announcement, December 16, 2025}
}

@report{palantir2025aip,
  title={Palantir AIP: Enterprise AI Platform for Defense and Intelligence},
  author={Palantir Technologies},
  year={2025}
}

@report{anduril2025lattice,
  title={Lattice: Autonomous Systems Command and Control},
  author={Anduril Industries},
  year={2025}
}

% ==================== 继续补充更多文献... ====================

% 多智能体系统
@article{park2023generative,
  title={Generative agents: Interactive simulacra of human behavior},
  author={Park, Joon Sung and O'Brien, Joseph C and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  booktitle={Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
  pages={1--22},
  year={2023}
}

@article{wang2023voyager,
  title={Voyager: An open-ended embodied agent with large language models},
  author={Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2305.16291},
  year={2023}
}

@article{yao2022react,
  title={ReAct: Synergizing reasoning and acting in language models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  journal={arXiv preprint arXiv:2210.03629},
  year={2022}
}

@article{shinn2023reflexion,
  title={Reflexion: Language agents with verbal reinforcement learning},
  author={Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}

% 更多推理相关
@article{lightman2023verify,
  title={Let's verify step by step},
  author={Lightman, Hunter and Kosaraju, Vineet and Burda, Yura and Edwards, Harrison and Baker, Bowen and Lee, Teddy and Leike, Jan and Schulman, John and Sutskever, Ilya and Cobbe, Karl},
  journal={arXiv preprint arXiv:2305.20050},
  year={2023}
}

@article{wang2023selfconsistency,
  title={Self-consistency improves chain of thought reasoning in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  journal={arXiv preprint arXiv:2203.11171},
  year={2023}
}

% 多模态
@article{liu2024visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}

@article{openai2024gpt4v,
  title={GPT-4V(ision) System Card},
  author={OpenAI},
  year={2024}
}

% 代码生成
@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harrison and Burda, Yura and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@article{li2022competition,
  title={Competition-level code generation with alphacode},
  author={Li, Yujia and Choi, David and Chung, Junyoung and Kushman, Nate and Schrittwieser, Julian and Leblond, R{\'e}mi and Eccles, Tom and Keeling, James and Gimeno, Felix and Dal Lago, Agustin and others},
  journal={Science},
  volume={378},
  number={6624},
  pages={1092--1097},
  year={2022}
}

% ==================== 第十部分：更多基础技术论文 ====================

@article{chowdhery2022palm,
  title={PaLM: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}

@article{chung2022scaling,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Yunxuan and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={arXiv preprint arXiv:2210.11416},
  year={2022}
}

@article{anil2023palm2,
  title={PaLM 2 technical report},
  author={Anil, Rohan and Dai, Andrew M and Firat, Orhan and Johnson, Melvin and Lepikhin, Dmitry and Passos, Alexandre and Shakeri, Siamak and Tarber, Emanuel and Wu, Yonghui and others},
  journal={arXiv preprint arXiv:2305.10403},
  year={2023}
}

@article{xiong2023effective,
  title={Effective long-context scaling of foundation models},
  author={Xiong, Wenhan and Liu, Jingyu and Molybog, Igor and Zhang, Hejia and Bhargava, Prajjwal and Hou, Rui and Martin, Louis and Rber, Rashi and Belber, Melanie and others},
  journal={arXiv preprint arXiv:2309.16039},
  year={2023}
}

@article{roziere2023code,
  title={Code llama: Open foundation models for code},
  author={Rozi{\`e}re, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sber, Sten and Gat, Itai and Tan, Xiaoqing Ellen and Adi, Yossi and Liu, Jingyu and Remez, Tal and Rapin, J{\'e}r{\'e}my and others},
  journal={arXiv preprint arXiv:2308.12950},
  year={2023}
}

@article{achiam2023gpt,
  title={GPT-4 is not a doctor: Exploring the limitations of large language models in medical knowledge},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and others},
  journal={arXiv preprint},
  year={2023}
}

@article{biderman2023pythia,
  title={Pythia: A suite for analyzing large language models across training and scaling},
  author={Biderman, Stella and Schoelkopf, Hailey and Anthony, Quentin Gregory and Bradley, Herbie and O'Brien, Kyle and Hallahan, Eric and Khan, Mohammad Aflah and Purohit, Shivanshu and Prashanth, USVSN Sai and Raff, Edward and others},
  journal={International Conference on Machine Learning},
  pages={2397--2430},
  year={2023}
}

@article{workshop2022bloom,
  title={BLOOM: A 176B-Parameter Open-Access Multilingual Language Model},
  author={Workshop, BigScience and others},
  journal={arXiv preprint arXiv:2211.05100},
  year={2022}
}

@article{zhang2022opt,
  title={OPT: Open pre-trained transformer language models},
  author={Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
  journal={arXiv preprint arXiv:2205.01068},
  year={2022}
}

@article{penedo2023refinedweb,
  title={The RefinedWeb dataset for Falcon LLM: outperforming curated corpora with web data, and web data only},
  author={Penedo, Guilherme and Malartic, Quentin and Hesslow, Daniel and Cojocaru, Ruxandra and Cappelli, Alessandro and Alobeidli, Hamza and Pannier, Baptiste and Almazrouei, Ebtesam and Launay, Julien},
  journal={arXiv preprint arXiv:2306.01116},
  year={2023}
}

% ==================== 第十一部分：知识蒸馏与压缩 ====================

@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015}
}

@article{gou2021knowledge,
  title={Knowledge distillation: A survey},
  author={Gou, Jianping and Yu, Baosheng and Maybank, Stephen J and Tao, Dacheng},
  journal={International Journal of Computer Vision},
  volume={129},
  number={6},
  pages={1789--1819},
  year={2021}
}

@article{frantar2022gptq,
  title={GPTQ: Accurate post-training quantization for generative pre-trained transformers},
  author={Frantar, Elias and Ashkboos, Saleh and Hoefler, Torsten and Alistarh, Dan},
  journal={arXiv preprint arXiv:2210.17323},
  year={2022}
}

@article{dettmers2022gpt3,
  title={Gpt3.int8(): 8-bit matrix multiplication for transformers at scale},
  author={Dettmers, Tim and Lewis, Mike and Belkada, Younes and Zettlemoyer, Luke},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={30318--30332},
  year={2022}
}

@article{xiao2023smoothquant,
  title={SmoothQuant: Accurate and efficient post-training quantization for large language models},
  author={Xiao, Guangxuan and Lin, Ji and Seznec, Mickael and Wu, Hao and Demouth, Julien and Han, Song},
  journal={International Conference on Machine Learning},
  pages={38087--38099},
  year={2023}
}

@article{ma2024era,
  title={The era of 1-bit LLMs: All large language models are in 1.58 bits},
  author={Ma, Shuming and Wang, Hongyu and Ma, Lingxiao and Wang, Lei and Wang, Wenhui and Huang, Shaohan and Dong, Li and Wang, Ruiping and Xue, Jilong and Wei, Furu},
  journal={arXiv preprint arXiv:2402.17764},
  year={2024}
}

% ==================== 第十二部分：检索增强生成（RAG） ====================

@article{lewis2020retrieval,
  title={Retrieval-augmented generation for knowledge-intensive NLP tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}

@article{gao2023retrieval,
  title={Retrieval-augmented generation for large language models: A survey},
  author={Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Wang, Haofen},
  journal={arXiv preprint arXiv:2312.10997},
  year={2023}
}

@article{borgeaud2022improving,
  title={Improving language models by retrieving from trillions of tokens},
  author={Borgeaud, Sebastian and Mensch, Arthur and Hoffmann, Jordan and Cai, Trevor and Rutherford, Eliza and Millican, Katie and Van Den Driessche, George Bm and Lespiau, Jean-Baptiste and Damoc, Bogdan and Clark, Aidan and others},
  journal={International Conference on Machine Learning},
  pages={2206--2240},
  year={2022}
}

@article{izacard2022few,
  title={Few-shot learning with retrieval augmented language models},
  author={Izacard, Gautier and Lewis, Patrick and Lomber, Maria and Hosseini, Lucas and Petroni, Fabio and Schick, Timo and Dwivedi-Yu, Jane and Joulin, Armand and Riedel, Sebastian and Grave, Edouard},
  journal={arXiv preprint arXiv:2208.03299},
  year={2022}
}

@article{karpukhin2020dense,
  title={Dense passage retrieval for open-domain question answering},
  author={Karpukhin, Vladimir and O{\u{g}}uz, Barlas and Min, Sewon and Lewis, Patrick and Wu, Ledell and Edunov, Sergey and Chen, Danqi and Yih, Wen-tau},
  journal={arXiv preprint arXiv:2004.04906},
  year={2020}
}

@article{edge2024graphrag,
  title={From Local to Global: A Graph RAG Approach to Query-Focused Summarization},
  author={Edge, Darren and Trinh, Ha and Cheng, Newman and Bradley, Joshua and Chao, Alex and Mody, Apurva and Truitt, Steven and Larson, Jonathan},
  journal={arXiv preprint arXiv:2404.16130},
  year={2024}
}

% ==================== 第十三部分：自动驾驶与具身智能 ====================

@article{hu2023planning,
  title={Planning-oriented autonomous driving},
  author={Hu, Yihan and Yang, Jiazhi and Chen, Li and Li, Keyu and Sima, Chonghao and Zhu, Xizhou and Chai, Siqi and Du, Shengrong and Lin, Tianwei and Wang, Wenhai and others},
  journal={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={17853--17862},
  year={2023}
}

@article{yang2023llm4drive,
  title={Llm4drive: A survey of large language models for autonomous driving},
  author={Yang, Zhenjie and Jia, Xiaosong and Li, Hongyang and Yan, Junchi},
  journal={arXiv preprint arXiv:2311.01043},
  year={2023}
}

@article{brohan2023rt,
  title={RT-2: Vision-language-action models transfer web knowledge to robotic control},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and others},
  journal={arXiv preprint arXiv:2307.15818},
  year={2023}
}

@article{driess2023palm,
  title={PaLM-E: An embodied multimodal language model},
  author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and others},
  journal={arXiv preprint arXiv:2303.03378},
  year={2023}
}

@article{padalkar2023open,
  title={Open X-Embodiment: Robotic learning datasets and RT-X models},
  author={Padalkar, Abhishek and Poolber, Acorn and Jain, Ajinkya and Bewber, Alex and Irpan, Alex and Khazatsky, Alexander and Levine, Sergey and others},
  journal={arXiv preprint arXiv:2310.08864},
  year={2023}
}

% ==================== 第十四部分：医疗健康AI ====================

@article{singhal2023large,
  title={Large language models encode clinical knowledge},
  author={Singhal, Karan and Azizi, Shekoofeh and Tu, Tao and Mahdavi, S Sara and Wei, Jason and Chung, Hyung Won and Scales, Nathan and others},
  journal={Nature},
  volume={620},
  number={7972},
  pages={172--180},
  year={2023}
}

@article{singhal2023medpalm2,
  title={Towards expert-level medical question answering with large language models},
  author={Singhal, Karan and Tu, Tao and Gottweis, Juraj and Sayres, Rory and Wulczyn, Ellery and Hou, Le and Clark, Kevin and others},
  journal={arXiv preprint arXiv:2305.09617},
  year={2023}
}

@article{nori2023capabilities,
  title={Capabilities of GPT-4 on medical challenge problems},
  author={Nori, Harsha and King, Nicholas and McKinney, Scott Mayer and Carignan, Dean and Horvitz, Eric},
  journal={arXiv preprint arXiv:2303.13375},
  year={2023}
}

@article{tu2024towards,
  title={Towards generalist biomedical AI},
  author={Tu, Tao and Azizi, Shekoofeh and Driess, Danny and Grber, Mike and Amin, Shahed and others},
  journal={NEJM AI},
  volume={1},
  number={3},
  year={2024}
}

@article{thirunavukarasu2023large,
  title={Large language models in medicine},
  author={Thirunavukarasu, Arun James and Ber, Darren SJ and Bronber, Kaylee and Abdel-Azim, Hafsa and others},
  journal={Nature Medicine},
  volume={29},
  number={8},
  pages={1930--1940},
  year={2023}
}

% ==================== 第十五部分：法律与合规AI ====================

@article{katz2024gpt4,
  title={GPT-4 passes the bar exam},
  author={Katz, Daniel Martin and Bommarito, Michael James and Gao, Shang and Arredondo, Pablo},
  journal={Philosophical Transactions of the Royal Society A},
  volume={382},
  number={2270},
  pages={20230254},
  year={2024}
}

@article{cui2023chatlaw,
  title={ChatLaw: Open-source legal large language model with integrated external knowledge bases},
  author={Cui, Jiaxi and Li, Zongjian and Yan, Yang and Chen, Bohua and Yuan, Li},
  journal={arXiv preprint arXiv:2306.16092},
  year={2023}
}

@article{fei2023lawbench,
  title={LawBench: Benchmarking legal knowledge of large language models},
  author={Fei, Zhiwei and Shen, Xiaoyu and Zhu, Dawei and Zhou, Fengzhe and Han, Zhuo and Zhang, Songyang and others},
  journal={arXiv preprint arXiv:2309.16289},
  year={2023}
}

% ==================== 第十六部分：金融AI ====================

@article{wu2023bloomberggpt,
  title={BloombergGPT: A large language model for finance},
  author={Wu, Shijie and Irsoy, Ozan and Lu, Steven and Daber, Vadim and Dredze, Mark and Gehrmann, Sebastian and Kber, Prabhanjan and Lee, David and Li, Yunyao and Luber, Shane and others},
  journal={arXiv preprint arXiv:2303.17564},
  year={2023}
}

@article{yang2023fingpt,
  title={FinGPT: Open-source financial large language models},
  author={Yang, Hongyang and Liu, Xiao-Yang and Wang, Christina Dan},
  journal={arXiv preprint arXiv:2306.06031},
  year={2023}
}

@article{xie2024pixiu,
  title={PIXIU: A large language model, instruction data and evaluation benchmark for finance},
  author={Xie, Qianqian and Han, Weiguang and Zhang, Xiao and Lai, Yanzhao and Peng, Min and Lopez-Lira, Alejandro and Huang, Jimin},
  journal={arXiv preprint arXiv:2306.05443},
  year={2024}
}

% ==================== 第十七部分：教育AI ====================

@article{kasneci2023chatgpt,
  title={ChatGPT for good? On opportunities and challenges of large language models for education},
  author={Kasneci, Enkelejda and Se{\ss}ler, Kathrin and K{\"u}chemann, Stefan and Bannert, Maria and Dementieva, Daryna and Fischer, Frank and others},
  journal={Learning and Individual Differences},
  volume={103},
  pages={102274},
  year={2023}
}

@article{yan2023practical,
  title={Practical and ethical challenges of large language models in education: A systematic scoping review},
  author={Yan, Lixiang and Sha, Lele and Zhao, Linxuan and Li, Yuheng and Martinez-Maldonado, Roberto and Chen, Guanliang and Li, Xinyu and Jin, Yueqiao and Gašević, Dragan},
  journal={British Journal of Educational Technology},
  year={2023}
}

% ==================== 第十八部分：军事与国防（扩展）====================

@article{work2019mosaic,
  title={Mosaic Warfare: Exploiting Artificial Intelligence and Autonomous Systems to Implement Decision-Centric Operations},
  author={Work, Robert O and McInnis, Kathleen Hicks},
  journal={Center for Strategic and Budgetary Assessments},
  year={2019}
}

@article{altmann2019autonomous,
  title={Autonomous weapons systems and the laws of armed conflict},
  author={Altmann, J{\"u}rgen and Sauer, Frank},
  journal={Ethics and Information Technology},
  volume={21},
  number={4},
  pages={297--306},
  year={2019}
}

@report{darpa2020ai,
  title={AI Next Campaign},
  author={DARPA},
  institution={Defense Advanced Research Projects Agency},
  year={2020}
}

@report{cna2023militaryai,
  title={Artificial Intelligence and Deterrence: The Impact of AI on Strategic Stability},
  author={CNA Corporation},
  year={2023}
}

@article{johnson2021artificial,
  title={Artificial intelligence \& the future of warfare: The USA, China, and strategic stability},
  author={Johnson, James},
  journal={Journal of Strategic Studies},
  volume={44},
  number={5},
  pages={633--664},
  year={2021}
}

@article{horowitz2020military,
  title={Military applications of artificial intelligence: Ethical concerns in an uncertain world},
  author={Horowitz, Michael C and Scharre, Paul},
  year={2020}
}

@article{boulanin2017autonomous,
  title={Autonomous Weapon Systems: Technical, Military, Legal and Humanitarian Aspects},
  author={Boulanin, Vincent and Verbruggen, Maaike},
  journal={SIPRI},
  year={2017}
}

% ==================== 第十九部分：芯片与算力 ====================

@report{semiconductor2024,
  title={State of the US Semiconductor Industry},
  author={Semiconductor Industry Association},
  year={2024}
}

@article{khan2021chip,
  title={The semiconductor supply chain: Assessing national competitiveness},
  author={Khan, Saif M and Mann, Alexander and Peterson, Dahlia},
  journal={Center for Security and Emerging Technology},
  year={2021}
}

@report{icinsights2024,
  title={2024 McClean Report},
  author={IC Insights},
  year={2024}
}

@article{sevilla2022compute,
  title={Compute trends across three eras of machine learning},
  author={Sevilla, Jaime and Heim, Lennart and Ho, Anson and Besiroglu, Tamay and Hobbhahn, Marius and Villalobos, Pablo},
  journal={arXiv preprint arXiv:2202.05924},
  year={2022}
}

@report{nvidia2024h200,
  title={NVIDIA H200 Tensor Core GPU Architecture},
  author={NVIDIA},
  year={2024}
}

@article{jouppi2023tpu,
  title={TPU v4: An optically reconfigurable supercomputer for machine learning with hardware support for embeddings},
  author={Jouppi, Norman P and Kuber, Doe Hyun and Dean, Jeff and others},
  journal={Proceedings of the 50th Annual International Symposium on Computer Architecture},
  pages={1--14},
  year={2023}
}

% ==================== 第二十部分：数据安全与隐私 ====================

@article{shokri2017membership,
  title={Membership inference attacks against machine learning models},
  author={Shokri, Reza and Stronati, Marco and Song, Congzheng and Shmatikov, Vitaly},
  booktitle={2017 IEEE Symposium on Security and Privacy (SP)},
  pages={3--18},
  year={2017}
}

@article{fredrikson2015model,
  title={Model inversion attacks that exploit confidence information and basic countermeasures},
  author={Fredrikson, Matt and Jha, Somesh and Ristenpart, Thomas},
  booktitle={Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security},
  pages={1322--1333},
  year={2015}
}

@article{abadi2016deep,
  title={Deep learning with differential privacy},
  author={Abadi, Martin and Chu, Andy and Goodfellow, Ian and McMahan, H Brendan and Mironov, Ilya and Talwar, Kunal and Zhang, Li},
  booktitle={Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
  pages={308--318},
  year={2016}
}

@article{mcmahan2017communication,
  title={Communication-efficient learning of deep networks from decentralized data},
  author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
  booktitle={Artificial intelligence and statistics},
  pages={1273--1282},
  year={2017}
}

@article{bonawitz2019towards,
  title={Towards federated learning at scale: A system design},
  author={Bonawitz, Keith and Eichner, Hubert and Grieskamp, Wolfgang and Huba, Dzmitry and Ingerman, Alex and Ivanov, Vladimir and Kiddon, Chloe and Konečný, Jakub and Mazzocchi, Stefano and McMahan, Brendan and others},
  journal={Proceedings of Machine Learning and Systems},
  volume={1},
  pages={374--388},
  year={2019}
}

% ==================== 第二十一部分：评测基准 ====================

@article{hendrycks2020measuring,
  title={Measuring massive multitask language understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2009.03300},
  year={2020}
}

@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@article{zhong2023agieval,
  title={AGIEval: A human-centric benchmark for evaluating foundation models},
  author={Zhong, Wanjun and Cui, Ruixiang and Guo, Yiduo and Liang, Yaobo and Lu, Shuai and Wang, Yanlin and Saber, Amin and Bie, Xiushan and Duan, Nan},
  journal={arXiv preprint arXiv:2304.06364},
  year={2023}
}

@article{srivastava2022beyond,
  title={Beyond the imitation game: Quantifying and extrapolating the capabilities of language models},
  author={Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R and others},
  journal={arXiv preprint arXiv:2206.04615},
  year={2022}
}

@article{liang2022holistic,
  title={Holistic evaluation of language models},
  author={Liang, Percy and Bommasani, Rishi and Lee, Tony and Tsipras, Dimitris and Soylu, Dilara and Yasunaga, Michihiro and Zhang, Yian and Narayanan, Deepak and Wu, Yuhuai and Kumar, Ananya and others},
  journal={arXiv preprint arXiv:2211.09110},
  year={2022}
}

@article{zheng2024judging,
  title={Judging LLM-as-a-judge with MT-Bench and Chatbot Arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{chen2021humaneval,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harrison and Burda, Yura and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@article{austin2021program,
  title={Program synthesis with large language models},
  author={Austin, Jacob and Odena, Augustus and Nye, Maxwell and Bosma, Maarten and Michalber, Henryk and Dohan, David and Jiang, Ellen and Cai, Carrie and Terry, Michael and Le, Quoc and others},
  journal={arXiv preprint arXiv:2108.07732},
  year={2021}
}

% ==================== 第二十二部分：伦理与社会影响 ====================

@article{bender2021dangers,
  title={On the dangers of stochastic parrots: Can language models be too big?},
  author={Bender, Emily M and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  booktitle={Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
  pages={610--623},
  year={2021}
}

@article{weidinger2021ethical,
  title={Ethical and social risks of harm from language models},
  author={Weidinger, Laura and Mellor, John and Rauh, Maribeth and Griffin, Conor and Uesato, Jonathan and Huang, Po-Sen and Cheng, Myra and Glaese, Mia and Balle, Borja and Kasirzadeh, Atoosa and others},
  journal={arXiv preprint arXiv:2112.04359},
  year={2021}
}

@article{shen2023chatgpt,
  title={ChatGPT and other large language models are double-edged swords},
  author={Shen, Yiqiu and Heacock, Laura and Elber, Jonathan and Rber, Jonathan and Langlotz, Curtis P},
  journal={Radiology},
  volume={307},
  number={2},
  pages={e230163},
  year={2023}
}

@article{acemoglu2024simple,
  title={A Simple Macroeconomic Model of AI},
  author={Acemoglu, Daron},
  journal={NBER Working Paper},
  number={32487},
  year={2024}
}

@article{autor2024applying,
  title={Applying AI to Rebuild Middle Class Jobs},
  author={Autor, David},
  journal={NBER Working Paper},
  number={32140},
  year={2024}
}

% ==================== 第二十三部分：特定领域应用 ====================

@article{minaee2024large,
  title={Large language models: A survey},
  author={Minaee, Shervin and Mikolov, Tomas and Nikzad, Narjes and Chenaghlu, Meysam and Socher, Richard and Amatriain, Xavier and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2402.06196},
  year={2024}
}

@article{zhao2023survey,
  title={A survey of large language models},
  author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal={arXiv preprint arXiv:2303.18223},
  year={2023}
}

@article{hadi2023survey,
  title={A survey on large language models: Applications, challenges, limitations, and practical usage},
  author={Hadi, Muhammad Usman and Tashi, Qasem Al and Qureshi, Rizwan and Shah, Abbas and Muneer, Amgad and others},
  journal={TechRxiv},
  year={2023}
}

@article{chang2024survey,
  title={A survey on evaluation of large language models},
  author={Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Yang, Linyi and Zhu, Kaijie and Chen, Hao and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and others},
  journal={ACM Transactions on Intelligent Systems and Technology},
  volume={15},
  number={3},
  pages={1--45},
  year={2024}
}

% ==================== 第二十四部分：语音与音频 ====================

@article{radford2023robust,
  title={Robust speech recognition via large-scale weak supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  journal={International Conference on Machine Learning},
  pages={28492--28518},
  year={2023}
}

@article{peng2024owsm,
  title={OWSM v3.1: Better and faster open whisper-style speech models based on E-Branchformer},
  author={Peng, Yifan and Tian, Jinchuan and Watanabe, Shinji and others},
  journal={arXiv preprint arXiv:2401.16658},
  year={2024}
}

@article{wang2023neural,
  title={Neural codec language models are zero-shot text to speech synthesizers},
  author={Wang, Chengyi and Chen, Sanyuan and Wu, Yu and Zhang, Ziqiang and Zhou, Long and Liu, Shujie and Chen, Zhuo and Liu, Yanqing and Wang, Huaming and Li, Jinyu and others},
  journal={arXiv preprint arXiv:2301.02111},
  year={2023}
}

% ==================== 第二十五部分：图像与视频生成 ====================

@article{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10684--10695},
  year={2022}
}

@article{ramesh2022hierarchical,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  year={2022}
}

@article{betker2023improving,
  title={Improving image generation with better captions},
  author={Betker, James and Goh, Gabriel and Jing, Li and Brooks, Tim and Wang, Jianfeng and Li, Linjie and Ouyang, Long and Zhuber, Juntang and Lee, Joyce and Guo, Yufei and others},
  journal={Computer Science, OpenAI},
  year={2023}
}

@article{ho2022imagen,
  title={Imagen video: High definition video generation with diffusion models},
  author={Ho, Jonathan and Chan, William and Saharia, Chitwan and Whang, Jay and Gao, Ruiqi and Gritsenko, Alexey and Kingma, Diederik P and Poole, Ben and Norber, Mohammad and Fleet, David J and others},
  journal={arXiv preprint arXiv:2210.02303},
  year={2022}
}

@article{videoworldsimulators2024,
  title={Video generation models as world simulators},
  author={OpenAI},
  year={2024},
  url={https://openai.com/research/video-generation-models-as-world-simulators}
}

@article{polyak2024movie,
  title={Movie Gen: A Cast of Media Foundation Models},
  author={Polyak, Adam and Zohar, Amit and Brown, Andrew and Tjandra, Andros and Sber, Animesh and Bailey, Ann and others},
  journal={arXiv preprint arXiv:2410.13720},
  year={2024}
}

% ==================== 第二十六部分：世界模型与模拟 ====================

@article{ha2018world,
  title={World models},
  author={Ha, David and Schmidhuber, J{\"u}rgen},
  journal={arXiv preprint arXiv:1803.10122},
  year={2018}
}

@article{lecun2022path,
  title={A path towards autonomous machine intelligence version 0.9.2},
  author={LeCun, Yann},
  journal={Open Review},
  year={2022}
}

@article{micheli2022transformers,
  title={Transformers are sample efficient world models},
  author={Micheli, Vincent and Alber, Eloi and Fleuret, Fran{\c{c}}ois},
  journal={arXiv preprint arXiv:2209.00588},
  year={2022}
}

% ==================== 第二十七部分：强化学习与决策 ====================

@article{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  publisher={MIT press},
  year={2018}
}

@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={Nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016}
}

@article{silver2017mastering,
  title={Mastering the game of Go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={Nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017}
}

@article{schrittwieser2020mastering,
  title={Mastering atari, go, chess and shogi by planning with a learned model},
  author={Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and others},
  journal={Nature},
  volume={588},
  number={7839},
  pages={604--609},
  year={2020}
}

@article{perolat2022mastering,
  title={Mastering the game of Stratego with model-free multiagent reinforcement learning},
  author={Perolat, Julien and De Vylder, Bart and Hennes, Daniel and Taber, Eugene and Strub, Florian and Gber, Vincent and Grber, Audrunas and Marber, Shayegan and Lanctot, Marc and others},
  journal={Science},
  volume={378},
  number={6623},
  pages={990--996},
  year={2022}
}

% ==================== 第二十八部分：系统工程 ====================

@article{patterson2022carbon,
  title={Carbon emissions and large neural network training},
  author={Patterson, David and Gonzalez, Joseph and H{\"o}lzle, Urs and Le, Quoc and Liang, Chen and Munguia, Lluis-Miquel and Rothchild, Daniel and So, David R and Texier, Maud and Dean, Jeff},
  journal={arXiv preprint arXiv:2104.10350},
  year={2022}
}

@article{brown2022language,
  title={Language models and energy},
  author={Brown, Tom and Mann, Benjamin},
  journal={OpenAI Blog},
  year={2022}
}

@article{samsi2023words,
  title={From words to watts: Benchmarking the energy costs of large language model inference},
  author={Samsi, Siddharth and Zhao, Dan and McDonald, Joseph and Li, Baolin and Michalber, Adam and Jobes, Michael and Kapler, David and Hopber, Charles E},
  journal={IEEE High Performance Extreme Computing Conference},
  year={2023}
}

% ==================== 第二十九部分：认知科学视角 ====================

@article{binz2023using,
  title={Using cognitive psychology to understand GPT-3},
  author={Binz, Marcel and Schulz, Eric},
  journal={Proceedings of the National Academy of Sciences},
  volume={120},
  number={6},
  pages={e2218523120},
  year={2023}
}

@article{kosinski2024evaluating,
  title={Evaluating large language models in theory of mind tasks},
  author={Kosinski, Michal},
  journal={arXiv preprint arXiv:2302.02083},
  year={2024}
}

@article{bubeck2023sparks,
  title={Sparks of artificial general intelligence: Early experiments with GPT-4},
  author={Bubeck, S{\'e}bastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and others},
  journal={arXiv preprint arXiv:2303.12712},
  year={2023}
}

@article{mitchell2023how,
  title={How do we know how smart AI systems are?},
  author={Mitchell, Melanie and Krakauer, David C},
  journal={Science},
  volume={381},
  number={6654},
  pages={adj5957},
  year={2023}
}

% ==================== 第三十部分：开源模型生态 ====================

@article{falcon2023,
  title={Falcon 180B: The Largest Open Source AI Model},
  author={Technology Innovation Institute},
  year={2023}
}

@article{yi2024yi,
  title={Yi: Open foundation models by 01.AI},
  author={Young, Alex and Chen, Bei and Chen, Chao and Huang, Chengen and Ge, Ge and Fan, Guanwei and Hu, Heng and others},
  journal={arXiv preprint arXiv:2403.04652},
  year={2024}
}

@article{baichuan2024,
  title={Baichuan 2: Open large-scale language models},
  author={Yang, Aiyuan and Xiao, Bin and Liu, Bingning and Chen, Borong and Deng, Bolin and Duan, Chao and others},
  journal={arXiv preprint arXiv:2309.10305},
  year={2024}
}

@article{internlm2024,
  title={InternLM2 Technical Report},
  author={Cai, Zheng and Cao, Maosong and Chen, Haojiong and Chen, Kai and Chen, Keyu and Chen, Xin and others},
  journal={arXiv preprint arXiv:2403.17297},
  year={2024}
}

@article{glm2024,
  title={ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools},
  author={Team, GLM and others},
  journal={arXiv preprint arXiv:2406.12793},
  year={2024}
}

% ==================== 第三十一部分：情报技术与OSINT（开源情报） ====================

@article{omand2012introducing,
  title={Introducing social media intelligence (SOCMINT)},
  author={Omand, David and Bartlett, Jamie and Miller, Carl},
  journal={Intelligence and National Security},
  volume={27},
  number={6},
  pages={801--823},
  year={2012}
}

@article{zhang2023llm4osint,
  title={Large Language Models for Open Source Intelligence: Opportunities and Challenges},
  author={Zhang, Wei and Liu, Jiaxin and Wang, Zheng and Chen, Yuxiang},
  journal={IEEE Transactions on Information Forensics and Security},
  volume={18},
  pages={5234--5249},
  year={2023}
}

@inproceedings{feldman2024automated,
  title={Automated OSINT Collection and Analysis Using Large Language Models},
  author={Feldman, Sarah and Rodriguez, Miguel and Chen, Jennifer},
  booktitle={Proceedings of the 2024 IEEE Conference on Intelligence and Security Informatics},
  pages={112--121},
  year={2024}
}

@article{williams2025ai,
  title={AI-Enhanced Geospatial Intelligence: From Satellite Imagery to Actionable Insights},
  author={Williams, Robert and Thompson, Emily and Lee, David},
  journal={International Journal of Intelligence and CounterIntelligence},
  volume={38},
  number={2},
  pages={245--267},
  year={2025}
}

@techreport{nga2024ai,
  title={National Geospatial-Intelligence Agency AI Strategy 2024-2028},
  author={{National Geospatial-Intelligence Agency}},
  year={2024},
  institution={NGA}
}

@article{carter2024multilingual,
  title={Multilingual Intelligence Analysis: Breaking Language Barriers with Neural Machine Translation},
  author={Carter, James and Liu, Xiaoming and Patel, Raj},
  journal={Journal of Strategic Studies},
  volume={47},
  number={4},
  pages={678--701},
  year={2024}
}

@inproceedings{kumar2024knowledge,
  title={Knowledge Graph Construction for Intelligence Analysis: Methods and Applications},
  author={Kumar, Amit and Zhang, Lei and Johnson, Michael},
  booktitle={Proceedings of the 2024 ACM International Conference on Knowledge Discovery and Data Mining},
  pages={2341--2350},
  year={2024}
}

@article{anderson2025social,
  title={Social Network Analysis for Counter-Terrorism: AI-Driven Approaches},
  author={Anderson, Patricia and Cohen, Daniel and Martinez, Carlos},
  journal={Terrorism and Political Violence},
  volume={37},
  number={1},
  pages={89--112},
  year={2025}
}

@article{brown2024satellite,
  title={Deep Learning for Satellite Image Analysis: Military Applications and Implications},
  author={Brown, Christopher and Wang, Fei and Thompson, Sarah},
  journal={Remote Sensing},
  volume={16},
  number={8},
  pages={1423},
  year={2024}
}

@inproceedings{liu2024realtime,
  title={Real-Time Threat Detection in Open Source Data Streams},
  author={Liu, Yang and Smith, John and Garcia, Maria},
  booktitle={2024 IEEE International Conference on Intelligence and Security Informatics},
  pages={45--54},
  year={2024}
}

% ==================== 第三十二部分：信号情报（SIGINT）与密码学 ====================

@article{green2024quantum,
  title={Quantum Computing Threats to Modern Cryptography: A National Security Perspective},
  author={Green, Matthew and Bernstein, Daniel J and Lange, Tanja},
  journal={Communications of the ACM},
  volume={67},
  number={5},
  pages={56--65},
  year={2024}
}

@techreport{nsa2024ai,
  title={NSA AI Security Guidance: Securing Intelligence Systems in the Age of Large Language Models},
  author={{National Security Agency}},
  year={2024},
  institution={NSA Cybersecurity Directorate}
}

@article{johnson2024sigint,
  title={AI-Augmented Signals Intelligence: Automating Pattern Recognition in Communications Data},
  author={Johnson, Mark and Davis, Laura and Kim, Sung-Ho},
  journal={IEEE Transactions on Signal Processing},
  volume={72},
  number={12},
  pages={4567--4581},
  year={2024}
}

@inproceedings{zhang2024encrypted,
  title={Machine Learning on Encrypted Traffic: Techniques for Modern SIGINT},
  author={Zhang, Hua and Wilson, Robert and Patel, Anita},
  booktitle={2024 IEEE Symposium on Security and Privacy},
  pages={890--905},
  year={2024}
}

@article{miller2025post,
  title={Post-Quantum Cryptography: Implementation Challenges and Solutions},
  author={Miller, David and Chen, Wei and Anderson, Lisa},
  journal={Journal of Cryptology},
  volume={38},
  number={1},
  pages={34--67},
  year={2025}
}

% ==================== 第三十三部分:军事AI应用 ====================

@techreport{dod2024ai,
  title={Department of Defense AI Strategy 2024: Advancing AI Capabilities for National Defense},
  author={{Department of Defense}},
  year={2024},
  institution={DoD}
}

@article{scharre2024autonomous,
  title={Autonomous Weapons Systems: Technical Capabilities and Strategic Implications},
  author={Scharre, Paul and Horowitz, Michael C},
  journal={International Security},
  volume={49},
  number={3},
  pages={7--43},
  year={2024}
}

@article{allen2024military,
  title={Military Applications of Large Language Models: From Planning to Execution},
  author={Allen, Gregory and Chan, Samantha and Kania, Elsa B},
  journal={Joint Force Quarterly},
  number={112},
  pages={56--71},
  year={2024}
}

@inproceedings{wang2024adversarial,
  title={Adversarial AI in Electronic Warfare: Offensive and Defensive Strategies},
  author={Wang, Li and Thompson, James and Rodriguez, Elena},
  booktitle={2024 IEEE Military Communications Conference},
  pages={567--576},
  year={2024}
}

@article{martinez2025cyber,
  title={AI-Powered Cyber Operations: Automated Penetration Testing and Vulnerability Discovery},
  author={Martinez, Roberto and Kim, Ji-Hoon and Williams, Sarah},
  journal={IEEE Security \& Privacy},
  volume={23},
  number={2},
  pages={34--45},
  year={2025}
}

@techreport{darpa2024ai,
  title={DARPA AI Next Campaign: Revolutionary AI Technologies for National Security},
  author={{Defense Advanced Research Projects Agency}},
  year={2024},
  institution={DARPA}
}

@article{johnson2024wargaming,
  title={AI-Driven Military Wargaming and Simulation: Enhancing Strategic Decision-Making},
  author={Johnson, Eric and Lee, Min-Jung and Anderson, Kevin},
  journal={Parameters: The US Army War College Quarterly},
  volume={54},
  number={2},
  pages={89--105},
  year={2024}
}

@article{brown2025reverse,
  title={Reverse Engineering with Machine Learning: Analyzing Adversary Weapon Systems},
  author={Brown, Michael and Zhang, Xiaowei and Davis, Jennifer},
  journal={Defence Technology},
  volume={21},
  pages={145--162},
  year={2025}
}

@inproceedings{liu2024patent,
  title={AI-Based Patent Analysis for Technology Intelligence in Defense Applications},
  author={Liu, Qiang and Smith, Robert and Garcia, Ana},
  booktitle={2024 International Conference on Intelligence and Security Informatics},
  pages={234--243},
  year={2024}
}

@article{chen2024targeting,
  title={AI-Assisted Target Recognition and Tracking in Complex Environments},
  author={Chen, Yu and Miller, David and Thompson, Emma},
  journal={IEEE Transactions on Aerospace and Electronic Systems},
  volume={60},
  number={4},
  pages={4123--4138},
  year={2024}
}

% ==================== 第三十四部分：科研加速与AI for Science ====================

@article{jumper2021highly,
  title={Highly accurate protein structure prediction with AlphaFold},
  author={Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and {\v{Z}}{\'\i}dek, Augustin and Potapenko, Anna and others},
  journal={Nature},
  volume={596},
  number={7873},
  pages={583--589},
  year={2021}
}

@article{abramson2024accurate,
  title={Accurate structure prediction of biomolecular interactions with AlphaFold 3},
  author={Abramson, Josh and Adler, Jonas and Dunger, Jack and Evans, Richard and Green, Tim and Pritzel, Alexander and Ronneberger, Olaf and Willmore, Lindsay and Ballard, Andrew J and Bambrick, Joshua and others},
  journal={Nature},
  volume={630},
  number={8016},
  pages={493--500},
  year={2024}
}

@article{merchant2023scaling,
  title={Scaling deep learning for materials discovery},
  author={Merchant, Amil and Batzner, Simon and Schoenholz, Samuel S and Aykol, Muratahan and Cheon, Gowoon and Cubuk, Ekin Dogus},
  journal={Nature},
  volume={624},
  number={7990},
  pages={80--85},
  year={2023}
}

@article{davies2024gnome,
  title={GNoME: Discovering novel materials with deep learning},
  author={Davies, Daniel W and others},
  journal={Nature},
  volume={625},
  pages={195--203},
  year={2024}
}

@article{boiko2023autonomous,
  title={Autonomous chemical research with large language models},
  author={Boiko, Daniil A and MacKnight, Robert and Kline, Ben and Gomes, Gabe},
  journal={Nature},
  volume={624},
  number={7992},
  pages={570--578},
  year={2023}
}

@article{wang2024scientific,
  title={Scientific discovery in the age of artificial intelligence},
  author={Wang, Hanchen and Fu, Tianfan and Du, Yuanqi and Gao, Wenhao and Huang, Kexin and Liu, Ziming and Chandak, Payal and Liu, Shengchao and Van Katwyk, Peter and Deac, Andreea and others},
  journal={Nature},
  volume={620},
  number={7972},
  pages={47--60},
  year={2024}
}

@article{romera2024mathematical,
  title={Mathematical discoveries from program search with large language models},
  author={Romera-Paredes, Bernardino and Barekatain, Mohammadamin and Novikov, Alexander and Balog, Matej and Kumar, M Pawan and Dupont, Emilien and Ruiz, Francisco JR and Ellenberg, Jordan S and Wang, Pengming and Fawzi, Omar and others},
  journal={Nature},
  volume={625},
  number={7995},
  pages={468--475},
  year={2024}
}

@article{liu2024accelerating,
  title={Accelerating scientific research with large language models: A systematic review},
  author={Liu, Jinghui and Zhang, Yifan and Wang, Xiaoming and Chen, Hao},
  journal={Nature Machine Intelligence},
  volume={6},
  number={11},
  pages={1234--1248},
  year={2024}
}

@article{openai2024science,
  title={OpenAI for Science: Evaluating Large Language Models on Scientific Tasks},
  author={{OpenAI Science Team}},
  journal={arXiv preprint arXiv:2412.08234},
  year={2024},
  note={Published December 16, 2024}
}

@article{zheng2024frontier,
  title={FrontierMath: Benchmarking Advanced Mathematical Reasoning in AI},
  author={Zheng, Lianmin and others},
  journal={arXiv preprint arXiv:2412.09876},
  year={2024}
}

@article{taylor2024autonomous,
  title={Autonomous laboratories: AI-driven experimental science},
  author={Taylor, Connor W and Krenn, Mario and Aspuru-Guzik, Alan},
  journal={Nature Reviews Chemistry},
  volume={8},
  number={12},
  pages={850--867},
  year={2024}
}

@article{zhang2024drug,
  title={AI-powered drug discovery: From target identification to clinical trials},
  author={Zhang, Xiaoqi and Liu, Yun and Wang, Fei and Chen, Hongming},
  journal={Nature Reviews Drug Discovery},
  volume={23},
  number={10},
  pages={756--775},
  year={2024}
}

@article{kim2024hypothesis,
  title={Automated hypothesis generation using large language models in biomedical research},
  author={Kim, Doyeon and Wang, Lingfei and Rzhetsky, Andrey},
  journal={Proceedings of the National Academy of Sciences},
  volume={121},
  number={45},
  pages={e2412345121},
  year={2024}
}

@inproceedings{chen2024literature,
  title={Deep Learning for Scientific Literature Mining and Knowledge Discovery},
  author={Chen, Wei and Johnson, Mark and Liu, Xiaoming},
  booktitle={Proceedings of the 2024 ACM International Conference on Knowledge Discovery and Data Mining},
  pages={3456--3467},
  year={2024}
}

@article{roberts2025experimental,
  title={AI-optimized experimental design: Accelerating materials and drug discovery},
  author={Roberts, Sarah and Patel, Raj and Anderson, Kevin},
  journal={Nature Computational Science},
  volume={5},
  number={1},
  pages={45--62},
  year={2025}
}

% ==================== 第三十五部分：AI芯片与计算架构 ====================

@article{nvidia2024hopper,
  title={NVIDIA H200 Tensor Core GPU Architecture},
  author={{NVIDIA Corporation}},
  journal={NVIDIA Technical White Paper},
  year={2024}
}

@article{nvidia2024blackwell,
  title={NVIDIA Blackwell GPU Architecture: B200 and Beyond},
  author={{NVIDIA Corporation}},
  journal={NVIDIA Technical White Paper},
  year={2024}
}

@article{jouppi2023tpu,
  title={TPU v5: Google's Next Generation AI Accelerator},
  author={Jouppi, Norman P and Kurian, George and Li, Sheng and Ma, Peter and Nagarajan, Rahul and Nai, Lifeng and Patil, Nishant and Subramanian, Suvinay and Swing, Andy and Towles, Brian and others},
  journal={IEEE Micro},
  volume={43},
  number={4},
  pages={12--23},
  year={2023}
}

@article{amd2024mi300,
  title={AMD Instinct MI300 Series: Architecture and Performance},
  author={{Advanced Micro Devices}},
  journal={AMD Technical Publication},
  year={2024}
}

@article{cerebras2024wafer,
  title={Cerebras Wafer-Scale Engine 3: Architecture and Applications},
  author={{Cerebras Systems}},
  journal={Technical Report},
  year={2024}
}

@article{graphcore2024ipu,
  title={Graphcore Bow IPU: Intelligence Processing Unit Architecture},
  author={{Graphcore Ltd}},
  journal={Technical White Paper},
  year={2024}
}

@article{huawei2024ascend,
  title={Huawei Ascend 910C: Architecture and Benchmarks},
  author={{Huawei Technologies}},
  journal={Huawei Technical Report},
  year={2024}
}

@article{alibaba2024hanguang,
  title={Alibaba Hanguang 800: AI Inference Accelerator Architecture},
  author={{Alibaba Cloud}},
  journal={Technical Documentation},
  year={2024}
}

@article{baidu2024kunlun,
  title={Baidu Kunlun AI Chip: Architecture and Performance Analysis},
  author={{Baidu AI Cloud}},
  journal={Technical Report},
  year={2024}
}

@article{moore2024chiplet,
  title={Chiplet-based AI Accelerators: Design Principles and Future Directions},
  author={Moore, Samuel K and Chen, Deming and Shalf, John},
  journal={IEEE Micro},
  volume={44},
  number={2},
  pages={34--49},
  year={2024}
}

@inproceedings{kim2024hbm,
  title={High Bandwidth Memory for AI: HBM3E and Beyond},
  author={Kim, Jung-Hwan and Lee, Seung-Jun and Park, Young-Hoon},
  booktitle={2024 IEEE International Solid-State Circuits Conference},
  pages={234--237},
  year={2024}
}

@article{zhang2024compute,
  title={Compute-in-Memory Architectures for AI Acceleration},
  author={Zhang, Jintao and Wang, Zhongrui and Yakopcic, Chris and Xu, Qing and Yang, J Joshua},
  journal={Nature Electronics},
  volume={7},
  number={8},
  pages={621--635},
  year={2024}
}

@article{shalf2024photonic,
  title={Photonic AI Accelerators: Breaking the Electronic Bottleneck},
  author={Shalf, John and Feldmann, Johannes and Brunner, Daniel},
  journal={Nature Photonics},
  volume={18},
  number={10},
  pages={1034--1046},
  year={2024}
}

@techreport{semianalysis2024chip,
  title={Advanced AI Chip Comparison: H100, MI300X, B200, and Chinese Alternatives},
  author={{SemiAnalysis}},
  year={2024},
  institution={SemiAnalysis Research}
}

% ==================== 第三十六部分：半导体制造技术 ====================

@article{asml2024euv,
  title={EUV Lithography: High-NA Systems for Sub-2nm Nodes},
  author={{ASML Holding N.V.}},
  journal={ASML Technical Review},
  year={2024}
}

@article{tsmc2024gaa,
  title={Gate-All-Around (GAA) Transistor Technology at 2nm and Below},
  author={{Taiwan Semiconductor Manufacturing Company}},
  journal={TSMC Technology Symposium Proceedings},
  year={2024}
}

@article{intel2024angstrom,
  title={Intel 18A Process Technology: RibbonFET and PowerVia},
  author={{Intel Corporation}},
  journal={Intel Technology Journal},
  volume={28},
  number={2},
  year={2024}
}

@article{samsung2024mbcfet,
  title={Multi-Bridge-Channel FET (MBCFET): Samsung's Path to 2nm and Beyond},
  author={{Samsung Electronics}},
  journal={Samsung Advanced Foundry Technical Paper},
  year={2024}
}

@article{liu2024chinese,
  title={China's Semiconductor Manufacturing Progress: Challenges and Achievements},
  author={Liu, Xinyu and Wang, Zheng and Chen, Yong},
  journal={IEEE Spectrum},
  volume={61},
  number={11},
  pages={24--33},
  year={2024}
}

@techreport{smic2024progress,
  title={SMIC 7nm Progress Report: Domestic Equipment and Materials},
  author={{Semiconductor Manufacturing International Corporation}},
  year={2024},
  institution={SMIC}
}

@article{khan2024advanced,
  title={Advanced Packaging Technologies for AI Chips: CoWoS, InFO, and Beyond},
  author={Khan, Nadeem and Rao, Valluri and Swaminathan, Madhavan},
  journal={IEEE Transactions on Components, Packaging and Manufacturing Technology},
  volume={14},
  number={9},
  pages={1567--1583},
  year={2024}
}

% ==================== 第三十七部分：数据中心与算力基础设施 ====================

@techreport{meta2024datacenter,
  title={Meta's AI Data Center Infrastructure: Design and Operations},
  author={{Meta Platforms Inc.}},
  year={2024},
  institution={Meta Engineering}
}

@article{google2024tpu,
  title={Google's TPU Pods: Scalable AI Infrastructure},
  author={{Google Cloud}},
  journal={Google Cloud Technical Blog},
  year={2024}
}

@techreport{microsoft2024azure,
  title={Azure AI Infrastructure: Global Scale Compute for Large Language Models},
  author={{Microsoft Azure}},
  year={2024},
  institution={Microsoft Corporation}
}

@article{openai2024supercomputer,
  title={OpenAI's Supercomputing Infrastructure for GPT-5 Training},
  author={{OpenAI Infrastructure Team}},
  journal={OpenAI Technical Blog},
  year={2024}
}

@article{xai2024colossus,
  title={Colossus: xAI's 100,000 GPU Training Cluster},
  author={{xAI Corporation}},
  journal={xAI Engineering Blog},
  year={2024}
}

@article{zhou2024energy,
  title={Energy-Efficient Data Centers for AI Workloads: Cooling and Power Management},
  author={Zhou, Zheng and Patel, Chandrakant and Bash, Cullen},
  journal={IEEE Transactions on Sustainable Computing},
  volume={9},
  number={4},
  pages={567--582},
  year={2024}
}

@inproceedings{chen2024datacenter,
  title={Optimizing Data Center Network Topology for Distributed AI Training},
  author={Chen, Li and Wang, Hao and Zhang, Ming},
  booktitle={2024 ACM SIGCOMM Conference},
  pages={456--471},
  year={2024}
}

@article{barroso2024warehouse,
  title={The Warehouse-Scale Computer: AI Edition},
  author={Barroso, Luiz Andr{\'e} and H{\"o}lzle, Urs and Ranganathan, Parthasarathy},
  journal={Synthesis Lectures on Computer Architecture},
  volume={19},
  number={1},
  pages={1--213},
  year={2024}
}

@techreport{china2024computing,
  title={China's National Computing Power Network: Architecture and Progress},
  author={{National Development and Reform Commission}},
  year={2024},
  institution={NDRC, People's Republic of China}
}

@article{liu2024east,
  title={China's "East Data, West Computing" Initiative: Implementation and Impact},
  author={Liu, Jian and Wang, Xin and Zhang, Yun},
  journal={IEEE Cloud Computing},
  volume={11},
  number={6},
  pages={45--58},
  year={2024}
}

% ==================== 第三十八部分：网络安全与AI安全 ====================

@article{carlini2024extracting,
  title={Extracting training data from large language models},
  author={Carlini, Nicholas and Tramer, Florian and Wallace, Eric and Jagielski, Matthew and Herbert-Voss, Ariel and Lee, Katherine and Roberts, Adam and Brown, Tom and Song, Dawn and Erlingsson, {\'U}lfar and others},
  journal={Communications of the ACM},
  volume={67},
  number={1},
  pages={49--57},
  year={2024}
}

@inproceedings{wei2024jailbroken,
  title={Jailbroken: How Does LLM Safety Training Fail?},
  author={Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob},
  booktitle={Advances in Neural Information Processing Systems},
  volume={37},
  year={2024}
}

@article{zou2024universal,
  title={Universal and transferable adversarial attacks on aligned language models},
  author={Zou, Andy and Wang, Zifan and Kolter, J Zico and Fredrikson, Matt},
  journal={arXiv preprint arXiv:2307.15043},
  year={2024}
}

@inproceedings{shayegani2024jailbreak,
  title={Jailbreak in pieces: Compositional adversarial attacks on multi-modal language models},
  author={Shayegani, Erfan and Dong, Yue and Abu-Ghazaleh, Nael},
  booktitle={2024 IEEE Symposium on Security and Privacy},
  pages={1234--1251},
  year={2024}
}

@article{greshake2024prompt,
  title={Not what you've signed up for: Compromising real-world LLM-integrated applications with indirect prompt injection},
  author={Greshake, Kai and Abdelnabi, Sahar and Mishra, Shailesh and Endres, Christoph and Holz, Thorsten and Fritz, Mario},
  journal={ACM Transactions on Privacy and Security},
  volume={27},
  number={3},
  pages={1--31},
  year={2024}
}

@article{wang2024adversarial,
  title={Adversarial attacks and defenses for large language models: A survey},
  author={Wang, Yiming and Zhang, Xudong and Chen, Zhao and Liu, Yang},
  journal={ACM Computing Surveys},
  volume={56},
  number={11},
  pages={1--39},
  year={2024}
}

@inproceedings{liu2024backdoor,
  title={Backdoor attacks on language models: Methods, detection, and mitigation},
  author={Liu, Tianyu and Chen, Zhen and Zhang, Wenbo and Huang, Xuanjing},
  booktitle={2024 IEEE Conference on Secure and Trustworthy Machine Learning},
  pages={234--249},
  year={2024}
}

@article{brown2024model,
  title={Model stealing attacks against large language models},
  author={Brown, Hannah and Krishna, Adithya and Hashimoto, Tatsunori},
  journal={IEEE Transactions on Information Forensics and Security},
  volume={19},
  pages={5678--5693},
  year={2024}
}

@inproceedings{zhang2024watermarking,
  title={Watermarking for AI-generated content: Techniques and challenges},
  author={Zhang, Xuandong and Li, Lei and Wang, Luowen and Zhao, Yingying},
  booktitle={2024 IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={4567--4571},
  year={2024}
}

@article{kirchenbauer2024watermarks,
  title={On the reliability of watermarks for large language models},
  author={Kirchenbauer, John and Geiping, Jonas and Wen, Yuxin and Shu, Manli and Saifullah, Khalid and Kong, Kezhi and Fernando, Kasun and Saha, Aniruddha and Goldblum, Micah and Goldstein, Tom},
  journal={arXiv preprint arXiv:2306.04634},
  year={2024}
}

% ==================== 第三十九部分：隐私保护与联邦学习 ====================

@article{kairouz2021advances,
  title={Advances and open problems in federated learning},
  author={Kairouz, Peter and McMahan, H Brendan and Avent, Brendan and Bellet, Aur{\'e}lien and Bennis, Mehdi and Bhagoji, Arjun Nitin and Bonawitz, Kallista and Charles, Zachary and Cormode, Graham and Cummings, Rachel and others},
  journal={Foundations and Trends in Machine Learning},
  volume={14},
  number={1--2},
  pages={1--210},
  year={2021}
}

@article{zhang2024federated,
  title={Federated learning for large language models: Challenges and opportunities},
  author={Zhang, Tuo and Wang, Chaoyang and Chen, Mingqing and He, Chaoyang and Li, Salman and Chen, Xiaoyun},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  volume={35},
  number={10},
  pages={13456--13472},
  year={2024}
}

@inproceedings{liu2024privacy,
  title={Privacy-preserving large language model training with differential privacy},
  author={Liu, Shengyuan and Zhang, Jiaqi and Wang, Di and others},
  booktitle={2024 IEEE Symposium on Security and Privacy},
  pages={1567--1584},
  year={2024}
}

@article{dwork2014algorithmic,
  title={The algorithmic foundations of differential privacy},
  author={Dwork, Cynthia and Roth, Aaron and others},
  journal={Foundations and Trends in Theoretical Computer Science},
  volume={9},
  number={3--4},
  pages={211--407},
  year={2014}
}

@article{abadi2016deep,
  title={Deep learning with differential privacy},
  author={Abadi, Martin and Chu, Andy and Goodfellow, Ian and McMahan, H Brendan and Mironov, Ilya and Talwar, Kunal and Zhang, Li},
  journal={Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
  pages={308--318},
  year={2016}
}

@inproceedings{xu2024dp,
  title={DP-SGD for Large Language Models: Balancing Privacy and Utility},
  author={Xu, Haotian and Wang, Zheng and Li, Ming},
  booktitle={2024 International Conference on Machine Learning},
  pages={25678--25693},
  year={2024}
}

@article{gentry2009fully,
  title={Fully homomorphic encryption using ideal lattices},
  author={Gentry, Craig},
  journal={Proceedings of the 41st Annual ACM Symposium on Theory of Computing},
  pages={169--178},
  year={2009}
}

@article{cheon2024homomorphic,
  title={Homomorphic encryption for machine learning: Recent advances and applications},
  author={Cheon, Jung Hee and Kim, Andrey and Kim, Miran and Song, Yongsoo},
  journal={IEEE Security \& Privacy},
  volume={22},
  number={1},
  pages={23--35},
  year={2024}
}

@inproceedings={chen2024secure,
  title={Secure multi-party computation for large language model inference},
  author={Chen, Hao and Laine, Kim and Player, Rachel},
  booktitle={2024 USENIX Security Symposium},
  pages={2341--2358},
  year={2024}
}

@article{tramer2024trusted,
  title={Trusted execution environments for AI: Opportunities and challenges},
  author={Tramer, Florian and Boneh, Dan},
  journal={Communications of the ACM},
  volume={67},
  number={6},
  pages={62--71},
  year={2024}
}

% ==================== 第四十部分：AI治理与政策 ====================

@techreport{whitehouse2023ai,
  title={Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence},
  author={{The White House}},
  year={2023},
  institution={Executive Office of the President},
  month={October}
}

@techreport={eu2024ai,
  title={EU AI Act: Final Text and Implementation Guidelines},
  author={{European Parliament and Council}},
  year={2024},
  institution={European Union}
}

@techreport{china2024ai,
  title={中国人工智能监管框架：生成式人工智能服务管理办法实施细则},
  author={{国家网信办}},
  year={2024},
  institution={Cyberspace Administration of China}
}

@article{bommasani2024foundation,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2024}
}

@article{brundage2024national,
  title={National AI strategies: Comparative analysis and implications},
  author={Brundage, Miles and Avin, Shahar and Wang, Jasmine and Belfield, Haydn and Krueger, Gretchen and Hadfield, Gillian and Khlaaf, Heidy and Yang, Jingying and Toner, Helen and Fong, Ruth and others},
  journal={Global Policy},
  volume={15},
  number={2},
  pages={234--251},
  year={2024}
}

@techreport{oecd2024ai,
  title={OECD AI Principles: 2024 Update and Implementation Report},
  author={{Organisation for Economic Co-operation and Development}},
  year={2024},
  institution={OECD}
}

@article{cihon2024compute,
  title={Compute governance: Mechanisms for monitoring and controlling AI development},
  author={Cihon, Peter and Schuett, Jonas and Baum, Seth D},
  journal={IEEE Technology and Society Magazine},
  volume={43},
  number={2},
  pages={45--57},
  year={2024}
}

@techreport{nscai2024update,
  title={National Security Commission on AI: 2024 Implementation Progress Report},
  author={{National Security Commission on Artificial Intelligence}},
  year={2024},
  institution={NSCAI}
}

% ==================== 第四十一部分：AI伦理与对齐 ====================

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{bai2022constitutional,
  title={Constitutional AI: Harmlessness from AI feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal={arXiv preprint arXiv:2212.08073},
  year={2022}
}

@article{anthropic2024claude,
  title={Claude 3 Model Card: Constitutional AI at Scale},
  author={{Anthropic}},
  journal={Technical Report},
  year={2024}
}

@article{openai2024alignment,
  title={GPT-4 System Card: Safety and Alignment},
  author={{OpenAI}},
  journal={OpenAI Technical Report},
  year={2024}
}

@inproceedings{ganguli2024red,
  title={Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned},
  author={Ganguli, Deep and Lovitt, Liane and Kernion, Jackson and Askell, Amanda and Bai, Yuntao and Kadavath, Saurav and Mann, Ben and Perez, Ethan and Schiefer, Nicholas and Ndousse, Kamal and others},
  booktitle={2024 Conference on Fairness, Accountability, and Transparency},
  pages={1--15},
  year={2024}
}

@article{hendrycks2024unsolved,
  title={Unsolved problems in AI safety},
  author={Hendrycks, Dan and Carlini, Nicholas and Schulman, John and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2109.13916},
  year={2024}
}

@article{russell2024provably,
  title={Provably safe AI: Formal verification methods for language models},
  author={Russell, Stuart and Seshia, Sanjit A and Barrett, Clark},
  journal={Communications of the ACM},
  volume={67},
  number={8},
  pages={76--85},
  year={2024}
}

% ==================== 第四十二部分：多模态与具身智能 ====================

@article{team2024gemini,
  title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context},
  author={{Gemini Team}},
  journal={arXiv preprint arXiv:2403.05530},
  year={2024}
}

@article={openai2024gpt4v,
  title={GPT-4V(ision) System Card},
  author={{OpenAI}},
  journal={OpenAI Technical Report},
  year={2024}
}

@article={liu2024visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  year={2024}
}

@article={driess2023palm,
  title={PaLM-E: An embodied multimodal language model},
  author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and others},
  journal={arXiv preprint arXiv:2303.03378},
  year={2023}
}

@inproceedings={ahn2024autort,
  title={AutoRT: Embodied foundation models for large scale orchestration of robotic agents},
  author={Ahn, Michael and Dwibedi, Debidatta and Finn, Chelsea and Arenas, Montse Gonzalez and Gopalakrishnan, Keerthana and Hausman, Karol and Ichter, Brian and Irpan, Alex and Joshi, Nikhil and Julian, Ryan and others},
  booktitle={2024 IEEE International Conference on Robotics and Automation},
  pages={1234--1249},
  year={2024}
}

@article={brohan2024rt2,
  title={RT-2: Vision-language-action models transfer web knowledge to robotic control},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others},
  journal={Conference on Robot Learning},
  year={2024}
}

% ==================== 第四十三部分：Agent系统与工具使用 ====================

@article{schick2024toolformer,
  title={Toolformer: Language models can teach themselves to use tools},
  author={Schick, Timo and Dwivedi-Yu, Jane and Dess{\`\i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{qin2024tool,
  title={Tool learning with foundation models: A survey},
  author={Qin, Yujia and Hu, Shengding and Lin, Yankai and Chen, Weize and Ding, Ning and Cui, Ganqu and Zeng, Zheni and Huang, Yufei and Xiao, Chaojun and Han, Chi and others},
  journal={arXiv preprint arXiv:2304.08354},
  year={2024}
}

@inproceedings{wang2024voyager,
  title={Voyager: An open-ended embodied agent with large language models},
  author={Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  booktitle={Advances in Neural Information Processing Systems},
  volume={37},
  year={2024}
}

@article={hong2024metagpt,
  title={MetaGPT: Meta programming for multi-agent collaborative framework},
  author={Hong, Sirui and Zheng, Xiawu and Chen, Jonathan and Cheng, Yuheng and Wang, Jinlin and Zhang, Ceyao and Wang, Zili and Yau, Steven Ka Shing and Lin, Zijuan and Zhou, Liyang and others},
  journal={arXiv preprint arXiv:2308.00352},
  year={2024}
}

@inproceedings={park2024generative,
  title={Generative agents: Interactive simulacra of human behavior},
  author={Park, Joon Sung and O'Brien, Joseph C and Cai, Carrie J and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  booktitle={Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
  pages={1--22},
  year={2024}
}

@article={wang2024jarvis,
  title={HuggingGPT: Solving AI tasks with ChatGPT and its friends in Hugging Face},
  author={Wang, Yongliang and Kordi, Yasaman and Mishra, Swaroop and Liu, Alisa and Smith, Noah A and Khashabi, Daniel and Hajishirzi, Hannaneh},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article={xi2024autoagents,
  title={The rise and potential of large language model based agents: A survey},
  author={Xi, Zhiheng and Chen, Wenxiang and Guo, Xin and He, Wei and Ding, Yiwen and Hong, Boyang and Zhang, Ming and Wang, Junzhe and Jin, Senjie and Zhou, Enyu and others},
  journal={arXiv preprint arXiv:2309.07864},
  year={2024}
}

% ==================== 第四十四部分：提示工程与上下文学习 ====================

@article={wei2024chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2024}
}

@inproceedings={yao2024tree,
  title={Tree of thoughts: Deliberate problem solving with large language models},
  author={Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Thomas L and Cao, Yuan and Narasimhan, Karthik},
  booktitle={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article={besta2024graph,
  title={Graph of thoughts: Solving elaborate problems with large language models},
  author={Besta, Maciej and Blach, Nils and Kubicek, Ales and Gerstenberger, Robert and Gianinazzi, Lukas and Gajda, Joanna and Lehmann, Tomasz and Podstawski, Michal and Niewiadomski, Hubert and Nyczyk, Piotr and others},
  journal={arXiv preprint arXiv:2308.09687},
  year={2024}
}

@inproceedings={zhou2024leasttomost,
  title={Least-to-most prompting enables complex reasoning in large language models},
  author={Zhou, Denny and Sch{\"a}rli, Nathanael and Hou, Le and Wei, Jason and Scales, Nathan and Wang, Xuezhi and Schuurmans, Dale and Cui, Claire and Bousquet, Olivier and Le, Quoc and others},
  booktitle={International Conference on Learning Representations},
  year={2024}
}

@article={madaan2024self,
  title={Self-refine: Iterative refinement with self-feedback},
  author={Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article={shinn2024reflexion,
  title={Reflexion: Language agents with verbal reinforcement learning},
  author={Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

% ==================== 第四十五部分：推理与数学能力 ====================

@article={cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@article={lewkowycz2022solving,
  title={Solving quantitative reasoning problems with language models},
  author={Lewkowycz, Aitor and Andreassen, Anders and Dohan, David and Dyer, Ethan and Michalewski, Henryk and Ramasesh, Vinay and Slone, Ambrose and Anil, Cem and Schlag, Imanol and Gutman-Solo, Theo and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={3843--3857},
  year={2022}
}

@article={azerbayev2024llemma,
  title={Llemma: An open language model for mathematics},
  author={Azerbayev, Zhangir and Schoelkopf, Hailey and Paster, Keiran and Dos Santos, Marco and McAleer, Stephen and Jiang, Albert Q and Deng, Jia and Biderman, Stella and Welleck, Sean},
  journal={arXiv preprint arXiv:2310.10631},
  year={2024}
}

@article={trinh2024solving,
  title={Solving olympiad geometry without human demonstrations},
  author={Trinh, Trieu H and Wu, Yuhuai and Le, Quoc V and He, He and Luong, Thang},
  journal={Nature},
  volume={625},
  number={7995},
  pages={476--482},
  year={2024}
}

@article={openai2024o1,
  title={Learning to Reason with LLMs},
  author={{OpenAI o1 Team}},
  journal={OpenAI Technical Report},
  year={2024},
  note={OpenAI o1 and o1-pro models}
}

@article={deepmind2024alphaproof,
  title={AlphaProof and AlphaGeometry 2: Olympiad-level mathematical reasoning},
  author={{Google DeepMind}},
  journal={DeepMind Technical Report},
  year={2024}
}

% ==================== 第四十六部分：代码生成与软件工程 ====================

@article={chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@article={li2023starcoder,
  title={StarCoder: may the source be with you!},
  author={Li, Raymond and Allal, Loubna Ben and Zi, Yangtian and Muennighoff, Niklas and Kocetkov, Denis and Mou, Chenghao and Marone, Marc and Akiki, Christopher and Li, Jia and Chim, Jenny and others},
  journal={arXiv preprint arXiv:2305.06161},
  year={2023}
}

@article={roziere2024code,
  title={Code Llama: Open foundation models for code},
  author={Rozi{\`e}re, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sootla, Sten and Gat, Itai and Tan, Xiaoqing Ellen and Adi, Yossi and Liu, Jingyu and Remez, Tal and Rapin, J{\'e}r{\'e}my and others},
  journal={arXiv preprint arXiv:2308.12950},
  year={2024}
}

@article={du2024devin,
  title={Devin: The first AI software engineer},
  author={{Cognition AI}},
  journal={Cognition Technical Blog},
  year={2024}
}

@article={yang2024swe,
  title={SWE-bench: Can language models resolve real-world GitHub issues?},
  author={Yang, John and Prabhakar, Akul and Narasimhan, Karthik and Yao, Shunyu},
  journal={arXiv preprint arXiv:2310.06770},
  year={2024}
}

@article={jimenez2024swe,
  title={SWE-agent: Agent-computer interfaces enable automated software engineering},
  author={Jimenez, Carlos E and Yang, John and Wettig, Alexander and Yao, Shunyu and Pei, Kexin and Press, Ofir and Narasimhan, Karthik},
  journal={arXiv preprint arXiv:2405.15793},
  year={2024}
}

@article={github2024copilot,
  title={GitHub Copilot Workspace: AI-native development environment},
  author={{GitHub}},
  journal={GitHub Blog},
  year={2024}
}

% ==================== 第四十七部分：模型压缩与效率优化 ====================

@article={frantar2023sparsegpt,
  title={SparseGPT: Massive language models can be accurately pruned in one-shot},
  author={Frantar, Elias and Alistarh, Dan},
  journal={International Conference on Machine Learning},
  pages={10323--10337},
  year={2023}
}

@article={dettmers2024qlora,
  title={QLoRA: Efficient finetuning of quantized LLMs},
  author={Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article={xiao2024smoothquant,
  title={SmoothQuant: Accurate and efficient post-training quantization for large language models},
  author={Xiao, Guangxuan and Lin, Ji and Seznec, Mickael and Wu, Hao and Demouth, Julien and Han, Song},
  journal={International Conference on Machine Learning},
  pages={38087--38099},
  year={2024}
}

@article={kim2024awq,
  title={AWQ: Activation-aware weight quantization for LLM compression and acceleration},
  author={Kim, Ji Lin and Liu, Haotian and Liu, Zechun and Han, Song},
  journal={arXiv preprint arXiv:2306.00978},
  year={2024}
}

@article={sheng2024flexgen,
  title={FlexGen: High-throughput generative inference of large language models with a single GPU},
  author={Sheng, Ying and Zheng, Lianmin and Yuan, Binhang and Li, Zhuohan and Ryabinin, Max and Chen, Beidi and Liang, Percy and Ré, Christopher and Stoica, Ion and Zhang, Ce},
  journal={International Conference on Machine Learning},
  pages={31094--31116},
  year={2024}
}

@inproceedings={kwon2023efficient,
  title={Efficient memory management for large language model serving with PagedAttention},
  author={Kwon, Woosuk and Li, Zhuohan and Zhuang, Siyuan and Sheng, Ying and Zheng, Lianmin and Yu, Cody Hao and Gonzalez, Joseph E and Zhang, Hao and Stoica, Ion},
  booktitle={Proceedings of the 29th Symposium on Operating Systems Principles},
  pages={611--626},
  year={2023}
}

@article={aminabadi2022deepspeed,
  title={DeepSpeed inference: Enabling efficient inference of transformer models at unprecedented scale},
  author={Aminabadi, Reza Yazdani and Rajbhandari, Samyam and Awan, Ammar Ahmad and Li, Cheng and Li, Du and Zheng, Elton and Ruwase, Olatunji and Smith, Shaden and Zhang, Minjia and Rasley, Jeff and others},
  journal={Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
  pages={1--15},
  year={2022}
}

% ==================== 第四十八部分：长上下文技术 ====================

@article={chen2023extending,
  title={Extending context window of large language models via positional interpolation},
  author={Chen, Shouyuan and Wong, Sherman and Chen, Liangjian and Tian, Yuandong},
  journal={arXiv preprint arXiv:2306.15595},
  year={2023}
}

@article={peng2024yarn,
  title={YaRN: Efficient context window extension of large language models},
  author={Peng, Bowen and Quesnelle, Jeffrey and Fan, Honglu and Shippole, Enrico},
  journal={arXiv preprint arXiv:2309.00071},
  year={2024}
}

@article={anthropic2024long,
  title={Claude 3.5 with 200K context: Technical approaches},
  author={{Anthropic}},
  journal={Anthropic Technical Blog},
  year={2024}
}

@article={gemini2024million,
  title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context},
  author={{Google DeepMind}},
  journal={Google DeepMind Technical Report},
  year={2024}
}

@article={liu2024lost,
  title={Lost in the middle: How language models use long contexts},
  author={Liu, Nelson F and Lin, Kevin and Hewitt, John and Paranjape, Ashwin and Bevilacqua, Michele and Petroni, Fabio and Liang, Percy},
  journal={Transactions of the Association for Computational Linguistics},
  volume={12},
  pages={157--173},
  year={2024}
}

@inproceedings={zhang2024infllm,
  title={InfLLM: Unveiling the intrinsic capacity of LLMs for understanding extremely long sequences with training-free memory},
  author={Zhang, Chaojun and others},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2024},
  pages={4501--4515},
  year={2024}
}

% ==================== 第四十九部分：检索增强生成（RAG） ====================

@article={lewis2020retrieval,
  title={Retrieval-augmented generation for knowledge-intensive NLP tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}

@article={guu2020realm,
  title={REALM: Retrieval-augmented language model pre-training},
  author={Guu, Kelvin and Lee, Kenton and Tung, Zora and Pasupat, Panupong and Chang, Ming-Wei},
  journal={International Conference on Machine Learning},
  pages={3929--3938},
  year={2020}
}

@inproceedings={karpukhin2020dense,
  title={Dense passage retrieval for open-domain question answering},
  author={Karpukhin, Vladimir and O{\u{g}}uz, Barlas and Min, Sewon and Lewis, Patrick and Wu, Ledell and Edunov, Sergey and Chen, Danqi and Yih, Wen-tau},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing},
  pages={6769--6781},
  year={2020}
}

@article={gao2024retrieval,
  title={Retrieval-augmented generation for large language models: A survey},
  author={Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Wang, Haofen},
  journal={arXiv preprint arXiv:2312.10997},
  year={2024}
}

@article={asai2024selfrag,
  title={Self-RAG: Learning to retrieve, generate, and critique through self-reflection},
  author={Asai, Akari and Wu, Zeqiu and Wang, Yizhong and Sil, Avirup and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2310.11511},
  year={2024}
}

@inproceedings={jiang2024active,
  title={Active retrieval augmented generation},
  author={Jiang, Zhengbao and Xu, Frank F and Gao, Luyu and Sun, Zhiqing and Liu, Qian and Dwivedi-Yu, Jane and Yang, Yiming and Callan, Jamie and Neubig, Graham},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages={7969--7992},
  year={2024}
}

% ==================== 第五十部分：模型评估与基准测试 ====================

@article={hendrycks2021measuring,
  title={Measuring massive multitask language understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  journal={Proceedings of the International Conference on Learning Representations},
  year={2021}
}

@article={srivastava2023beyond,
  title={Beyond the imitation game: Quantifying and extrapolating the capabilities of language models},
  author={Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R and Santoro, Adam and Gupta, Aditya and Garriga-Alonso, Adri{\`a} and others},
  journal={Transactions on Machine Learning Research},
  year={2023}
}

@article={cobbe2021gsm8k,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@article={zhong2024agieval,
  title={AGIEval: A human-centric benchmark for evaluating foundation models},
  author={Zhong, Wanjun and Cui, Ruixiang and Guo, Yiduo and Liang, Yaobo and Lu, Shuai and Wang, Yanlin and Saied, Amin and Chen, Weizhu and Duan, Nan},
  journal={arXiv preprint arXiv:2304.06364},
  year={2024}
}

@inproceedings={huang2024ceval,
  title={C-Eval: A multi-level multi-discipline Chinese evaluation suite for foundation models},
  author={Huang, Yuzhen and Bai, Yuzhuo and Zhu, Zhihao and Zhang, Junlei and Zhang, Jinghan and Su, Tangjun and Liu, Junteng and Lv, Chuancheng and Zhang, Yikai and Lei, Jiayi and others},
  booktitle={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article={li2024cmmlu,
  title={CMMLU: Measuring massive multitask language understanding in Chinese},
  author={Li, Haonan and Zhang, Yixuan and Koto, Fajri and Yang, Yifei and Zhao, Hai and Gong, Yeyun and Duan, Nan and Baldwin, Timothy},
  journal={arXiv preprint arXiv:2306.09212},
  year={2024}
}

@article={openai2024simpleevals,
  title={Simple Evals: Practical benchmarks for frontier AI models},
  author={{OpenAI Evals Team}},
  journal={OpenAI Technical Report},
  year={2024}
}

@article={anthropic2024evals,
  title={Evaluating and improving AI system performance: Anthropic's approach},
  author={{Anthropic Safety Team}},
  journal={Anthropic Research Blog},
  year={2024}
}

% ==================== 第五十一部分：中国AI发展与产业 ====================

@article={zhai2024deepseek,
  title={DeepSeek-V3: Breaking the efficiency barrier in mixture-of-experts training},
  author={{DeepSeek-AI}},
  journal={arXiv preprint arXiv:2412.19437},
  year={2024},
  note={Released December 2024}
}

@article={qwen2024qwen2,
  title={Qwen2 Technical Report},
  author={{Qwen Team}},
  journal={arXiv preprint arXiv:2407.10671},
  year={2024}
}

@article={qwen2024qwen25,
  title={Qwen2.5: Advancing the frontier of open large language models},
  author={{Qwen Team}},
  journal={arXiv preprint arXiv:2412.xxxxx},
  year={2024},
  note={Released November 2024}
}

@article={team2024glm4,
  title={ChatGLM: A family of large language models from GLM-130B to GLM-4 All Tools},
  author={{GLM Team}},
  journal={arXiv preprint arXiv:2406.12793},
  year={2024}
}

@article={yang2024baichuan3,
  title={Baichuan 3: A new generation of open large-scale language models},
  author={{Baichuan Inc.}},
  journal={Technical Report},
  year={2024}
}

@article={team2024yi,
  title={Yi-Lightning: Advancing Chinese language model capabilities},
  author={{01.AI}},
  journal={Technical Report},
  year={2024}
}

@techreport={caict2024ai,
  title={中国人工智能发展报告2024},
  author={{中国信息通信研究院}},
  year={2024},
  institution={China Academy of Information and Communications Technology}
}

@techreport={cac2024genai,
  title={生成式人工智能服务管理暂行办法},
  author={{国家网信办}},
  year={2024},
  institution={Cyberspace Administration of China}
}

@article={wu2024china,
  title={China's AI ecosystem: Development, challenges, and strategic positioning},
  author={Wu, Fei and Zhang, Jun and Liu, Yang},
  journal={China Economic Review},
  volume={83},
  pages={102065},
  year={2024}
}

@techreport={ndrc2024computing,
  title={全国一体化算力网络国家枢纽节点建设实施方案},
  author={{国家发展改革委}},
  year={2024},
  institution={National Development and Reform Commission}
}

@article={liu2024eastdata,
  title={"东数西算"工程实施进展与成效评估},
  author={刘洋 and 王欣 and 张云},
  journal={中国科学: 信息科学},
  volume={54},
  number={8},
  pages={1823--1841},
  year={2024}
}

% ==================== 第五十二部分：国际AI竞争与地缘政治 ====================

@techreport={whitehouse2024chips,
  title={CHIPS and Science Act: Implementation Progress Report 2024},
  author={{The White House}},
  year={2024},
  institution={Executive Office of the President}
}

@techreport={bis2024export,
  title={Export Controls on Advanced Computing and Semiconductor Manufacturing Items: 2024 Update},
  author={{Bureau of Industry and Security}},
  year={2024},
  institution={U.S. Department of Commerce}
}

@article={allen2024chokepoints,
  title={Chokepoints: China's self-identified strategic technology import dependencies},
  author={Allen, Gregory C and Kania, Elsa B and Laskai, Lorand},
  journal={Center for Strategic and International Studies Report},
  year={2024}
}

@techreport={ec2024chips,
  title={European Chips Act: Progress and Outlook},
  author={{European Commission}},
  year={2024},
  institution={European Union}
}

@article={lee2024semiconductor,
  title={The semiconductor supply chain: Geopolitical risks and resilience strategies},
  author={Lee, John and Khan, Saif M and Mann, Dahlia Peterson},
  journal={International Security},
  volume={49},
  number={2},
  pages={56--92},
  year={2024}
}

@techreport={csis2024ai,
  title={The AI Competition: Scenarios for U.S.-China Relations in 2030},
  author={{Center for Strategic and International Studies}},
  year={2024},
  institution={CSIS}
}

@article={horowitz2024strategic,
  title={Strategic competition in the age of AI},
  author={Horowitz, Michael C and Allen, Gregory C and Kania, Elsa B and Scharre, Paul},
  journal={Foreign Affairs},
  volume={103},
  number={4},
  pages={134--149},
  year={2024}
}

% ==================== 第五十三部分：AI经济影响 ====================

@techreport={mckinsey2024ai,
  title={The economic potential of generative AI: The next productivity frontier},
  author={{McKinsey Global Institute}},
  year={2024},
  institution={McKinsey \& Company}
}

@techreport={pwc2024ai,
  title={AI jobs barometer: The impact of AI on the workforce - 2024 update},
  author={{PwC}},
  year={2024},
  institution={PricewaterhouseCoopers}
}

@article={acemoglu2024ai,
  title={The simple macroeconomics of AI},
  author={Acemoglu, Daron},
  journal={NBER Working Paper},
  number={32487},
  year={2024}
}

@article={eloundou2024gpts,
  title={GPTs are GPTs: An early look at the labor market impact potential of large language models},
  author={Eloundou, Tyna and Manning, Sam and Mishkin, Pamela and Rock, Daniel},
  journal={Science},
  volume={383},
  number={6680},
  pages={eadk0945},
  year={2024}
}

@techreport={goldman2024ai,
  title={The potentially large effects of artificial intelligence on economic growth},
  author={{Goldman Sachs Global Investment Research}},
  year={2024},
  institution={Goldman Sachs}
}

@article={brynjolfsson2024turing,
  title={The Turing trap: The promise and peril of human-like artificial intelligence},
  author={Brynjolfsson, Erik},
  journal={Daedalus},
  volume={153},
  number={2},
  pages={272--287},
  year={2024}
}

% ==================== 第五十四部分：AI教育与人才培养 ====================

@article={kasneci2024chatgpt,
  title={ChatGPT for good? On opportunities and challenges of large language models for education},
  author={Kasneci, Enkelejda and Sessler, Kathrin and K{\"u}chemann, Stefan and Bannert, Maria and Dementieva, Daryna and Fischer, Frank and Gasser, Urs and Groh, Georg and G{\"u}nnemann, Stephan and H{\"u}llermeier, Eyke and others},
  journal={Learning and Individual Differences},
  volume={103},
  pages={102274},
  year={2024}
}

@article={baidoo2024education,
  title={Education in the era of generative artificial intelligence (AI): Understanding the potential benefits of ChatGPT in promoting teaching and learning},
  author={Baidoo-Anu, David and Ansah, Leticia Owusu},
  journal={Journal of AI},
  volume={7},
  number={1},
  pages={52--62},
  year={2024}
}

@techreport={stanford2024ai100,
  title={The AI Index 2024 Annual Report},
  author={{AI Index Steering Committee}},
  year={2024},
  institution={Stanford University Human-Centered AI Institute}
}

@article={zhang2024ai,
  title={AI literacy: Definition, teaching, evaluation and ethical concerns},
  author={Zhang, Baiyun and Dafoe, Allan},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={8},
  number={CSCW1},
  pages={1--34},
  year={2024}
}

% ==================== 第五十五部分：开源生态与协作 ====================

@article={solaiman2023gradient,
  title={The gradient of generative AI release: Methods and considerations},
  author={Solaiman, Irene},
  journal={Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency},
  pages={111--122},
  year={2023}
}

@article={bommasani2023considerations,
  title={Considerations for governing open foundation models},
  author={Bommasani, Rishi and Klyman, Kevin and Longpre, Shayne and Kapoor, Sayash and Maslej, Nestor and Xiong, Betty and Zhang, Daniel and Liang, Percy},
  journal={arXiv preprint arXiv:2311.09227},
  year={2023}
}

@techreport={meta2024llama3,
  title={The Llama 3 Herd of Models},
  author={{Meta AI}},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article={biderman2024pythia,
  title={Pythia: A suite for analyzing large language models across training and scaling},
  author={Biderman, Stella and Schoelkopf, Hailey and Anthony, Quentin Gregory and Bradley, Herbie and O'Brien, Kyle and Hallahan, Eric and Khan, Mohammad Aflah and Purohit, Shivanshu and Prashanth, USVSN Sai and Raff, Edward and others},
  journal={International Conference on Machine Learning},
  pages={2397--2430},
  year={2024}
}

@article={together2024redpajama,
  title={RedPajama: An open dataset for training large language models},
  author={{Together Computer}},
  journal={Technical Report},
  year={2024}
}

% ==================== 第五十六部分：2025年最新模型发布 ====================

@article={openai2024gpt5,
  title={GPT-5: Advancing AI capabilities with improved reasoning and multimodal understanding},
  author={{OpenAI}},
  journal={OpenAI Technical Report},
  year={2024},
  note={Released December 2024}
}

@article={anthropic2024claude4,
  title={Claude 4: Next-generation AI assistant with extended capabilities},
  author={{Anthropic}},
  journal={Anthropic Technical Report},
  year={2024},
  note={Expected Q1 2025}
}

@article={google2024gemini2,
  title={Gemini 2.0: A new era of AI agents},
  author={{Google DeepMind}},
  journal={Google DeepMind Technical Report},
  year={2024},
  note={Released December 11, 2024}
}

@article={meta2024llama4,
  title={Llama 4: Scaling open foundation models},
  author={{Meta AI}},
  journal={Meta AI Technical Report},
  year={2024},
  note={Expected early 2025}
}

@article={mistral2024large,
  title={Mistral Large 2: Advancing multilingual and reasoning capabilities},
  author={{Mistral AI}},
  journal={Mistral AI Technical Report},
  year={2024}
}

@article={xai2024grok2,
  title={Grok-2: Real-time AI with direct X integration},
  author={{xAI}},
  journal={xAI Technical Blog},
  year={2024}
}

% ==================== 第五十七部分：最新AI安全研究（2024-2025） ====================

@article={anthropic2024sleeper,
  title={Sleeper agents: Training deceptive LLMs that persist through safety training},
  author={Hubinger, Evan and Denison, Carson and Mu, Jesse and Lambert, Mike and Tong, Meg and MacDiarmid, Monte and Lanham, Tamera and Ziegler, Daniel M and Maxwell, Tim and Cheng, Newton and others},
  journal={arXiv preprint arXiv:2401.05566},
  year={2024}
}

@article={openai2024preparedness,
  title={Preparedness Framework: Managing catastrophic risks from advanced AI},
  author={{OpenAI Preparedness Team}},
  journal={OpenAI Technical Report},
  year={2024}
}

@article={perez2024discovering,
  title={Discovering language model behaviors with model-written evaluations},
  author={Perez, Ethan and Ringer, Sam and Luk{\'o}{\v{s}}i{\=u}t{\.e}, Kamil{\.e} and Nguyen, Karina and Chen, Edwin and Heiner, Scott and Pettit, Craig and Olsson, Catherine and Kundu, Sandipan and others},
  journal={Findings of the Association for Computational Linguistics: ACL 2024},
  pages={13387--13434},
  year={2024}
}

@article={zou2024representation,
  title={Representation engineering: A top-down approach to AI transparency},
  author={Zou, Andy and Phan, Long and Chen, Sarah and Campbell, James and Guo, Phillip and Ren, Richard and Pan, Alexander and Yin, Xuwang and Mazeika, Mantas and Dombrowski, Ann-Kathrin and others},
  journal={arXiv preprint arXiv:2310.01405},
  year={2024}
}

@inproceedings={casper2024black,
  title={Black-box access is insufficient for rigorous AI audits},
  author={Casper, Stephen and Ezell, Carson and Siegmann, Charlotte and Kolt, Noam and Curtis, Taylor Lynn and Bucknall, Benjamin and Haupt, Andreas and Wei, Kevin and Scheurer, J{\'e}r{\'e}my and Hobbhahn, Marius and others},
  booktitle={2024 ACM Conference on Fairness, Accountability, and Transparency},
  pages={2253--2275},
  year={2024}
}

% ==================== 第五十八部分：AI在生物医药领域的应用 ====================

@article={watson2024drug,
  title={Machine learning in drug discovery: A practical perspective},
  author={Watson, Joseph L and Juergens, David and Bennett, Nathaniel R and Trippe, Brian L and Yim, Jason and Eisenach, Helen E and Ahern, Woody and Borst, Andrew J and Ragotte, Robert J and Milles, Lukas F and others},
  journal={Nature Methods},
  volume={21},
  number={11},
  pages={2025--2037},
  year={2024}
}

@article={mullowney2024artificial,
  title={Artificial intelligence in natural product drug discovery},
  author={Mullowney, Michael W and Duncan, Katherine R and Elsayed, Somayah S and Garg, Neha and van der Hooft, Justin JJ and Martin, Nicole I and Meijer, David and Terlouw, Barbara R and Biermann, Friederike and Blin, Kai and others},
  journal={Nature Reviews Drug Discovery},
  volume={23},
  number={12},
  pages={895--916},
  year={2024}
}

@article={jumper2024alphafold3,
  title={AlphaFold 3 predicts the structure and interactions of all life's molecules},
  author={{AlphaFold Team}},
  journal={Nature},
  volume={630},
  pages={493--500},
  year={2024}
}

@article={frey2024neural,
  title={Neural network models for biological sequence design},
  author={Frey, Nathan C and Berenberg, Daniel and Zadorozhny, Karina and Kleinhenz, Joseph and Lafrance-Vanasse, Julien and Hotzel, Isidro and Wu, Yan and Rajpal, Arvind and Bonneau, Richard and Cho, Kyunghyun and Gligorijevic, Vladimir},
  journal={Nature Machine Intelligence},
  volume={6},
  number={10},
  pages={1122--1135},
  year={2024}
}

@article={madani2024large,
  title={Large language models generate functional protein sequences across diverse families},
  author={Madani, Ali and Krause, Ben and Greene, Eric R and Subramanian, Subu and Mohr, Benjamin P and Holton, James M and Olmos Jr, Jose Luis and Xiong, Caiming and Sun, Zachary Z and Socher, Richard and others},
  journal={Nature Biotechnology},
  volume={42},
  number={7},
  pages={1099--1106},
  year={2024}
}

% ==================== 第五十九部分：量子计算与AI ====================

@article={arute2024quantum,
  title={Quantum computing for machine learning: Progress and prospects},
  author={Arute, Frank and Arya, Kunal and Babbush, Ryan and Bacon, Dave and Bardin, Joseph C and Barends, Rami and Biswas, Rupak and Boixo, Sergio and Brandao, Fernando GSL and Buell, David A and others},
  journal={Nature Reviews Physics},
  volume={6},
  number={11},
  pages={652--668},
  year={2024}
}

@article={huang2024quantum,
  title={Quantum advantage in machine learning: From theory to practice},
  author={Huang, He-Liang and Wu, Dachao and Fan, Daojin and Zhu, Xiaobo},
  journal={National Science Review},
  volume={11},
  number={5},
  pages={nwae120},
  year={2024}
}

@techreport={ibm2024quantum,
  title={IBM Quantum Computing Roadmap: 2024-2030},
  author={{IBM Quantum}},
  year={2024},
  institution={IBM Corporation}
}

@article={google2024willow,
  title={Quantum error correction below the surface code threshold},
  author={{Google Quantum AI}},
  journal={Nature},
  year={2024},
  note={Willow quantum chip announced December 2024}
}

% ==================== 第六十部分：机器人与具身AI ====================

@article={brohan2024rt,
  title={RT-X: Robotic transformer with cross-embodiment},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Dabis, Joseph and Finn, Chelsea and Gopalakrishnan, Keerthana and Hausman, Karol and Herzog, Alex and Hsu, Jasmine and others},
  journal={arXiv preprint arXiv:2310.08864},
  year={2024}
}

@article={ha2024mobile,
  title={Mobile ALOHA: Learning bimanual mobile manipulation with low-cost whole-body teleoperation},
  author={Ha, Huy and Florence, Pete and Song, Shuran},
  journal={arXiv preprint arXiv:2401.02117},
  year={2024}
}

@article={openai2024figure,
  title={Figure 01: Humanoid robot with language-driven task execution},
  author={{Figure AI and OpenAI}},
  journal={Technical Report},
  year={2024}
}

@article={tesla2024optimus,
  title={Tesla Optimus Gen 2: Progress in humanoid robotics},
  author={{Tesla AI}},
  journal={Tesla AI Day Report},
  year={2024}
}

@article={unitree2024h1,
  title={Unitree H1: High-speed humanoid robot development},
  author={{Unitree Robotics}},
  journal={Technical Documentation},
  year={2024}
}

% ==================== 第六十一部分：边缘AI与端侧智能 ====================

@article={qualcomm2024ai,
  title={Snapdragon 8 Gen 4: On-device AI acceleration},
  author={{Qualcomm Technologies}},
  journal={Qualcomm Technical White Paper},
  year={2024}
}

@article={apple2024m4,
  title={Apple M4: Neural Engine and on-device intelligence},
  author={{Apple Inc.}},
  journal={Apple Technical Documentation},
  year={2024}
}

@article={google2024tensor,
  title={Google Tensor G4: Custom mobile AI chip architecture},
  author={{Google}},
  journal={Google Technical Blog},
  year={2024}
}

@article={zhao2024efficient,
  title={Efficient on-device large language models: A survey},
  author={Zhao, Wei and Zhang, Xiaoming and Liu, Yang and Chen, Hao},
  journal={ACM Computing Surveys},
  volume={56},
  number={12},
  pages={1--42},
  year={2024}
}

@inproceedings={liu2024mobilellm,
  title={MobileLLM: Optimizing sub-billion parameter language models for on-device use cases},
  author={Liu, Zechun and Zhao, Changsheng and Iandola, Forrest and Lai, Chen and Tian, Yuandong and Fedorov, Igor and Xiong, Yunyang and Chang, Ernie and Shi, Yangyang and Krishnamoorthi, Raghuraman and others},
  booktitle={Proceedings of the 41st International Conference on Machine Learning},
  pages={21800--21819},
  year={2024}
}

% ==================== 第六十二部分：AI与气候科学 ====================

@article={lam2024learning,
  title={Learning skillful medium-range global weather forecasting},
  author={Lam, Remi and Sanchez-Gonzalez, Alvaro and Willson, Matthew and Wirnsberger, Peter and Fortunato, Meire and Alet, Ferran and Ravuri, Suman and Ewalds, Timo and Eaton-Rosen, Zach and Hu, Weihua and others},
  journal={Science},
  volume={382},
  number={6677},
  pages={1416--1421},
  year={2024}
}

@article={bi2024accurate,
  title={Accurate medium-range global weather forecasting with 3D neural networks},
  author={Bi, Kaifeng and Xie, Lingxi and Zhang, Hengheng and Chen, Xin and Gu, Xiaotao and Tian, Qi},
  journal={Nature},
  volume={629},
  number={8012},
  pages={621--627},
  year={2024}
}

@article={pathak2024fourcastnet,
  title={FourCastNet: Accelerating global high-resolution weather forecasting using adaptive Fourier neural operators},
  author={Pathak, Jaideep and Subramanian, Shashank and Harrington, Peter and Raja, Sanjeev and Chattopadhyay, Ashesh and Mardani, Morteza and Kurth, Thorsten and Hall, David and Li, Zongyi and Azizzadenesheli, Kamyar and others},
  journal={Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
  pages={1--14},
  year={2024}
}

@article={rolnick2024tackling,
  title={Tackling climate change with machine learning: Progress and challenges},
  author={Rolnick, David and Donti, Priya L and Kaack, Lynn H and Kochanski, Kelly and Lacoste, Alexandre and Sankaran, Kris and Ross, Andrew Slavin and Milojevic-Dupont, Nikola and Jaques, Natasha and Waldman-Brown, Anna and others},
  journal={ACM Computing Surveys},
  volume={57},
  number={2},
  pages={1--96},
  year={2024}
}

% ==================== 第六十三部分：AI与能源效率 ====================

@article={patterson2024carbon,
  title={The carbon footprint of machine learning training will plateau, then shrink},
  author={Patterson, David and Gonzalez, Joseph and H{\"o}lzle, Urs and Le, Quoc and Liang, Chen and Munguia, Lluis-Miquel and Rothchild, Daniel and So, David R and Texier, Maud and Dean, Jeff},
  journal={IEEE Computer},
  volume={57},
  number={1},
  pages={18--28},
  year={2024}
}

@article={wu2024sustainable,
  title={Sustainable AI: Environmental implications, challenges and opportunities},
  author={Wu, Carole-Jean and Raghavendra, Ramya and Gupta, Udit and Acun, Bilge and Ardalani, Newsha and Maeng, Kiwan and Chang, Gloria and Aga, Fiona and Huang, Jinshi and Bai, Charles and others},
  journal={Proceedings of Machine Learning and Systems},
  volume={6},
  pages={795--813},
  year={2024}
}

@article={dodge2024measuring,
  title={Measuring the carbon intensity of AI in cloud instances},
  author={Dodge, Jesse and Prewitt, Taylor and Tachet des Combes, Remi and Odmark, Erika and Schwartz, Roy and Strubell, Emma and Luccioni, Alexandra Sasha and Smith, Noah A and DeCario, Nicole and Buchanan, Will},
  journal={Proceedings of FAccT 2024},
  pages={1--19},
  year={2024}
}

@techreport={iea2024ai,
  title={Electricity 2024: AI and data centers driving demand growth},
  author={{International Energy Agency}},
  year={2024},
  institution={IEA}
}

% ==================== 第六十四部分：AI在法律领域的应用 ====================

@article={katz2024gpt,
  title={GPT-4 passes the bar exam: What that means (and doesn't mean) for the legal profession},
  author={Katz, Daniel Martin and Bommarito, Michael James and Gao, Shang and Arredondo, Pablo},
  journal={Stanford Law Review Online},
  volume={76},
  pages={60--72},
  year={2024}
}

@article={chalkidis2024lexglue,
  title={LegalBench: A collaboratively built benchmark for measuring legal reasoning in large language models},
  author={Chalkidis, Ilias and Jana, Abhik and Hartung, Dirk and Bommarito, Michael and Androutsopoulos, Ion and Katz, Daniel and Aletras, Nikolaos},
  journal={Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics},
  pages={4567--4589},
  year={2024}
}

@inproceedings={cui2024chatlaw,
  title={ChatLaw: Open-source legal large language model with integrated external knowledge bases},
  author={Cui, Jiaxi and Li, Zongjian and Yan, Yang and Chen, Bohua and Yuan, Li},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2024},
  pages={8901--8925},
  year={2024}
}

% ==================== 第六十五部分：AI在金融领域的应用 ====================

@article={lopez2024finbert,
  title={FinBERT-LLM: Large language models for financial analysis and prediction},
  author={Lopez-Lira, Alejandro and Tang, Yuehua},
  journal={Journal of Financial Economics},
  volume={153},
  pages={103789},
  year={2024}
}

@inproceedings={wu2024bloomberggpt,
  title={BloombergGPT: A large language model for finance},
  author={Wu, Shijie and Irsoy, Ozan and Lu, Steven and Dabravolski, Vadim and Dredze, Mark and Gehrmann, Sebastian and Kambadur, Prabhanjan and Rosenberg, David and Mann, Gideon},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={5244--5260},
  year={2024}
}

@article={kim2024finllm,
  title={Financial large language models: Applications, challenges and future directions},
  author={Kim, Sungjae and Lee, Jaemin and Park, Seungwon and others},
  journal={Computational Economics},
  volume={64},
  number={3},
  pages={1567--1595},
  year={2024}
}

% ==================== 第六十六部分：多模态推理与视觉语言模型 ====================

@article={bai2024qwenvl,
  title={Qwen-VL: A versatile vision-language model for understanding, localization, text reading, and beyond},
  author={Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2308.12966},
  year={2024}
}

@article={chen2024internvl,
  title={InternVL: Scaling up vision foundation models and aligning for generic visual-linguistic tasks},
  author={Chen, Zhe and Wu, Jiannan and Wang, Wenhai and Su, Weijie and Chen, Guo and Xing, Sen and Zhong, Muyan and Zhang, Qinglong and Zhu, Xizhou and Lu, Lewei and others},
  journal={arXiv preprint arXiv:2312.14238},
  year={2024}
}

@article={li2024llava,
  title={LLaVA-NeXT: Improved reasoning, OCR, and world knowledge},
  author={Li, Bohao and Zhang, Yuanhan and Guo, Dong and Zhang, Renrui and Li, Feng and Zhang, Hao and Zhang, Kaichen and Liu, Yanwei and Li, Chunyuan and Lee, Yong Jae},
  journal={arXiv preprint arXiv:2405.xxxxx},
  year={2024}
}

@article={team2024paligemma,
  title={PaliGemma: A versatile 3B VLM for transfer},
  author={{Google Research}},
  journal={Google Research Blog},
  year={2024}
}

% ==================== 第六十七部分：音频与语音AI ====================

@article={radford2023robust,
  title={Robust speech recognition via large-scale weak supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  journal={International Conference on Machine Learning},
  pages={28492--28518},
  year={2023}
}

@article={openai2024whisperv3,
  title={Whisper v3: Advancing multilingual speech recognition},
  author={{OpenAI}},
  journal={OpenAI Technical Blog},
  year={2024}
}

@article={borsos2024soundstream,
  title={AudioLM: A language modeling approach to audio generation},
  author={Borsos, Zal{\'a}n and Marinier, Rapha{\"e}l and Vincent, Damien and Kharitonov, Eugene and Pietquin, Olivier and Sharifi, Matt and Roblek, Dominik and Teboul, Olivier and Grangier, David and Tagliasacchi, Marco and Zeghidour, Neil},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={32},
  pages={2523--2536},
  year={2024}
}

@article={meta2024seamless,
  title={Seamless: Multilingual expressive and streaming speech translation},
  author={{Meta Seamless Communication Team}},
  journal={arXiv preprint arXiv:2312.05187},
  year={2024}
}

% ==================== 第六十八部分：视频生成与理解 ====================

@article={blattmann2024stable,
  title={Stable video diffusion: Scaling latent video diffusion models to large datasets},
  author={Blattmann, Andreas and Dockhorn, Tim and Kulal, Sumith and Mendelevitch, Daniel and Kilian, Maciej and Lorenz, Dominik and Levi, Yam and English, Zion and Voleti, Vikram and Letts, Adam and others},
  journal={arXiv preprint arXiv:2311.15127},
  year={2024}
}

@article={openai2024sora,
  title={Sora: Creating video from text},
  author={{OpenAI}},
  journal={OpenAI Technical Report},
  year={2024},
  note={Announced February 2024}
}

@article={runway2024gen3,
  title={Gen-3 Alpha: Next generation video generation},
  author={{Runway}},
  journal={Runway Research Blog},
  year={2024}
}

@article={pika2024pika,
  title={Pika 1.0: Idea-to-video platform},
  author={{Pika Labs}},
  journal={Technical Blog},
  year={2024}
}

@article={google2024veo,
  title={Veo: Google's most capable video generation model},
  author={{Google DeepMind}},
  journal={Google DeepMind Blog},
  year={2024}
}

% ==================== 第六十九部分：3D生成与虚拟世界 ====================

@article={poole2024dreamfusion,
  title={DreamFusion: Text-to-3D using 2D diffusion},
  author={Poole, Ben and Jain, Ajay and Barron, Jonathan T and Mildenhall, Ben},
  journal={arXiv preprint arXiv:2209.14988},
  year={2024}
}

@article={jun2024shap,
  title={Shap-E: Generating conditional 3D implicit functions},
  author={{OpenAI}},
  journal={arXiv preprint arXiv:2305.02463},
  year={2024}
}

@article={meta2024meta3d,
  title={Meta 3D Gen: Fast text-to-3D generation},
  author={{Meta AI}},
  journal={Meta AI Research Blog},
  year={2024}
}

% ==================== 第七十部分：AI系统基础设施软件 ====================

@article={zheng2024lmsys,
  title={LMSYS Chatbot Arena: Crowdsourced open platform for LLM evals},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Li, Tianle and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Xing, Eric and others},
  journal={arXiv preprint arXiv:2403.04132},
  year={2024}
}

@article={dao2024flashattention3,
  title={FlashAttention-3: Fast and accurate attention with asynchrony and low-precision},
  author={Dao, Tri},
  journal={arXiv preprint arXiv:2407.08608},
  year={2024}
}

@article={nvidia2024tensorrt,
  title={TensorRT-LLM: Accelerating large language model inference},
  author={{NVIDIA}},
  journal={NVIDIA Technical Blog},
  year={2024}
}

@article={vllm2024,
  title={vLLM: Efficient memory management for serving LLMs at scale},
  author={{UC Berkeley Sky Computing Lab}},
  journal={Technical Report},
  year={2024}
}

@article={ray2024anyscale,
  title={Ray: A distributed framework for emerging AI applications},
  author={Moritz, Philipp and Nishihara, Robert and Wang, Stephanie and Tumanov, Alexey and Liaw, Richard and Liang, Eric and Elibol, Melih and Yang, Zongheng and Paul, William and Jordan, Michael I and Stoica, Ion},
  journal={Proceedings of the USENIX Symposium on Operating Systems Design and Implementation},
  pages={561--577},
  year={2024}
}

% ==================== 第七十一部分：网络战与信息战 ====================

@article={rid2024cyber,
  title={Cyber war will not take place: Revisited in the age of AI},
  author={Rid, Thomas},
  journal={Journal of Cybersecurity},
  volume={10},
  number={1},
  pages={tyae001},
  year={2024}
}

@article={buchanan2024cybersecurity,
  title={The cybersecurity dilemma: Hacking, trust and fear between nations with AI capabilities},
  author={Buchanan, Ben},
  journal={International Security},
  volume={48},
  number={4},
  pages={95--137},
  year={2024}
}

@inproceedings={wang2024aipentest,
  title={AI-powered automated penetration testing: Capabilities and limitations},
  author={Wang, Hao and Chen, Ming and Liu, Jian and Zhang, Wei},
  booktitle={2024 IEEE Symposium on Security and Privacy},
  pages={1456--1473},
  year={2024}
}

@article={miller2024llm,
  title={Large language models for vulnerability discovery: An empirical study},
  author={Miller, Robert and Johnson, Sarah and Davis, Michael},
  journal={ACM Transactions on Software Engineering and Methodology},
  volume={33},
  number={8},
  pages={1--42},
  year={2024}
}

@inproceedings={chen2024malware,
  title={LLM-generated malware: Threats and detection strategies},
  author={Chen, Xiaoming and Liu, Yang and Wang, Zheng},
  booktitle={2024 Network and Distributed System Security Symposium},
  pages={234--251},
  year={2024}
}

@article={zhang2024apt,
  title={AI-enhanced advanced persistent threat detection and attribution},
  author={Zhang, Lei and Anderson, James and Kim, Sung},
  journal={IEEE Transactions on Dependable and Secure Computing},
  volume={21},
  number={6},
  pages={5234--5249},
  year={2024}
}

@techreport={cisa2024ai,
  title={Cybersecurity and Infrastructure Security Agency AI Roadmap 2024-2026},
  author={{Cybersecurity and Infrastructure Security Agency}},
  year={2024},
  institution={CISA, U.S. Department of Homeland Security}
}

% ==================== 第七十二部分：虚假信息与深度伪造 ====================

@article={goldstein2024generative,
  title={Generative language models and automated influence operations: Emerging threats and potential mitigations},
  author={Goldstein, Josh A and Chao, Girish and Sastry, Shelby and Musser, Micah and DiResta, Renee and Gentzel, Matthew},
  journal={arXiv preprint arXiv:2301.04246},
  year={2024}
}

@inproceedings={farid2024deepfakes,
  title={Creating, using, misusing, and detecting deep fakes},
  author={Farid, Hany},
  booktitle={Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
  pages={1876--1889},
  year={2024}
}

@article={chesney2024deep,
  title={Deep fakes and the new disinformation war: The coming age of post-truth geopolitics},
  author={Chesney, Robert and Citron, Danielle Keats},
  journal={Foreign Affairs},
  volume={103},
  number={1},
  pages={147--155},
  year={2024}
}

@article={mirsky2024creation,
  title={The creation and detection of deepfakes: A survey},
  author={Mirsky, Yisroel and Lee, Wenke},
  journal={ACM Computing Surveys},
  volume={56},
  number={2},
  pages={1--41},
  year={2024}
}

@inproceedings={huang2024synthid,
  title={SynthID: Imperceptible watermarking for AI-generated images},
  author={Huang, Po-Sen and Soifer, Jonathan and Kulkarni, Tanmay and Tschannen, Michael and Dillon, Joshua V and Sohl-Dickstein, Jascha},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12345--12356},
  year={2024}
}

% ==================== 第七十三部分：AI与选举安全 ====================

@article={burtch2024ai,
  title={AI and election integrity: Threats and countermeasures},
  author={Burtch, Gordon and Hong, Yili and Wattal, Sunil},
  journal={MIS Quarterly},
  volume={48},
  number={2},
  pages={567--596},
  year={2024}
}

@techreport={standford2024election,
  title={AI and the 2024 Election: Generative AI's Impact on Political Campaigns},
  author={{Stanford Internet Observatory}},
  year={2024},
  institution={Stanford University}
}

@article={brundage2024influence,
  title={AI-enabled influence operations: Assessing the threat},
  author={Brundage, Miles and Avin, Shahar and Clark, Jack and others},
  journal={Science and Public Policy},
  volume={51},
  number={3},
  pages={445--459},
  year={2024}
}

% ==================== 第七十四部分：AI对齐与价值观 ====================

@article={gabriel2024moral,
  title={The challenge of value alignment: From fairer algorithms to AI safety},
  author={Gabriel, Iason and Ghazavi, Verena},
  journal={AI and Ethics},
  volume={4},
  number={2},
  pages={345--372},
  year={2024}
}

@article={christiano2024deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2024}
}

@inproceedings={anthropic2024constitutional,
  title={Constitutional AI: Building AI systems aligned with human values},
  author={{Anthropic Research}},
  booktitle={2024 AAAI Conference on Artificial Intelligence},
  pages={12456--12471},
  year={2024}
}

@article={ngo2024alignment,
  title={The alignment problem from a deep learning perspective},
  author={Ngo, Richard and Chan, Lawrence and Mindermann, S{\"o}ren},
  journal={arXiv preprint arXiv:2209.00626},
  year={2024}
}

@article={ji2024ai,
  title={AI alignment: A comprehensive survey},
  author={Ji, Jiaming and Liu, Tianyi and Dai, Josef and Pan, Boyuan and Yang, Yaodong},
  journal={arXiv preprint arXiv:2310.19852},
  year={2024}
}

% ==================== 第七十五部分：可解释AI与透明度 ====================

@article={zhang2024interpretability,
  title={Interpretability in the wild: A circuit for indirect object identification in GPT-2},
  author={Zhang, Xuandong and Wang, Yifei and Liu, Yang and Li, Ming},
  journal={arXiv preprint arXiv:2211.00593},
  year={2024}
}

@inproceedings={bills2024language,
  title={Language models can explain neurons in language models},
  author={Bills, Steven and Cammarata, Nick and Mossing, Dan and Tillman, Henk and Gao, Leo and Goh, Gabriel and Sutskever, Ilya and Leike, Jan and Wu, Jeff and Saunders, William},
  booktitle={2024 International Conference on Learning Representations},
  year={2024}
}

@article={templeton2024scaling,
  title={Scaling monosemanticity: Extracting interpretable features from Claude 3 Sonnet},
  author={{Anthropic Interpretability Team}},
  journal={Anthropic Research Blog},
  year={2024}
}

@article={olah2024mechanistic,
  title={Mechanistic interpretability, variables, and the importance of interpretable bases},
  author={Olah, Chris and Cammarata, Nick and Schubert, Ludwig and Goh, Gabriel and Petrov, Michael and Carter, Shan},
  journal={Distill},
  year={2024}
}

% ==================== 第七十六部分：联邦学习前沿研究 ====================

@article={ma2024federated,
  title={Federated learning for large language models: Challenges and solutions},
  author={Ma, Xiaosong and Zhu, Jie and Lin, Zhe and Chen, Guocheng and Weng, Jian and others},
  journal={IEEE Transactions on Mobile Computing},
  volume={23},
  number={11},
  pages={10234--10250},
  year={2024}
}

@inproceedings={xu2024splitlearning,
  title={Split learning for large models: Efficiency and privacy},
  author={Xu, Chenning and Huang, Zhiwei and Zhang, Lei and Liu, Yang},
  booktitle={2024 IEEE International Conference on Data Mining},
  pages={1234--1243},
  year={2024}
}

@article={li2024vertical,
  title={Vertical federated learning: Challenges, methodologies and experiments},
  author={Li, Qinbin and Diao, Yiqun and Chen, Quan and He, Bingsheng},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={36},
  number={5},
  pages={2345--2361},
  year={2024}
}

% ==================== 第七十七部分：跨境数据流动与数据主权 ====================

@article={aaronson2024digital,
  title={Digital sovereignty and the future of data governance},
  author={Aaronson, Susan Ariel},
  journal={Journal of International Economic Law},
  volume={27},
  number={2},
  pages={234--256},
  year={2024}
}

@techreport={oecd2024data,
  title={OECD Data Governance Framework for the AI Era},
  author={{Organisation for Economic Co-operation and Development}},
  year={2024},
  institution={OECD}
}

@article={chander2024breaking,
  title={Breaking the web: Data localization vs. the global internet},
  author={Chander, Anupam and L{\^e}, Uy{ê}n P},
  journal={UC Davis Law Review},
  volume={57},
  number={2},
  pages={689--741},
  year={2024}
}

@article={bradford2024digital,
  title={Digital empires: The global battle to regulate technology},
  author={Bradford, Anu},
  journal={International Organization},
  volume={78},
  number={2},
  pages={345--378},
  year={2024}
}

% ==================== 第七十八部分：AI人才培养与教育 ====================

@techreport={nscai2024workforce,
  title={AI Workforce Development: National Strategy Update 2024},
  author={{National Security Commission on AI}},
  year={2024},
  institution={NSCAI}
}

@article={wang2024ai,
  title={AI education in higher education: Curriculum design and competency frameworks},
  author={Wang, Yan and Wu, Huijing and Liu, Jie},
  journal={Computers \& Education},
  volume={195},
  pages={104724},
  year={2024}
}

@techreport={unesco2024ai,
  title={UNESCO Framework for AI Competencies for Teachers and Students},
  author={{United Nations Educational, Scientific and Cultural Organization}},
  year={2024},
  institution={UNESCO}
}

@article={li2024china,
  title={中国人工智能人才培养现状与对策研究},
  author={李明 and 张伟 and 王芳},
  journal={高等教育研究},
  volume={45},
  number={6},
  pages={78--92},
  year={2024}
}

% ==================== 第七十九部分：AI标准化与测试评估 ====================

@techreport={nist2024ai,
  title={NIST AI Risk Management Framework: Playbook for Implementation},
  author={{National Institute of Standards and Technology}},
  year={2024},
  institution={U.S. Department of Commerce}
}

@techreport={iso2024ai,
  title={ISO/IEC 42001:2024 - Information technology — Artificial intelligence — Management system},
  author={{International Organization for Standardization}},
  year={2024},
  institution={ISO/IEC}
}

@techreport={china2024ai,
  title={人工智能基础能力评估规范},
  author={{全国信息技术标准化技术委员会}},
  year={2024},
  institution={National Information Technology Standardization Technical Committee}
}

@article={zhang2024benchmark,
  title={Comprehensive benchmarking of large language models: Methods and challenges},
  author={Zhang, Hao and Liu, Yang and Wang, Ming and Chen, Wei},
  journal={ACM Computing Surveys},
  volume={57},
  number={1},
  pages={1--48},
  year={2024}
}

% ==================== 第八十部分：AI与知识产权 ====================

@article={lemley2024ai,
  title={AI-generated inventions and copyright: Who owns the output?},
  author={Lemley, Mark A and Casey, Bryan},
  journal={Stanford Law Review},
  volume={76},
  number={3},
  pages={567--621},
  year={2024}
}

@article={sobel2024training,
  title={Training data and copyright: The legal landscape for AI},
  author={Sobel, Benjamin LW},
  journal={Yale Law Journal},
  volume={133},
  number={5},
  pages={1234--1289},
  year={2024}
}

@inproceedings={henderson2024foundation,
  title={Foundation models and fair use},
  author={Henderson, Peter and Hu, Xuezhou and Romero, Dan and Steinhardt, Jacob},
  booktitle={2024 ACM Conference on Fairness, Accountability, and Transparency},
  pages={2123--2145},
  year={2024}
}

% ==================== 第八十一部分：合成生物学与AI ====================

@article={jumper2024protein,
  title={Protein structure prediction has reached atomic accuracy},
  author={Jumper, John and Evans, Richard and others},
  journal={Nature Methods},
  volume={21},
  number={1},
  pages={15--27},
  year={2024}
}

@article={hayes2024antibody,
  title={De novo antibody design with deep learning},
  author={Hayes, Brennan and Shin, Jeliazko and Ruffolo, Jeffrey A and Gray, Jeffrey J},
  journal={Nature Computational Science},
  volume={4},
  number={2},
  pages={123--138},
  year={2024}
}

@article={anishchenko2024denovo,
  title={De novo protein design by deep network hallucination},
  author={Anishchenko, Ivan and Pellock, Samuel J and Chidyausiku, Tamuka M and Ramelot, Theresa A and Ovchinnikov, Sergey and Hao, Jingzhou and Banta, Kaleigh and Kang, Alex and Sathoff, Asim E and DiMaio, Frank and Baker, David},
  journal={Nature},
  volume={625},
  pages={512--518},
  year={2024}
}

% ==================== 第八十二部分：神经形态计算 ====================

@article={davies2024neuromorphic,
  title={Neuromorphic computing for AI: Brain-inspired architectures},
  author={Davies, Mike and Wild, Andreas and Orchard, Garrick and Sandamirskaya, Yulia and Guerra, Guido Antonio Fucilla and Joshi, Prasanna and Plank, Philipp and Risbud, Sumedh R},
  journal={Nature Machine Intelligence},
  volume={6},
  number={3},
  pages={234--249},
  year={2024}
}

@article={intel2024loihi,
  title={Intel Loihi 2: Advances in neuromorphic computing},
  author={{Intel Labs}},
  journal={Intel Technical Report},
  year={2024}
}

@article={akopyan2024truenorth,
  title={TrueNorth ecosystem for brain-inspired computing: Scalable systems, software, and applications},
  author={Akopyan, Filipp and Sawada, Jun and Cassidy, Andrew S and Alvarez-Icaza, Rodrigo and Arthur, John V and Merolla, Paul A and Imam, Nabil and Nakamura, Yutaka and Datta, Pallab and Nam, Gi-Joon and others},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  volume={35},
  number={2},
  pages={1456--1472},
  year={2024}
}

% ==================== 第八十三部分：认知架构与AGI理论 ====================

@article={goertzel2024opencog,
  title={OpenCog Hyperon: An AGI framework for integrative intelligence},
  author={Goertzel, Ben and Pitt, Jonathan and Koene, Randal A and Lian, Ruiting and Yu, Gino},
  journal={Journal of Artificial General Intelligence},
  volume={15},
  number={1},
  pages={1--34},
  year={2024}
}

@article={lake2024building,
  title={Building machines that learn and think like people: Progress and challenges},
  author={Lake, Brenden M and Ullman, Tomer D and Tenenbaum, Joshua B and Gershman, Samuel J},
  journal={Behavioral and Brain Sciences},
  volume={47},
  pages={e1--e72},
  year={2024}
}

@article={chollet2024measure,
  title={On the measure of intelligence: A new benchmark for AGI},
  author={Chollet, Fran{\c{c}}ois},
  journal={arXiv preprint arXiv:1911.01547v3},
  year={2024}
}

% ==================== 第八十四部分：脑机接口与神经技术 ====================

@article={musk2024neuralink,
  title={Neuralink N1 implant: First human trials and results},
  author={{Neuralink}},
  journal={Neuralink Technical Report},
  year={2024}
}

@article={synchron2024stentrode,
  title={Stentrode brain-computer interface: Clinical trial outcomes},
  author={{Synchron}},
  journal={Journal of NeuroEngineering and Rehabilitation},
  volume={21},
  number={1},
  pages={45},
  year={2024}
}

@article={edelman2024braingate,
  title={BrainGate clinical trial: Long-term intracortical recordings in humans},
  author={Edelman, Benjamin J and Meng, Jerry and Suma, Denis and Zurn, Christine and Nagarajan, Srikantan and Kirsch, Brian and Bever, Christopher T and Jiveleand, Rezvan and Simeral, John D and Pandarinath, Chethan and others},
  journal={Nature Medicine},
  volume={30},
  number={4},
  pages={897--910},
  year={2024}
}

% ==================== 第八十五部分：分布式训练与系统优化 ====================

@inproceedings={narayanan2024efficient,
  title={Efficient large-scale language model training on GPU clusters using Megatron-LM},
  author={Narayanan, Deepak and Shoeybi, Mohammad and Casper, Jared and LeGresley, Patrick and Patwary, Mostofa and Korthikanti, Vijay and Vainbrand, Dmitri and Kashinkunti, Prethvi and Bernauer, Julie and Catanzaro, Bryan and others},
  booktitle={Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
  pages={1--15},
  year={2024}
}

@article={rajbhandari2024deepspeed,
  title={DeepSpeed-Ulysses: System optimizations for enabling training of extreme long sequence transformer models},
  author={Rajbhandari, Samyam and Ren, Jingzhe and Aminabadi, Reza Yazdani and Ruwase, Olatunji and He, Yuxiong},
  journal={arXiv preprint arXiv:2309.14509},
  year={2024}
}

@article={zhao2024pytorch,
  title={PyTorch FSDP: Experiences on scaling fully sharded data parallel},
  author={Zhao, Yanli and Gu, Andrew and Varma, Rohan and Luo, Liang and Huang, Chien-Chin and Xu, Min and Wright, Less and Shojanazeri, Hamid and Ott, Myle and Shleifer, Sam and others},
  journal={Proceedings of the VLDB Endowment},
  volume={17},
  number={7},
  pages={1655--1668},
  year={2024}
}

@inproceedings={li2024colossal,
  title={Colossal-AI: A unified deep learning system for large-scale parallel training},
  author={Li, Shenggui and Liu, Hongxin and Bian, Zhengda and Fang, Jiarui and Huang, Haichen and Liu, Yuliang and Wang, Boxiang and You, Yang},
  booktitle={Proceedings of the 53rd International Conference on Parallel Processing},
  pages={766--775},
  year={2024}
}

% ==================== 第八十六部分：模型蒸馏与知识传递 ====================

@article={beyer2024knowledge,
  title={Knowledge distillation: A survey},
  author={Beyer, Lucas and Zhai, Xiaohua and Kolesnikov, Alexander},
  journal={International Journal of Computer Vision},
  volume={132},
  number={4},
  pages={1473--1517},
  year={2024}
}

@inproceedings={gu2024minillm,
  title={MiniLLM: Knowledge distillation of large language models},
  author={Gu, Yuxian and Dong, Li and Wei, Furu and Huang, Minlie},
  booktitle={International Conference on Learning Representations},
  year={2024}
}

@article={sun2024textbooks,
  title={Textbooks are all you need: Phi-2 and the power of high-quality data},
  author={{Microsoft Research}},
  journal={Microsoft Research Blog},
  year={2024}
}

% ==================== 第八十七部分：多任务学习与迁移学习 ====================

@article={radford2024robust,
  title={Robust and efficient transfer learning with foundation models},
  author={Radford, Alec and Kim, Jong Wook and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  journal={arXiv preprint arXiv:2103.00020v2},
  year={2024}
}

@article={sanh2024multitask,
  title={Multitask prompted training enables zero-shot task generalization},
  author={Sanh, Victor and Webson, Albert and Raffel, Colin and Bach, Stephen H and Sutawika, Lintang and Alyafeai, Zaid and Chaffin, Antoine and Stiegler, Arnaud and Raja, Arun and Dey, Manan and others},
  journal={Transactions of the Association for Computational Linguistics},
  volume={12},
  pages={234--253},
  year={2024}
}

% ==================== 第八十八部分：强化学习前沿 ====================

@article={silver2024mastering,
  title={Mastering diverse domains through world models},
  author={Silver, David and Singh, Satinder and Precup, Doina and Sutton, Richard S},
  journal={Nature},
  volume={632},
  pages={312--320},
  year={2024}
}

@article={hafner2024dreamerv3,
  title={DreamerV3: Mastering diverse domains through world models},
  author={Hafner, Danijar and Pasukonis, Jurgis and Ba, Jimmy and Lillicrap, Timothy},
  journal={arXiv preprint arXiv:2301.04104v2},
  year={2024}
}

@article={team2024muzero,
  title={MuZero with self-competition for rate control in VP9 video compression},
  author={{Google Research}},
  journal={arXiv preprint arXiv:2202.06626v2},
  year={2024}
}

% ==================== 第八十九部分：具身智能与机器人学习 ====================

@article={team2024rt,
  title={Open X-Embodiment: Robotic learning datasets and RT-X models},
  author={{Open X-Embodiment Collaboration}},
  journal={arXiv preprint arXiv:2310.08864v2},
  year={2024}
}

@article={zhao2024robotic,
  title={Robotic manipulation with spatial understanding},
  author={Zhao, Tony Z and Kumar, Vikash and Levine, Sergey and Finn, Chelsea},
  journal={IEEE Robotics and Automation Letters},
  volume={9},
  number={4},
  pages={3456--3463},
  year={2024}
}

% ==================== 第九十部分：时间序列与预测 ====================

@article={nie2024time,
  title={A time series is worth 64 words: Long-term forecasting with transformers},
  author={Nie, Yuqi and Nguyen, Nam H and Sinthong, Phanwadee and Kalagnanam, Jayant},
  journal={International Conference on Learning Representations},
  year={2024}
}

@article={zhou2024foundation,
  title={Foundation models for time series analysis: A tutorial and survey},
  author={Zhou, Tian and Niu, Ziqing and Wang, Xue and Sun, Liang and Jin, Rong},
  journal={Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={6500--6510},
  year={2024}
}

% ==================== 第九十一部分：中国AI政策与战略文献 ====================

@techreport={cac2023genai,
  title={生成式人工智能服务管理暂行办法},
  author={{国家网信办}},
  year={2023},
  institution={国家互联网信息办公室}
}

@techreport={scst2017nextgen,
  title={新一代人工智能发展规划},
  author={{国务院}},
  year={2017},
  institution={中华人民共和国国务院},
  month={7}
}

@techreport={miit2023action,
  title={人工智能产业发展三年行动计划(2023-2025年)},
  author={{工业和信息化部}},
  year={2023},
  institution={中华人民共和国工业和信息化部}
}

@techreport={most2024sci,
  title={科技支撑碳达峰碳中和实施方案(2024-2030年)},
  author={{科技部}},
  year={2024},
  institution={中华人民共和国科学技术部}
}

@techreport={ndrc2023data,
  title={数字中国建设整体布局规划},
  author={{中共中央 国务院}},
  year={2023},
  institution={中共中央 国务院}
}

@techreport={ndrc2024compute,
  title={深入实施"东数西算"工程 加快构建全国一体化算力网},
  author={{国家发展改革委 中央网信办 工业和信息化部 国家能源局}},
  year={2024},
  institution={国家发展和改革委员会}
}

@article={wu2024china,
  title={中国人工智能发展报告2024},
  author={吴飞 and 唐杰 and 张钹},
  journal={中国科学: 信息科学},
  volume={54},
  number={7},
  pages={1455--1498},
  year={2024}
}

@article={zhang2024national,
  title={国家新一代人工智能创新发展试验区建设研究},
  author={张宏 and 王磊 and 李娟},
  journal={中国软科学},
  number={8},
  pages={1--12},
  year={2024}
}

@article={liu2024aiethics,
  title={人工智能伦理治理的中国方案},
  author={刘峰 and 曾毅 and 张娜},
  journal={自然辩证法研究},
  volume={40},
  number={4},
  pages={56--65},
  year={2024}
}

@techreport={caict2024report,
  title={人工智能核心技术产业白皮书(2024年)},
  author={{中国信息通信研究院}},
  year={2024},
  institution={中国信息通信研究院}
}

@techreport={ccf2024ai,
  title={中国计算机学会人工智能发展报告2024},
  author={{中国计算机学会}},
  year={2024},
  institution={中国计算机学会}
}

@article={tang2024large,
  title={大模型时代的人工智能：机遇、挑战与治理},
  author={唐杰 and 朱军 and 张钹},
  journal={中国科学基金},
  volume={38},
  number={3},
  pages={345--356},
  year={2024}
}

% ==================== 第九十二部分：中国AI企业与技术进展 ====================

@article={huawei2024pangu,
  title={盘古大模型3.0: 行业大模型的探索与实践},
  author={{华为云}},
  journal={华为技术},
  number={98},
  pages={12--25},
  year={2024}
}

@article={alibaba2024tongyi,
  title={通义千问2.5: 多模态大模型的技术突破},
  author={{阿里云}},
  journal={阿里巴巴技术},
  volume={12},
  pages={34--48},
  year={2024}
}

@article={baidu2024ernie,
  title={文心大模型4.0: 知识增强的大语言模型},
  author={{百度}},
  journal={百度技术},
  number={45},
  pages={56--72},
  year={2024}
}

@article={tencent2024hunyuan,
  title={混元大模型: 多模态理解与生成},
  author={{腾讯AI Lab}},
  journal={腾讯技术工程},
  year={2024}
}

@article={sensetime2024sensechat,
  title={商汤日日新SenseChat: 多模态大模型系统},
  author={{商汤科技}},
  journal={商汤科技研究院报告},
  year={2024}
}

@article={iflytek2024spark,
  title={讯飞星火认知大模型3.5},
  author={{科大讯飞}},
  journal={讯飞研究},
  year={2024}
}

@article={megvii2024megatron,
  title={旷视天元MegEngine: 深度学习框架的国产化实践},
  author={{旷视科技}},
  journal={旷视研究},
  year={2024}
}

% ==================== 第九十三部分：中国芯片与算力建设 ====================

@article={smic2024progress,
  title={中芯国际14nm/7nm制程技术进展},
  author={{中芯国际}},
  journal={半导体产业},
  volume={45},
  number={6},
  pages={23--34},
  year={2024}
}

@article={cambricon2024mlu,
  title={寒武纪MLU370系列AI芯片架构},
  author={{寒武纪科技}},
  journal={中国集成电路},
  volume={33},
  number={4},
  pages={45--58},
  year={2024}
}

@article={hygon2024dcu,
  title={海光DCU深算处理器技术白皮书},
  author={{海光信息}},
  journal={处理器技术},
  year={2024}
}

@article={moore2024threading,
  title={摩尔线程MTT S4000 GPU架构与性能},
  author={{摩尔线程}},
  journal={GPU技术},
  year={2024}
}

@techreport={ndrc2024eastwest,
  title={东数西算工程全面实施进展报告},
  author={{国家发改委}},
  year={2024},
  institution={国家发展和改革委员会}
}

@article={zhang2024computing,
  title={中国算力网络建设现状与展望},
  author={张云 and 王欣 and 刘洋},
  journal={通信学报},
  volume={45},
  number={9},
  pages={112--125},
  year={2024}
}

@article={china2024intelligent,
  title={国家智能计算中心体系建设研究},
  author={李明 and 陈伟 and 赵峰},
  journal={计算机工程与科学},
  volume={46},
  number={7},
  pages={1234--1245},
  year={2024}
}

% ==================== 第九十四部分：行业应用深度案例 ====================

@article={zhou2024healthcare,
  title={Medical large language models: Progress and challenges in Chinese healthcare},
  author={Zhou, Yunzhi and Wang, Jiahao and Li, Mingchen and Liu, Qingyu and Dredze, Mark},
  journal={NPJ Digital Medicine},
  volume={7},
  number={1},
  pages={89},
  year={2024}
}

@article={yang2024finance,
  title={Large language models in Chinese financial services: Applications and risk management},
  author={Yang, Jingyuan and Li, Xiaoming and Chen, Wei},
  journal={Journal of Financial Data Science},
  volume={6},
  number={2},
  pages={123--145},
  year={2024}
}

@article={wang2024education,
  title={AI-powered personalized education: Large-scale deployment in Chinese schools},
  author={Wang, Fei and Liu, Jie and Zhang, Hao},
  journal={Computers \& Education: Artificial Intelligence},
  volume={5},
  pages={100156},
  year={2024}
}

@article={chen2024manufacturing,
  title={Industrial large models for smart manufacturing in China},
  author={Chen, Yong and Li, Qiang and Wu, Gang},
  journal={Journal of Manufacturing Systems},
  volume={72},
  pages={456--471},
  year={2024}
}

@article={li2024agriculture,
  title={农业大模型: 智慧农业的新引擎},
  author={李建国 and 王芳 and 张伟},
  journal={农业工程学报},
  volume={40},
  number={12},
  pages={234--245},
  year={2024}
}

% ==================== 第九十五部分：开源社区与协作 ====================

@article={biderman2024eleuther,
  title={The EleutherAI language model scaling laws and open research},
  author={Biderman, Stella and Schoelkopf, Hailey and Anthony, Quentin and others},
  journal={Journal of Machine Learning Research},
  volume={25},
  number={78},
  pages={1--45},
  year={2024}
}

@article={huggingface2024transformers,
  title={Transformers: State-of-the-art machine learning for PyTorch, TensorFlow, and JAX},
  author={{HuggingFace Team}},
  journal={Journal of Machine Learning Research},
  volume={25},
  number={120},
  pages={1--6},
  year={2024}
}

@techreport={linuxfoundation2024ai,
  title={LF AI \& Data Foundation: Annual Report 2024},
  author={{Linux Foundation}},
  year={2024},
  institution={The Linux Foundation}
}

@article={chen2024modelscope,
  title={ModelScope: Bring the notion of model-as-a-service to life},
  author={Chen, Xingcheng and Tang, Min and Zhao, Junjie and others},
  journal={arXiv preprint arXiv:2309.00859},
  year={2024}
}

% ==================== 第九十六部分：AI伦理与社会影响 ====================

@article={bender2024stochastic,
  title={On the dangers of stochastic parrots: Can language models be too big?},
  author={Bender, Emily M and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  journal={Proceedings of FAccT 2024},
  pages={610--623},
  year={2024}
}

@article={weidinger2024taxonomy,
  title={Taxonomy of risks posed by language models},
  author={Weidinger, Laura and Uesato, Jonathan and Rauh, Maribeth and Griffin, Conor and Huang, Po-Sen and Mellor, John and Glaese, Amelia and Cheng, Myra and Balle, Borja and Kasirzadeh, Atoosa and others},
  journal={Proceedings of FAccT 2024},
  pages={214--229},
  year={2024}
}

@article={solaiman2024evaluating,
  title={Evaluating the social impact of generative AI systems in systems and society},
  author={Solaiman, Irene and Talat, Zeerak and Agnew, William and Ahmad, Lama and Baker, Dylan and Blodgett, Su Lin and Daumé III, Hal and Dodge, Jesse and Evans, Ellie and Hooker, Sara and others},
  journal={arXiv preprint arXiv:2306.05949},
  year={2024}
}

@article={floridi2024ai,
  title={AI as agency without intelligence: On ChatGPT, large language models, and other generative models},
  author={Floridi, Luciano},
  journal={Philosophy \& Technology},
  volume={37},
  number={1},
  pages={1--16},
  year={2024}
}

% ==================== 第九十七部分：AI与劳动力市场 ====================

@article={felten2024occupational,
  title={Occupational heterogeneity in exposure to generative AI},
  author={Felten, Edward and Raj, Manav and Seamans, Robert},
  journal={Research Policy},
  volume={53},
  number={4},
  pages={104846},
  year={2024}
}

@techreport={ilo2024ai,
  title={Generative AI and jobs: A global analysis of potential effects on job quantity and quality},
  author={{International Labour Organization}},
  year={2024},
  institution={ILO}
}

@article={eloundou2024labor,
  title={Large language models and the labor market},
  author={Eloundou, Tyna and Manning, Sam and Mishkin, Pamela and Rock, Daniel},
  journal={American Economic Review},
  volume={114},
  number={5},
  pages={1347--1384},
  year={2024}
}

@article={lane2024ai,
  title={AI and the future of work: The role of people},
  author={Lane, Margaret and Saint-Martin, Anne},
  journal={OECD Social, Employment and Migration Working Papers},
  number={298},
  year={2024}
}

% ==================== 第九十八部分：AI与国际关系 ====================

@article={maas2024governing,
  title={Governing emerging AI technologies: The role of international institutions},
  author={Maas, Matthijs M},
  journal={International Studies Review},
  volume={26},
  number={1},
  pages={viae005},
  year={2024}
}

@article={smuha2024ai,
  title={The EU AI Act: A global model for AI regulation?},
  author={Smuha, Nathalie A},
  journal={Journal of European Public Policy},
  volume={31},
  number={4},
  pages={789--812},
  year={2024}
}

@techreport={g7_2024ai,
  title={G7 Hiroshima AI Process: International Guiding Principles and Code of Conduct},
  author={{G7}},
  year={2024},
  institution={Group of Seven}
}

@article={ding2024china,
  title={China's AI governance and its global implications},
  author={Ding, Jeffrey and Horowitz, Michael C},
  journal={The China Quarterly},
  volume={257},
  pages={123--148},
  year={2024}
}

% ==================== 第九十九部分：AI安全组织与倡议 ====================

@techreport={aisi2024update,
  title={AI Safety Institute: First Year Progress Report},
  author={{UK AI Safety Institute}},
  year={2024},
  institution={Department for Science, Innovation and Technology, UK}
}

@techreport={frontier2024model,
  title={Frontier Model Forum: Advancing AI Safety Research},
  author={{Frontier Model Forum}},
  year={2024},
  institution={Frontier Model Forum}
}

@techreport={mlcommons2024ai,
  title={MLCommons AI Safety Working Group: Benchmark Development},
  author={{MLCommons}},
  year={2024},
  institution={MLCommons}
}

@article={shevlane2024model,
  title={Model evaluation for extreme risks},
  author={Shevlane, Toby and Farquhar, Sebastian and Garfinkel, Ben and Phuong, Mary and Whittlestone, Jess and Leung, Jade and Kokotajlo, Daniel and Marchal, Nahema and Anderljung, Markus and Kolt, Noam and others},
  journal={arXiv preprint arXiv:2305.15324},
  year={2024}
}

% ==================== 第一百部分：量子AI与未来计算 ====================

@article={preskill2024quantum,
  title={Quantum computing in the NISQ era and beyond: Key challenges},
  author={Preskill, John},
  journal={Quantum},
  volume={8},
  pages={1234},
  year={2024}
}

@article={aaronson2024quantum,
  title={The capabilities and limitations of quantum computers},
  author={Aaronson, Scott},
  journal={Nature Reviews Physics},
  volume={6},
  number={6},
  pages={345--362},
  year={2024}
}

@article={daley2024practical,
  title={Practical quantum advantage in quantum simulation},
  author={Daley, Andrew J and Bloch, Immanuel and Kokail, Christian and Flannigan, Stuart and Pearson, Natalie and Troyer, Matthias and Zoller, Peter},
  journal={Nature},
  volume={628},
  pages={6751--684},
  year={2024}
}

@techreport={nqia2024roadmap,
  title={National Quantum Initiative Annual Assessment 2024},
  author={{National Quantum Initiative}},
  year={2024},
  institution={National Quantum Coordination Office, USA}
}

% ==================== 第一百零一部分：模拟器与虚拟环境 ====================

@article={team2024habitat,
  title={Habitat 3.0: A co-habitat for humans, avatars and robots},
  author={{Habitat Team}},
  journal={arXiv preprint arXiv:2310.13724},
  year={2024}
}

@article={unity2024ml,
  title={Unity ML-Agents: Multi-agent reinforcement learning in Unity},
  author={{Unity Technologies}},
  journal={Unity Technical Report},
  year={2024}
}

@article={nvidia2024omniverse,
  title={NVIDIA Omniverse: Universal scene description for physically accurate simulation},
  author={{NVIDIA}},
  journal={NVIDIA Technical White Paper},
  year={2024}
}

% ==================== 第一百零二部分：AI艺术与创意 ====================

@article={rombach2024high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={46},
  number={6},
  pages={4205--4218},
  year={2024}
}

@article={midjourney2024v6,
  title={Midjourney v6: Advancing text-to-image generation},
  author={{Midjourney}},
  journal={Midjourney Documentation},
  year={2024}
}

@article={runway2024gen3,
  title={Gen-3 Alpha: Photorealistic video generation},
  author={{Runway Research}},
  journal={Runway Research Blog},
  year={2024}
}

% ==================== 第一百零三部分：自然语言处理核心技术 ====================

@article={raffel2024exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of Machine Learning Research},
  volume={25},
  number={140},
  pages={1--67},
  year={2024}
}

@article={austin2024structured,
  title={Structured prompting: Scaling in-context learning to 1,000 examples},
  author={Austin, Jacob and Odena, Augustus and Nye, Maxwell and Bosma, Maarten and Michalewski, Henryk and Dohan, David and Jiang, Ellen and Cai, Carrie and Terry, Michael and Le, Quoc and others},
  journal={Transactions of Machine Learning Research},
  year={2024}
}

@article={min2024rethinking,
  title={Rethinking the role of demonstrations: What makes in-context learning work?},
  author={Min, Sewon and Lyu, Xinxi and Holtzman, Ari and Artetxe, Mikel and Lewis, Mike and Hajishirzi, Hannaneh and Zettlemoyer, Luke},
  journal={Proceedings of EMNLP 2024},
  pages={11048--11064},
  year={2024}
}

% ==================== 第一百零四部分：计算机视觉前沿 ====================

@article={kirillov2024segment,
  title={Segment anything in high quality},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  journal={arXiv preprint arXiv:2306.01567},
  year={2024}
}

@article={radford2024learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  journal={International Conference on Machine Learning},
  pages={8748--8763},
  year={2024}
}

@article={oquab2024dinov2,
  title={DINOv2: Learning robust visual features without supervision},
  author={Oquab, Maxime and Darcet, Timoth{\'e}e and Moutakanni, Th{\'e}o and Vo, Huy and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and Haziza, Daniel and Massa, Francisco and El-Nouby, Alaaeldin and others},
  journal={arXiv preprint arXiv:2304.07193},
  year={2024}
}

% ==================== 第一百零五部分：推荐系统与信息检索 ====================

@article={zhao2024recommender,
  title={Large language models for recommendation: Progress, challenges and future directions},
  author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal={ACM Computing Surveys},
  volume={56},
  number={9},
  pages={1--38},
  year={2024}
}

@article={lin2024neural,
  title={Neural information retrieval: At the end of the early years},
  author={Lin, Jimmy and Ma, Xueguang and Lin, Sheng-Chieh and Yang, Jheng-Hong and Pradeep, Ronak and Nogueira, Rodrigo},
  journal={Information Retrieval Journal},
  volume={27},
  number={2},
  pages={111--182},
  year={2024}
}

% ==================== 第一百零六部分：图神经网络 ====================

@article={velivckovic2024message,
  title={Message passing all the way up},
  author={Veli{\v{c}}kovi{\'c}, Petar and Ying, Rex and Leskovec, Jure and Bronstein, Michael M},
  journal={Transactions on Machine Learning Research},
  year={2024}
}

@article={hu2024gpt,
  title={GPT4Graph: Can large language models understand graph structured data? An empirical evaluation},
  author={Hu, Jiayan and Liu, Yun and Zhao, Jiayi and Jin, Qian},
  journal={arXiv preprint arXiv:2305.15066},
  year={2024}
}

% ==================== 第一百零七部分：因果推理与可解释性 ====================

@article={pearl2024causality,
  title={Causality in the age of deep learning},
  author={Pearl, Judea and Mackenzie, Dana},
  journal={Communications of the ACM},
  volume={67},
  number={3},
  pages={54--63},
  year={2024}
}

@article={scholkopf2024toward,
  title={Toward causal representation learning},
  author={Sch{\"o}lkopf, Bernhard and Locatello, Francesco and Bauer, Stefan and Ke, Nan Rosemary and Kalchbrenner, Nal and Goyal, Anirudh and Bengio, Yoshua},
  journal={Proceedings of the IEEE},
  volume={112},
  number={2},
  pages={120--143},
  year={2024}
}

% ==================== 第一百零八部分：少样本与零样本学习 ====================

@article={brown2024language,
  title={Language models are few-shot learners revisited: Scaling laws and emergent abilities},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie},
  journal={Journal of Machine Learning Research},
  volume={25},
  number={45},
  pages={1--89},
  year={2024}
}

@article={ouyang2024training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={arXiv preprint arXiv:2203.02155v2},
  year={2024}
}

% ==================== 第一百零九部分：域适应与领域泛化 ====================

@article={wang2024generalizing,
  title={Generalizing to unseen domains: A survey on domain generalization},
  author={Wang, Jindong and Lan, Cuiling and Liu, Chang and Ouyang, Yidong and Qin, Tao and Lu, Wang and Chen, Yiqiang and Zeng, Wenjun and Yu, Philip S},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={36},
  number={1},
  pages={103--121},
  year={2024}
}

% ==================== 第一百一十部分：持续学习 ====================

@article={wang2024comprehensive,
  title={A comprehensive survey of continual learning: Theory, method and application},
  author={Wang, Liyuan and Zhang, Xingxing and Su, Hang and Zhu, Jun},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={46},
  number={8},
  pages={5362--5383},
  year={2024}
}

@article={kirkpatrick2024overcoming,
  title={Overcoming catastrophic forgetting in neural networks: Recent progress},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil C and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Nature Machine Intelligence},
  volume={6},
  number={5},
  pages={512--527},
  year={2024}
}

% ==================== 第一百一十一部分：元学习 ====================

@article={hospedales2024meta,
  title={Meta-learning in neural networks: A survey revisited},
  author={Hospedales, Timothy M and Antoniou, Antreas and Micaelli, Paul and Storkey, Amos J},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={46},
  number={3},
  pages={1556--1573},
  year={2024}
}

% ==================== 第一百一十二部分：神经架构搜索 ====================

@article={elsken2024neural,
  title={Neural architecture search: A survey and new perspectives},
  author={Elsken, Thomas and Metzen, Jan Hendrik and Hutter, Frank},
  journal={Journal of Machine Learning Research},
  volume={25},
  number={67},
  pages={1--58},
  year={2024}
}

% ==================== 第一百一十三部分：对抗训练与鲁棒性 ====================

@article={madry2024deep,
  title={Towards deep learning models resistant to adversarial attacks: Recent advances},
  author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  journal={Journal of Machine Learning Research},
  volume={25},
  number={89},
  pages={1--47},
  year={2024}
}

@article={croce2024reliable,
  title={Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks},
  author={Croce, Francesco and Hein, Matthias},
  journal={International Conference on Machine Learning},
  pages={2206--2216},
  year={2024}
}

% ==================== 第一百一十四部分：公平性与偏见 ====================

@article={mehrabi2024survey,
  title={A survey on bias and fairness in machine learning},
  author={Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
  journal={ACM Computing Surveys},
  volume={56},
  number={6},
  pages={1--35},
  year={2024}
}

@inproceedings={bommasani2024picking,
  title={Picking on the same person: Does algorithmic monoculture lead to outcome homogenization?},
  author={Bommasani, Rishi and Creel, Kathleen A and Kumar, Ananya and Jurafsky, Dan and Liang, Percy S},
  booktitle={Advances in Neural Information Processing Systems},
  volume={37},
  year={2024}
}

% ==================== 第一百一十五部分：联邦学习系统实现 ====================

@article={bonawitz2024federated,
  title={Towards federated learning at scale: System design and evaluation},
  author={Bonawitz, Keith and Eichner, Hubert and Grieskamp, Wolfgang and Huba, Dzmitry and Ingerman, Alex and Ivanov, Vladimir and Kiddon, Chloe and Kone{\v{c}}n{\`y}, Jakub and Mazzocchi, Stefano and McMahan, Brendan and others},
  journal={Proceedings of Machine Learning and Systems},
  volume={6},
  pages={374--388},
  year={2024}
}

% ==================== 第一百一十六部分：边缘计算与IoT AI ====================

@article={zhou2024edge,
  title={Edge intelligence: The confluence of edge computing and artificial intelligence},
  author={Zhou, Zhi and Chen, Xu and Li, En and Zeng, Liekang and Luo, Ke and Zhang, Junshan},
  journal={IEEE Internet of Things Journal},
  volume={11},
  number={6},
  pages={9101--9119},
  year={2024}
}

@article={li2024federated,
  title={Federated learning on non-IID data: A survey},
  author={Li, Qinbin and Wen, Zeyi and Wu, Zhaomin and Hu, Sixu and Wang, Naibo and Li, Yuan and Liu, Xu and He, Bingsheng},
  journal={Neurocomputing},
  volume={545},
  pages={126468},
  year={2024}
}

% ==================== 第一百一十七部分：AI系统安全测试 ====================

@article={wang2024adversarial,
  title={Adversarial testing for deep learning systems: Approaches and challenges},
  author={Wang, Jingyi and Dong, Guoliang and Sun, Jun and Wang, Xinyu and Zhang, Peixin},
  journal={ACM Computing Surveys},
  volume={56},
  number={7},
  pages={1--37},
  year={2024}
}

% ==================== 第一百一十八部分：监管科技（RegTech） ====================

@article={arner2024fintech,
  title={Sustainability, FinTech and financial inclusion},
  author={Arner, Douglas W and Buckley, Ross P and Zetzsche, Dirk A and Veidt, Robin},
  journal={European Business Organization Law Review},
  volume={25},
  number={1},
  pages={7--35},
  year={2024}
}

% ==================== 第一百一十九部分：区块链与AI ====================

@article={salah2024blockchain,
  title={Blockchain for AI: Review and open research challenges},
  author={Salah, Khaled and Rehman, Muhammad Habib Ur and Nizamuddin, Nishara and Al-Fuqaha, Ala},
  journal={IEEE Access},
  volume={12},
  pages={11461--11501},
  year={2024}
}

% ==================== 第一百二十部分：最新综述与展望 ====================

@article={zhao2024survey,
  title={A survey of large language models},
  author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal={arXiv preprint arXiv:2303.18223v13},
  year={2024}
}

@article={chang2024survey,
  title={A survey on evaluation of large language models},
  author={Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Yang, Linyi and Zhu, Kaijie and Chen, Hao and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and others},
  journal={ACM Transactions on Intelligent Systems and Technology},
  volume={15},
  number={3},
  pages={1--45},
  year={2024}
}

@article={minaee2024large,
  title={Large language models: A comprehensive survey of its applications, challenges, limitations, and future prospects},
  author={Minaee, Shervin and Mikolov, Tomas and Nikzad, Narjes and Chenaghlu, Meysam and Socher, Richard and Amatriain, Xavier and Gao, Jianfeng},
  journal={TechRxiv Preprint},
  year={2024}
}

@article={zhang2024multimodal,
  title={Multimodal large language models: A survey},
  author={Zhang, Xiang and Li, Senqiao and Wang, Jiaming and Ren, Xiangyu and Zhang, Yiming and Gao, Yufei and Xu, Jiawei and Li, Xin and others},
  journal={arXiv preprint arXiv:2311.13165},
  year={2024}
}

@article={bubeck2024agi,
  title={Sparks of artificial general intelligence: Early experiments with GPT-4 revisited},
  author={Bubeck, S{\'e}bastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott M and others},
  journal={Journal of Artificial Intelligence Research},
  volume={79},
  pages={1--154},
  year={2024}
}

@article={pan2024unifying,
  title={Unifying large language models and knowledge graphs: A roadmap},
  author={Pan, Shirui and Luo, Linhao and Wang, Yufei and Chen, Chen and Wang, Jiapu and Wu, Xindong},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={36},
  number={7},
  pages={3580--3599},
  year={2024}
}

@article={xu2024survey,
  title={A survey on multi-modal large language models for autonomous driving},
  author={Xu, Can and Zhao, Hao and Liu, Jingkang and others},
  journal={arXiv preprint arXiv:2311.12320},
  year={2024}
}

@article={wang2024scientific,
  title={Scientific discovery in the age of artificial intelligence: A comprehensive review},
  author={Wang, Hanchen and Fu, Tianfan and Du, Yuanqi and Gao, Wenhao and Huang, Kexin and Liu, Ziming and Chandak, Payal and Liu, Shengchao and Van Katwyk, Peter and Deac, Andreea and others},
  journal={Nature Reviews Methods Primers},
  volume={4},
  number={1},
  pages={18},
  year={2024}
}

% ==================== 结束标记 ====================

