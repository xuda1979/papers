\documentclass{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}

\title{Fine-tuning Binary Large Language Models: A $\{-1, 0, 1\}$ Parameter Approach for Efficient Training and Inference}
\author{Research Team}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
This paper explores the fine-tuning of Large Language Models (LLMs) that have been quantized to ternary values $\{-1, 0, 1\}$. We investigate methods to continue training these highly quantized models to maintain performance while significantly reducing computational and memory requirements for both training and inference.
\end{abstract}

\section{Introduction}
Large Language Models (LLMs) have achieved remarkable success in various natural language processing tasks. However, their massive size imposes significant computational and memory costs. Quantization is a promising technique to alleviate these costs. In this work, we focus on extreme quantization to ternary weights $\{-1, 0, 1\}$ and propose efficient fine-tuning strategies.

\section{Methodology}
\label{sec:methodology}
We describe our approach for converting float-based LLMs to binary/ternary networks and the subsequent fine-tuning process.
% TODO: Detail the quantization process and fine-tuning algorithm.

\section{Experiments}
\label{sec:experiments}
% TODO: Describe experimental setup and results.

\section{Conclusion}
% TODO: Conclude the findings.

\end{document}
