
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{gu2023mamba,
  title={Mamba: Linear-time sequence modeling with selective state spaces},
  author={Gu, Albert and Dao, Tri},
  journal={arXiv preprint arXiv:2312.00752},
  year={2023}
}

@article{child2019generating,
  title={Generating Long Sequences with Sparse Transformers},
  author={Child, Rewon and Gray, Scott and Radford, Alec and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1904.10509},
  year={2019}
}

@article{beltagy2020longformer,
  title={Longformer: The Long-Document Transformer},
  author={Beltagy, Iz and Peters, Matthew E and Cohan, Arman},
  journal={arXiv preprint arXiv:2004.05150},
  year={2020}
}

@article{wang2020linformer,
  title={Linformer: Self-Attention with Linear Complexity},
  author={Wang, Sinong and Li, Belinda Z and Khabsa, Madian and Fang, Han and Ma, Hao},
  journal={arXiv preprint arXiv:2006.04768},
  year={2020}
}

@article{kitaev2020reformer,
  title={Reformer: The Efficient Transformer},
  author={Kitaev, Nikita and Kaiser, {\L}ukasz and Levskaya, Anselm},
  journal={arXiv preprint arXiv:2001.04451},
  year={2020}
}

@inproceedings{yun2020,
  title={Are Transformers universal approximators of sequence-to-sequence functions?},
  author={Yun, Chulhee and Bhojanapalli, Srinadh and Rawat, Ankit Singh and Reddi, Sashank J and Kumar, Sanjiv},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{davis1970rotation,
  title={The rotation of eigenvectors by a perturbation. III},
  author={Davis, Chandler and Kahan, William M},
  journal={SIAM Journal on Numerical Analysis},
  volume={7},
  number={1},
  pages={1--46},
  year={1970},
  publisher={SIAM}
}

@article{tropp2012user,
  title={User-friendly tail bounds for sums of random matrices},
  author={Tropp, Joel A},
  journal={Foundations of computational mathematics},
  volume={12},
  number={4},
  pages={389--434},
  year={2012},
  publisher={Springer}
}

@book{chung1997spectral,
  title={Spectral graph theory},
  author={Chung, Fan RK},
  volume={92},
  year={1997},
  publisher={American Mathematical Soc.}
}

@article{spielman2011graph,
  title={Graph sparsification by effective resistances},
  author={Spielman, Daniel A and Srivastava, Nikhil},
  journal={SIAM Journal on Computing},
  volume={40},
  number={6},
  pages={1913--1926},
  year={2011},
  publisher={SIAM}
}

@article{roy2021mixture,
    title={Mixture-of-Depths: Dynamically allocating compute in transformer-based language models},
    author={Roy, Aurko and Saffar, Mohammad and Vaswani, Ashish and Grangier, David},
    journal={arXiv preprint arXiv:2104.04561},
    year={2021}
}

@article{dao2022flashattention,
  title={FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness},
  author={Dao, Tri and Fu, Daniel Y and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  journal={Advances in Neural Information Processing Systems},
  year={2022}
}
