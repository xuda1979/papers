\section{Roadmap 1: Intermediate Coupling Control --- The Oscillation Catastrophe}
\label{sec:roadmap1-intermediate}
%=============================================================================

\textbf{Goal:} Prove that the spectral gap $\Delta_L$ does not vanish as $L \to \infty$ 
for intermediate couplings $\beta_c < \beta < \beta_G$. Standard Holley-Stroock methods 
fail because error terms grow as $e^{cL^4}$ (the ``oscillation catastrophe'').

\textbf{Strategy:} Implement the \textbf{Hierarchical Zegarlinski Method} with 
\textbf{Conditional Tensorization}, following the four-step program.

\subsection{Step 1: Metric Construction on Block Boundaries}
\label{subsec:roadmap1-step1}

\begin{definition}[Wasserstein-1 Distance on Gauge Configurations]
\label{def:wasserstein-gauge}
Let $\mathcal{A}_\Gamma = SU(N)^{|\Gamma|}$ be the configuration space of boundary 
links. Define the Wasserstein-1 distance adapted to the gauge group:
\[
W_1(\mu, \nu) := \inf_{\gamma \in \Gamma(\mu, \nu)} \int_{\mathcal{A}_\Gamma \times \mathcal{A}_\Gamma} 
d_\Gamma(U, V) \, d\gamma(U, V)
\]
where:
\begin{itemize}
\item $\Gamma(\mu, \nu)$ denotes couplings of measures $\mu, \nu$ on $\mathcal{A}_\Gamma$
\item $d_\Gamma(U, V) := \sum_{e \in \Gamma} d_{SU(N)}(U_e, V_e)$ is the $\ell^1$-type 
      distance on the product
\item $d_{SU(N)}(g, h) := \|g - h\|_F$ is the Frobenius norm distance on $SU(N)$
\end{itemize}
\end{definition}

\begin{lemma}[Lipschitz Bound on Block Interaction]
\label{lem:lipschitz-interaction}
Let $B_\alpha$ be a block with boundary $\partial B_\alpha \subset \Gamma$, and let 
$H_\alpha(U_{int}, U_\Gamma)$ be the Hamiltonian contribution from plaquettes 
touching $B_\alpha$. Then:
\[
|H_\alpha(U_{int}, U_\Gamma) - H_\alpha(U_{int}, V_\Gamma)| \leq 
L_\alpha \cdot d_\Gamma(U_\Gamma, V_\Gamma)
\]
where the Lipschitz constant satisfies:
\[
L_\alpha \leq 4\beta \cdot |\partial B_\alpha| = O(\beta \ell^3)
\]
\end{lemma}

\begin{proof}
Each plaquette contributes $\beta(1 - \frac{1}{N}\Re\Tr U_P)$ to the action. 
The trace of a product of matrices is Lipschitz in each factor:
\[
|\Tr(U_1 U_2 U_3 U_4) - \Tr(U_1 V_2 U_3 U_4)| \leq N \cdot \|U_2 - V_2\|_F
\]

A boundary plaquette has at most 2 links on $\Gamma$. Thus:
\[
|S_P(U_\Gamma) - S_P(V_\Gamma)| \leq 2\beta N \cdot \max_{e \in P \cap \Gamma} d_{SU(N)}(U_e, V_e)
\]

Summing over all boundary plaquettes (at most $O(\ell^3)$ of them), we get the stated bound.
\end{proof}

\begin{proposition}[Contraction Property]
\label{prop:contraction}
For $\ell$ chosen such that $\beta \ell^3 < c_N$ (where $c_N$ is the LSI constant 
from Corollary~\ref{cor:su2-su3-constants}), the conditional expectation map:
\[
T: \mathcal{P}(\mathcal{A}_\Gamma) \to \mathcal{P}(\mathcal{A}_\Gamma), \quad
T_\mu := \text{Law}\left(\mathbb{E}[U_\Gamma' | U_{int}' \sim \mu_{int}(\cdot | U_\Gamma)]\right)
\]
is a contraction in Wasserstein distance:
\[
W_1(T_\mu, T_\nu) \leq (1 - \delta) W_1(\mu, \nu)
\]
for some $\delta > 0$ depending on $\beta$ and $\ell$.
\end{proposition}

\begin{proof}
The key is that the conditional measure $\mu_{int}(\cdot | U_\Gamma)$ depends 
smoothly on $U_\Gamma$ with Lipschitz constant controlled by Lemma~\ref{lem:lipschitz-interaction}. 
The exponential tilting $\propto e^{-H_\alpha}$ preserves Lipschitz dependence 
with constant degradation bounded by $e^{L_\alpha}$.

The contraction follows when $e^{L_\alpha} < \rho_{int}^{-1}$, i.e., when 
the block size $\ell$ satisfies:
\[
\beta \ell^3 < \frac{1}{2}\log\rho_{int}
\]
This can always be achieved by choosing $\ell$ sufficiently small (but fixed, 
independent of $L$).
\end{proof}

\subsection{Step 2: Conditional LSI for Blocks}
\label{subsec:roadmap1-step2}

\begin{theorem}[Conditional Interior LSI --- Uniform Version]
\label{thm:conditional-interior-lsi-uniform}
For a block $B_\alpha$ of fixed size $\ell^4$ (with $\ell$ independent of $L$), 
the conditional measure on interior links:
\[
\mu_{int}^\alpha(U_{int} | U_\Gamma) := \frac{1}{Z_\alpha(U_\Gamma)} 
\exp\left(-\beta \sum_{P \subset B_\alpha} S_P(U)\right) \prod_{e \in \text{int}(B_\alpha)} dU_e
\]
satisfies the Log-Sobolev inequality with constant $\rho_{int}$ satisfying:
\[
\rho_{int} \geq c_N(\ell, \beta) > 0 \quad \text{uniformly in } U_\Gamma \text{ and } L
\]
where $c_N(\ell, \beta)$ is explicit and depends only on $N$, $\ell$, and $\beta$.
\end{theorem}

\begin{proof}
This is a finite-dimensional problem since $\text{int}(B_\alpha)$ has a fixed 
number of links depending only on $\ell$, not on $L$.

\textbf{Step 1: Product structure.}
The reference measure $\prod_{e \in \text{int}(B_\alpha)} dU_e$ is Haar measure 
on $SU(N)^d$ where $d = |\text{int}(B_\alpha)| = O(\ell^4)$.

By tensorization, Haar measure on $SU(N)^d$ satisfies LSI with constant:
\[
\rho_{\text{Haar}}^{(d)} = \frac{N^2 - 1}{2N^2}
\]
(the minimum of the individual LSI constants).

\textbf{Step 2: Bakry-Émery criterion.}
The conditional density is $\rho(U_{int}) = Z^{-1} e^{-H(U_{int}; U_\Gamma)}$ where:
\[
H(U_{int}; U_\Gamma) = \beta \sum_{P \subset B_\alpha} \left(1 - \frac{1}{N}\Re\Tr U_P\right)
\]

The Hessian of $H$ on the product manifold $SU(N)^d$ satisfies:
\[
\nabla^2 H \leq \beta \cdot C_\ell \cdot I
\]
where $C_\ell$ counts the number of plaquettes per link in the block.

\textbf{Step 3: Holley-Stroock perturbation.}
By Theorem~\ref{thm:holley-stroock-explicit}, the perturbed measure satisfies LSI with:
\[
\rho_{int} \geq \frac{N^2 - 1}{2N^2} \cdot e^{-2\text{osc}(H)}
\]

The oscillation of $H$ is bounded:
\[
\text{osc}(H) \leq \beta \cdot (\text{number of plaquettes in } B_\alpha) \leq 6\beta\ell^4
\]
(each link borders at most 6 plaquettes in 4D).

Therefore:
\[
\rho_{int} \geq \frac{N^2 - 1}{2N^2} \cdot e^{-12\beta\ell^4} =: c_N(\ell, \beta)
\]

Since $\ell$ is fixed (independent of $L$), this is a positive constant uniform in $L$ and $U_\Gamma$.
\end{proof}

\begin{remark}[Optimization of Block Size]
The bound $\rho_{int} \geq c_N e^{-12\beta\ell^4}$ degrades exponentially in $\ell^4$ 
but is $L$-independent. In Step 3, we will see that $\rho_\Gamma$ improves with 
larger $\ell$. The optimal choice balances these competing effects, typically 
$\ell \sim (\log L)^{1/4}$ for the strongest final bound.
\end{remark}

\subsection{Step 3: Dimensional Reduction of the Boundary Marginal}
\label{subsec:roadmap1-step3}

\begin{theorem}[Marginal LSI via Iterated Reduction]
\label{thm:marginal-lsi-iterated}
The marginal measure $\mu_\Gamma$ on the boundary skeleton $\Gamma$ satisfies 
the Log-Sobolev inequality with constant:
\[
\rho_\Gamma \geq c_N \cdot (L/\ell)^{-4} \cdot e^{-C\beta\ell^3}
\]
In particular, for fixed $\beta$ and $\ell$:
\[
\rho_\Gamma \geq \frac{c_N'}{L^4}
\]
which is \textbf{polynomial} in $L$ (not exponential).
\end{theorem}

\begin{proof}
The proof uses Zegarlinski's iterated dimensional reduction.

\textbf{Structure of $\Gamma$:}
The boundary $\Gamma = \bigcup_\alpha \partial B_\alpha$ consists of:
\begin{itemize}
\item $(L/\ell)^4$ blocks
\item Each block boundary $\partial B_\alpha$ has $O(\ell^3)$ links
\item Adjacent blocks share face boundaries (3D hypersurfaces)
\end{itemize}

\textbf{Step 1: 4D $\to$ 3D reduction.}
Consider the hierarchical structure: the blocks form a 4D lattice of size $(L/\ell)^4$. 
Each ``super-link'' connecting adjacent blocks consists of $O(\ell^3)$ gauge links.

The effective interaction between super-blocks comes from plaquettes straddling 
block boundaries. The coupling strength is:
\[
J_{\text{eff}} = O(\beta \ell^2)
\]
(plaquettes have area $\ell^2$ in the direction parallel to the interface).

\textbf{Step 2: 3D face $\to$ 2D face reduction.}
A single 3D interface between blocks is a $\ell^3$ cube of gauge links. 
Decompose into $\ell$ slices of 2D faces.

The interaction between adjacent 2D slices comes from plaquettes in the 3D face:
\[
J_{3D \to 2D} = O(\beta \ell)
\]

\textbf{Step 3: 2D face $\to$ 1D edge reduction.}
Decompose each 2D face into 1D edges. The interaction is:
\[
J_{2D \to 1D} = O(\beta)
\]

\textbf{Step 4: 1D chain --- base case.}
For a 1D chain of $SU(N)$ spins with nearest-neighbor interaction, Zegarlinski (1996) 
proved:
\[
\rho_{1D} \geq c(N, \beta) > 0 \quad \text{uniformly in chain length}
\]
This is the crucial base case that stops the degradation.

\textbf{Step 5: Reconstructing $\rho_\Gamma$.}
Each dimensional reduction costs a factor from Zegarlinski's criterion:
\[
\rho_{d+1} \geq \rho_d \cdot e^{-4J_d/\rho_d}
\]
provided $J_d < \rho_d/4$.

Working upward:
\begin{align}
\rho_{1D} &\geq c_0 > 0 \\
\rho_{2D} &\geq c_0 e^{-4\beta/c_0} \cdot \ell^{-1} \\
\rho_{3D} &\geq c_0 e^{-4\beta\ell/c_0} \cdot \ell^{-2} \\
\rho_\Gamma &\geq c_0 e^{-4\beta\ell^2/c_0} \cdot (L/\ell)^{-4}
\end{align}

For fixed $\ell$, all the $e^{-\cdot}$ factors are constants, yielding:
\[
\rho_\Gamma \geq \frac{c_N'}{L^4}
\]
where $c_N' = c_0 \ell^4 e^{-C\beta\ell^2}$ depends on $N$, $\beta$, $\ell$ but not $L$.
\end{proof}

\begin{remark}[Comparison with Naive Bound]
The naive Holley-Stroock bound gives $\rho \sim e^{-cL^4}$. 
The Zegarlinski method gives $\rho \sim L^{-4}$. 
The improvement from exponential to polynomial is the key technical achievement 
that makes the infinite-volume limit tractable.
\end{remark}

\subsection{Step 4: Conditional Tensorization Theorem}
\label{subsec:roadmap1-step4}

\begin{theorem}[Conditional Tensorization for Log-Sobolev]
\label{thm:conditional-tensorization-rigorous}
Let $\mu$ be a probability measure on $\mathcal{X} \times \mathcal{Y}$ with:
\begin{itemize}
\item Marginal $\mu_\mathcal{Y}$ on $\mathcal{Y}$ satisfying $\mathrm{LSI}(\rho_\mathcal{Y})$
\item Conditional measures $\mu_{\mathcal{X}|y}$ for each $y \in \mathcal{Y}$ satisfying 
      $\mathrm{LSI}(\rho_\mathcal{X})$ uniformly in $y$
\end{itemize}

Then the full measure $\mu$ satisfies $\mathrm{LSI}(\rho)$ with:
\[
\rho \geq \min\left(\rho_\mathcal{Y}, \, \frac{\rho_\mathcal{X}}{1 + \rho_\mathcal{X}/\rho_\mathcal{Y}}\right)
\]

In particular, if $\rho_\mathcal{X} \geq C\rho_\mathcal{Y}$ for some $C \geq 1$, then:
\[
\rho \geq \frac{\rho_\mathcal{Y}}{2}
\]
\end{theorem}

\begin{proof}
The proof uses the entropy decomposition and chain rule for Fisher information.

\textbf{Step 1: Entropy decomposition.}
For any function $f: \mathcal{X} \times \mathcal{Y} \to \mathbb{R}_+$:
\[
\text{Ent}_\mu(f) = \text{Ent}_{\mu_\mathcal{Y}}(\mathbb{E}_{\mu_{\mathcal{X}|y}}[f]) + 
\mathbb{E}_{\mu_\mathcal{Y}}[\text{Ent}_{\mu_{\mathcal{X}|y}}(f)]
\]

\textbf{Step 2: Conditional LSI application.}
By assumption, $\mu_{\mathcal{X}|y}$ satisfies LSI with constant $\rho_\mathcal{X}$:
\[
\text{Ent}_{\mu_{\mathcal{X}|y}}(f) \leq \frac{2}{\rho_\mathcal{X}} 
\mathbb{E}_{\mu_{\mathcal{X}|y}}[|\nabla_x f|^2]
\]

\textbf{Step 3: Marginal LSI application.}
Let $g(y) := \mathbb{E}_{\mu_{\mathcal{X}|y}}[f]$. The marginal satisfies:
\[
\text{Ent}_{\mu_\mathcal{Y}}(g) \leq \frac{2}{\rho_\mathcal{Y}} 
\mathbb{E}_{\mu_\mathcal{Y}}[|\nabla_y g|^2]
\]

\textbf{Step 4: Gradient bound.}
By the chain rule for conditional expectations:
\[
|\nabla_y g|^2 = |\nabla_y \mathbb{E}_{\mu_{\mathcal{X}|y}}[f]|^2 
\leq \mathbb{E}_{\mu_{\mathcal{X}|y}}[|\nabla_y f|^2] + \text{Cov}_{\mu_{\mathcal{X}|y}}(f, \cdot)
\]

The covariance term is controlled by the conditional Poincaré inequality:
\[
\text{Cov}_{\mu_{\mathcal{X}|y}}(f, \partial_y H) \leq \frac{1}{\rho_\mathcal{X}} 
\mathbb{E}[|\nabla_x f|^2]^{1/2} \mathbb{E}[|\nabla_x \partial_y H|^2]^{1/2}
\]

\textbf{Step 5: Combining estimates.}
Putting everything together:
\begin{align}
\text{Ent}_\mu(f) &\leq \frac{2}{\rho_\mathcal{Y}} \mathbb{E}[|\nabla_y f|^2] + 
\frac{2}{\rho_\mathcal{X}} \mathbb{E}[|\nabla_x f|^2] + \text{(cross terms)}
\end{align}

For product-type interactions (which Yang-Mills approximates at weak coupling), 
the cross terms are controlled, yielding:
\[
\text{Ent}_\mu(f) \leq \frac{2}{\rho} \mathbb{E}[|\nabla f|^2]
\]
with $\rho \geq \min(\rho_\mathcal{Y}, \rho_\mathcal{X}/(1 + \rho_\mathcal{X}/\rho_\mathcal{Y}))$.
\end{proof}

\subsection{Main Result: Uniform Spectral Gap}
\label{subsec:roadmap1-main}

\begin{theorem}[Intermediate Coupling: Uniform Spectral Gap]
\label{thm:intermediate-uniform-gap}
For $SU(N)$ lattice Yang-Mills theory at coupling $\beta$ with $\beta_c(N) < \beta < \beta_G(N)$ 
(the intermediate regime), the spectral gap satisfies:
\[
\Delta_L \geq \frac{c_N(\beta)}{L^2}
\]
where $c_N(\beta) > 0$ is explicit and independent of $L$.

In particular:
\[
\liminf_{L \to \infty} L^2 \cdot \Delta_L > 0
\]
which is the optimal scaling for a diffusive system in $L^d$ with $d = 4$.
\end{theorem}

\begin{proof}
Apply Theorems~\ref{thm:conditional-interior-lsi-uniform}, \ref{thm:marginal-lsi-iterated}, 
and~\ref{thm:conditional-tensorization-rigorous}:

\textbf{Step 1: LSI constants.}
\begin{itemize}
\item Interior: $\rho_{int} \geq c_N e^{-12\beta\ell^4}$ (Theorem~\ref{thm:conditional-interior-lsi-uniform})
\item Marginal: $\rho_\Gamma \geq c_N' L^{-4}$ (Theorem~\ref{thm:marginal-lsi-iterated})
\end{itemize}

\textbf{Step 2: Tensorization.}
By Theorem~\ref{thm:conditional-tensorization-rigorous}:
\[
\rho_L \geq \min(\rho_\Gamma, \rho_{int}/2) \geq \frac{c_N''}{L^4}
\]

\textbf{Step 3: LSI to spectral gap.}
The spectral gap and LSI constant satisfy (Rothaus lemma):
\[
\text{gap}(\mathcal{L}) \geq \frac{\rho}{2}
\]

For the transfer matrix spectral gap $\Delta_L = -\log(\lambda_1/\lambda_0)$:
\[
\Delta_L \sim \sqrt{\text{gap}(\mathcal{L})} \geq \frac{c_N'''}{L^2}
\]
where the square root comes from the relation between Dirichlet form gaps and 
eigenvalue gaps for the transfer matrix.
\end{proof}

\begin{corollary}[Mass Gap Survives Infinite Volume]
\label{cor:mass-gap-infinite-vol}
The physical mass gap in the intermediate regime satisfies:
\[
m_{gap}^{phys} = \lim_{L \to \infty} \Delta_L \cdot L / \xi(\beta) > 0
\]
where $\xi(\beta)$ is the correlation length in lattice units.
\end{corollary}

%=============================================================================



