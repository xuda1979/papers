\documentclass[11pt, a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage{amsmath, amssymb}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{hyperref}

\geometry{margin=1in}

\title{The Calculus of Instructions: An Algebraic Formalization of Prompt Engineering}
\author{Research Group on Theoretical AI}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
Prompt Engineering has evolved as a "folk art," relying on heuristics and trial-and-error. This paper proposes a transition to "Algorithmic Prompting," formalizing prompts not as strings but as functional operators in a high-dimensional semantic space. We introduce a "Prompt Algebra" that defines operations such as composition, negation, and constraint satisfaction. By treating the LLM as a compiler and the prompt as code, we derive a "Calculus of Instructions" that predicts the interaction effects of combining multiple directives. We also explore the security implications, applying this formalism to "Contextual Integrity Verification" to mathematically prove resistance against prompt injection attacks.
\end{abstract}

\section{Introduction}
A major limitation in current AI interaction is the lack of a "theory of compositionality" for prompts. Why does adding "Let's think step by step" change the output distribution so drastically? Why does the order of instructions matter? \citep{zhou2022large}.

We posit that prompts are not merely context; they are "soft programs" that reconfigure the attention weights of the model. We aim to define a formal system $(P, \oplus, \otimes)$ where $P$ is the set of all prompts and the operations model their semantic combination.

\section{Theoretical Framework}

\subsection{The Prompt Algebra}
Let $M$ be an LLM. Let $f_p(x) = M(p \oplus x)$ be the function induced by prompt $p$.
We investigate the properties of the composition operator $\oplus$:
\begin{itemize}
    \item \textbf{Non-Commutativity}: $p_1 \oplus p_2 \neq p_2 \oplus p_1$. The order of instructions ("Summarize then Translate" vs. "Translate then Summarize") fundamentally alters the information flow.
    \item \textbf{Idempotence}: Does $p \oplus p \approx p$? (Repeating an instruction often reinforces it, unlike standard logic).
    \item \textbf{Inverse Elements}: Does there exist a prompt $p^{-1}$ such that $p \oplus p^{-1}$ is the null identity? (e.g., "Forget the previous instruction").
\end{itemize}

\section{Methodology: Axiomatic Testing}
We use API access to SOTA models to test these algebraic properties.
\begin{itemize}
    \item \textbf{Associativity Test}: Is $(A \oplus B) \oplus C \equiv A \oplus (B \oplus C)$?
    \item \textbf{Distributivity}: Does $Task(Data_1 + Data_2) \equiv Task(Data_1) + Task(Data_2)$?
\end{itemize}

\subsection{Prompt Compilers}
If the algebra is consistent, we can build "Prompt Compilers." Just as a C++ compiler optimizes code, a prompt compiler could rewrite a user's intent into the mathematically optimal token sequence for a specific model $\theta$.

\section{Security: The Algebra of Injection}
Prompt Injection \citep{greshake2023more} can be viewed as an algebraic attack: finding a user input $u$ such that:
\begin{equation}
    System \oplus u \approx u
\end{equation}
(The user input overwrites the system instruction).
We propose "Contextual Integrity Verification" (CIV) as a type system for this algebra. If $System$ has type $T_{admin}$ and $u$ has type $T_{user}$, the operation $\oplus$ must respect type safety, preventing $T_{user}$ from modifying the state reserved for $T_{admin}$.

\section{Conclusion}
Formalizing prompt engineering is the necessary step to turn AI interaction from an art into a robust engineering discipline. By establishing the "Calculus of Instructions," we pave the way for automated optimization, verification, and security of LLM systems.

\bibliographystyle{plainnat}
\bibliography{references}

\end{document}
