\section{Mosco Convergence of \texorpdfstring{$p$}{p}-Energies}
\label{app:Mosco}

To rigorously justify the passage to the limit $\epsilon \to 0$ in the Penrose Inequality, we establish the Mosco convergence of the $p$-energy functionals associated with the smoothed metrics $\hat{g}_\epsilon$ to the functional on the singular limit $(\tM, \tg)$. This variational convergence ensures that the minimizers (the $p$-capacitary potentials) converge strongly, preventing any sudden jump in the capacity or the Hawking mass.

\subsection{Setup and Definitions}
Let $W^{1,p}(\tM)$ be the fixed Sobolev space on the background manifold. Since all metrics $\hat{g}_\epsilon$ and $\tg$ are uniformly bi-Lipschitz equivalent on the compact collar (and identical outside), the underlying vector space $W^{1,p}$ is the same for all $\epsilon$.
Define the energy functionals $\mathcal{F}_\epsilon, \mathcal{F}_0 : L^p(\tM) \to [0, \infty]$ by:
\[
    \mathcal{F}_\epsilon(u) = \begin{cases} \int_{\tM} |\nabla u|_{\hat{g}_\epsilon}^p \, dV_{\hat{g}_\epsilon} & \text{if } u \in W^{1,p}(\tM), \\ +\infty & \text{otherwise}. \end{cases}
\]
\[
    \mathcal{F}_0(u) = \begin{cases} \int_{\tM} |\nabla u|_{\tg}^p \, dV_{\tg} & \text{if } u \in W^{1,p}(\tM), \\ +\infty & \text{otherwise}. \end{cases}
\]

\begin{theorem}[Mosco Convergence]\label{thm:MoscoAppendix}
The sequence of functionals $\mathcal{F}_\epsilon$ Mosco-converges to $\mathcal{F}_0$ in $L^p(\tM)$ as $\epsilon \to 0$. That is, the following two conditions hold:
\begin{enumerate}
    \item \textbf{Liminf Inequality:} For every sequence $u_\epsilon \to u$ weakly in $L^p$,
    \[ \liminf_{\epsilon \to 0} \mathcal{F}_\epsilon(u_\epsilon) \ge \mathcal{F}_0(u). \]
    \item \textbf{Recovery Sequence:} For every $u \in L^p$, there exists a sequence $u_\epsilon \to u$ strongly in $L^p$ such that
    \[ \limsup_{\epsilon \to 0} \mathcal{F}_\epsilon(u_\epsilon) \le \mathcal{F}_0(u). \]
\end{enumerate}
\end{theorem}

\begin{proof}
\textbf{1. Proof of the Liminf Inequality.}
Let $u_\epsilon \to u$ weakly in $L^p$. Without loss of generality, assume $\liminf \mathcal{F}_\epsilon(u_\epsilon) < \infty$. Then $u_\epsilon$ is bounded in $W^{1,p}$. By reflexivity, a subsequence converges weakly in $W^{1,p}$ to $u$.
The metrics converge uniformly: $\|\hat{g}_\epsilon - \tg\|_{C^0} \to 0$.
Write the energy density as $L_\epsilon(x, \xi) = \langle \xi, \xi \rangle_{\hat{g}_\epsilon(x)}^{p/2} \sqrt{\det \hat{g}_\epsilon(x)}$.
Since $\hat{g}_\epsilon \to \tg$ uniformly, the integrand converges uniformly on compact sets: $L_\epsilon(x, \xi) \to L_0(x, \xi)$.
The functional $u \mapsto \int L_0(x, \nabla u)$ is convex and continuous in $\nabla u$, hence weakly lower semicontinuous.
The perturbation by $\epsilon$ is uniform, so standard $\Gamma$-convergence results for integral functionals with continuous coefficients apply (see Dal Maso \cite{dalmaso1993}, Theorem 5.14).
Explicitly:
\begin{align*}
    \int |\nabla u_\epsilon|_{\hat{g}_\epsilon}^p dV_\epsilon &= \int |\nabla u_\epsilon|_{\tg}^p dV_0 + \int \left( |\nabla u_\epsilon|_{\hat{g}_\epsilon}^p dV_\epsilon - |\nabla u_\epsilon|_{\tg}^p dV_0 \right) \\
    &\ge \mathcal{F}_0(u_\epsilon) - C\epsilon \|\nabla u_\epsilon\|_p^p.
\end{align*}
Taking the liminf:
\[ \liminf \mathcal{F}_\epsilon(u_\epsilon) \ge \liminf (\mathcal{F}_0(u_\epsilon) - o(1)) \ge \mathcal{F}_0(u). \]

\textbf{2. Proof of the Recovery Sequence.}
Let $u \in W^{1,p}(\tM)$ (otherwise the inequality is trivial).
Choose the constant sequence $u_\epsilon = u$.
Since $u$ is fixed, we only need to estimate the convergence of the integral with varying coefficients.
\[
    |\mathcal{F}_\epsilon(u) - \mathcal{F}_0(u)| \le \int_{\tM} \left| |\nabla u|_{\hat{g}_\epsilon}^p \sqrt{\det \hat{g}_\epsilon} - |\nabla u|_{\tg}^p \sqrt{\det \tg} \right| dx.
\]
The integrand is supported on the collar $N_{2\epsilon}$ (where the metrics differ) and the global domain (where they are identical).
More precisely, the metrics differ only in $N_{2\epsilon}$.
Outside $N_{2\epsilon}$, the difference is zero.
Inside $N_{2\epsilon}$, we have uniform convergence $\|\hat{g}_\epsilon - \tg\|_{L^\infty} \le C\epsilon$.
Thus, the integrand is bounded by $C\epsilon |\nabla u|^p$.
\[
    |\mathcal{F}_\epsilon(u) - \mathcal{F}_0(u)| \le C\epsilon \int_{N_{2\epsilon}} |\nabla u|^p dx.
\]
Since $u \in W^{1,p}$, the integral over the shrinking set $N_{2\epsilon}$ goes to 0 by absolute continuity of the Lebesgue integral.
Thus $\mathcal{F}_\epsilon(u) \to \mathcal{F}_0(u)$.
\end{proof}

\begin{remark}[Uniform Gradient Bounds and Ellipticity Independence from Curvature]\label{rem:EllipticityIndependence}
A critical subtlety in the Mosco convergence proof concerns the \emph{uniformity} of gradient bounds for the minimizers $u_{p,\epsilon}$ as $\epsilon \to 0$. The metric $\hat{g}_\epsilon$ is undergoing surgery in the collar $N_{2\epsilon}$: while it converges to $\tg$ in $C^0$, its curvature tensor $R_{\hat{g}_\epsilon}$ diverges as $O(1/\epsilon)$. A natural concern is whether the elliptic regularity constants---and hence the gradient bounds---might blow up with the curvature.

\textbf{Resolution:} The uniform gradient bound relies on the \textbf{De Giorgi--Nash--Moser estimates} for elliptic equations, which depend \emph{only} on the \textbf{ellipticity constants} $(\lambda, \Lambda)$ of the metric, \emph{not} on the smoothness of the metric coefficients beyond measurability. Specifically:

\begin{enumerate}
    \item \textbf{Ellipticity preservation under convolution:} The smoothed metric $\hat{g}_\epsilon$ is constructed via convolution of the Lipschitz metric $\tg$ with a standard mollifier. Convolution preserves ellipticity bounds:
    \[
        \lambda |\xi|^2 \le \tg_{ij}\xi^i\xi^j \le \Lambda |\xi|^2 \quad \Longrightarrow \quad \lambda |\xi|^2 \le (\hat{g}_\epsilon)_{ij}\xi^i\xi^j \le \Lambda |\xi|^2.
    \]
    The same ellipticity constants $(\lambda, \Lambda)$ hold for all $\epsilon > 0$.
    
    \item \textbf{Tolksdorf--Lieberman gradient estimates:} The interior gradient bounds for $p$-harmonic functions (Tolksdorf \cite{tolksdorf1984}, Lieberman \cite{lieberman1988}) have the form
    \[
        \|\nabla u_{p,\epsilon}\|_{L^\infty(K)} \le C(\lambda, \Lambda, K, \text{dist}(K, \partial\tM)),
    \]
    where the constant $C$ depends on the ellipticity ratio $\Lambda/\lambda$ but \emph{not} on higher-order smoothness of the metric coefficients. In particular, $C$ is \textbf{independent of $\epsilon$} even though $\|R_{\hat{g}_\epsilon}\|_{L^\infty} \to \infty$ as $\epsilon \to 0$.
    
    \item \textbf{Stability of De Giorgi--Nash--Moser constants:} The Harnack inequality and $C^{0,\alpha}$ regularity for solutions of divergence-form elliptic equations depend only on the ellipticity and dimension. Since the ellipticity constants of $\hat{g}_\epsilon$ are uniformly bounded (in fact, constant in $\epsilon$), all De Giorgi--Nash--Moser constants remain stable as $\epsilon \to 0$.
\end{enumerate}

\textbf{Conclusion:} The gradient bound $\|\nabla u_{p,\epsilon}\|_{L^\infty(K)} \le C_T$ with $C_T$ independent of $\epsilon$ is rigorously justified, despite the curvature explosion $R_{\hat{g}_\epsilon} \sim 1/\epsilon$. This is the key observation enabling the uniform estimates in Theorem~\ref{thm:CompleteDblLimit} and the validity of the Mosco convergence framework.
\end{remark}

\subsection{Convergence of Capacitary Potentials}
A direct consequence of Mosco convergence is the convergence of minimizers.
Let $u_\epsilon$ be the $p$-capacitary potential for $(\tM, \hat{g}_\epsilon)$ (solution to $\Delta_{p,\epsilon} u_\epsilon = 0$ with $u_\epsilon \to 1$ at $\infty$, $u_\epsilon=0$ on $\Sigma$).
Let $u_0$ be the potential for $(\tM, \tg)$.
\begin{corollary}
$u_\epsilon \to u_0$ strongly in $W^{1,p}(\tM)$. Consequently, the level set masses converge:
\[ \lim_{\epsilon \to 0} M_{Hawking}(\Sigma_t(u_\epsilon)) = M_{Hawking}(\Sigma_t(u_0)). \]
\end{corollary}
This justifies the continuity of the mass profile used in Section \ref{sec:Synthesis}.

